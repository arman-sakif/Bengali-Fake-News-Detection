{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Pips"
      ],
      "metadata": {
        "id": "PVbzepNk5h-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOq7B_40lDK9",
        "outputId": "a735fac6-2cc7-4694-a248-069f608d163e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLXleXuvNmOV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Ni-8Uqswow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9e53607-6e2c-4383-d286-af4d75f0a194"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaUFAGkoOjw9"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeHFP-aKe8yS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEtV-2-RNpO5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQJ_1ZHyvhne"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import *\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "#note: importing something 2nd time does not cause any performance loss \n"
      ],
      "metadata": {
        "id": "spCh2Lun43Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files"
      ],
      "metadata": {
        "id": "xco38aFLIKSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.disable(logging.INFO) # disable INFO and DEBUG logging everywhere"
      ],
      "metadata": {
        "id": "T2yRWmXmINb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logger = logging.getLogger('my-logger')\n",
        "logger.propagate = False\n",
        "# now if you use logger it will not log to console."
      ],
      "metadata": {
        "id": "citJ1TVK22Zn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "CT88y4RBYZEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Datasets"
      ],
      "metadata": {
        "id": "NGquUlcjUKjK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = '/content/drive/MyDrive/datasets/aug_train_augx2_cbuet_para.csv'\n",
        "path2 = '/content/drive/MyDrive/datasets/aug_test.csv'\n",
        "# path3 = '/content/drive/MyDrive/datasets/test.csv'"
      ],
      "metadata": {
        "id": "PKsvtoZ-6QuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_train = pd.read_csv(path1)\n",
        "aug_test = pd.read_csv(path2)"
      ],
      "metadata": {
        "id": "J5EqTc526gg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(aug_train.shape, aug_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EoSDuOo0KqOc",
        "outputId": "85373edf-9c8f-469e-b2e9-ed3698be4fbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7014, 3) (1300, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aug_train.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B9y1jvk1wa-Y",
        "outputId": "71ac793f-bfdf-4470-d205-1d73c39ae4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   articleID                                               text  label\n",
              "0        235  সমকামীতা'র হার বেড়েছে চট্টগ্রামে। নানা কারণে ব...      0\n",
              "1      58271  ৭ রোহিঙ্গা ধরে পুলিশে দিলো জনতা। সাতক্ষীরা সদর...      1\n",
              "2        593  ['খালেদা জিয়ার শরীরে কামড় লেগে ঘা হয়েছে, তা...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-af8c2aaa-3492-4b60-87e3-fd65dfe66642\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>articleID</th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>235</td>\n",
              "      <td>সমকামীতা'র হার বেড়েছে চট্টগ্রামে। নানা কারণে ব...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>58271</td>\n",
              "      <td>৭ রোহিঙ্গা ধরে পুলিশে দিলো জনতা। সাতক্ষীরা সদর...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>593</td>\n",
              "      <td>['খালেদা জিয়ার শরীরে কামড় লেগে ঘা হয়েছে, তা...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af8c2aaa-3492-4b60-87e3-fd65dfe66642')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-af8c2aaa-3492-4b60-87e3-fd65dfe66642 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-af8c2aaa-3492-4b60-87e3-fd65dfe66642');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = aug_train[['text','label']]\n",
        "test_df = aug_test[['text','label']]"
      ],
      "metadata": {
        "id": "QcVAt3n0LFar"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "ycik9pTI6m26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89b0acaf-e42d-4d3a-f5da-8b22bd0868bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((7014, 2), (1300, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is necessary because model won't run if there are NAN values. Though Training set is clean, this is for double check\n",
        "final_df = final_df.dropna() \n",
        "final_df.label.value_counts()"
      ],
      "metadata": {
        "id": "Xw2nWrN06ufX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "078b3ad8-57f5-4f42-f661-c0d8a36834d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    3507\n",
              "1    3507\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "ae5rhzVm6ySx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e625796b-b6e6-4f68-a3c2-cccf725316cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  label\n",
              "0  সমকামীতা'র হার বেড়েছে চট্টগ্রামে। নানা কারণে ব...      0\n",
              "1  ৭ রোহিঙ্গা ধরে পুলিশে দিলো জনতা। সাতক্ষীরা সদর...      1\n",
              "2  ['খালেদা জিয়ার শরীরে কামড় লেগে ঘা হয়েছে, তা...      0\n",
              "3   নিউটনের গতিবিদ্যা হল যৌন নিপীড়নকারীদের আশ্রয...      0\n",
              "4  ['গালিগালাজ স্বাস্থ্যের জন্য ভালো! । স্কুল - ক...      0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-806a14d6-2640-471f-8007-98b464c19b79\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>সমকামীতা'র হার বেড়েছে চট্টগ্রামে। নানা কারণে ব...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>৭ রোহিঙ্গা ধরে পুলিশে দিলো জনতা। সাতক্ষীরা সদর...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['খালেদা জিয়ার শরীরে কামড় লেগে ঘা হয়েছে, তা...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>নিউটনের গতিবিদ্যা হল যৌন নিপীড়নকারীদের আশ্রয...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['গালিগালাজ স্বাস্থ্যের জন্য ভালো! । স্কুল - ক...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-806a14d6-2640-471f-8007-98b464c19b79')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-806a14d6-2640-471f-8007-98b464c19b79 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-806a14d6-2640-471f-8007-98b464c19b79');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#prerequisites for model train/test"
      ],
      "metadata": {
        "id": "1e8eKa460zXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertTokenizer, AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('DeadBeast/mbert-base-cased-finetuned-bengali-fakenews')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "bfe6318765d44e95a2b37e4d4c6dfa60",
            "512689cfef3e468db77a51681b621c4d",
            "dbd814fc81ab430b81005e2392fbf51a",
            "f78d45bf8dd549c3ba57ae04bd9dde33",
            "9e1fc86641824764ad529c14037eee68",
            "4f9ff978511440acaedd2b7ebafa871f",
            "205b9765468545b192495fb4f894d86b",
            "75e8ba8530d540b88214765f7adf43fa",
            "f4ef44610f0541a4a5771d472269e6f0",
            "defffe577c8f4997ba2cda14b0e22480",
            "de129d4ac26c4e4ebe8ac2d10be4cf15",
            "e511d96be9784294a8fcad8027311f89",
            "8882e325aa9745c98d17ff927e85cbc7",
            "a7e4dc31653b4d459472986d8702088d",
            "0d09d775f6ee4cbbbb08eb7a707dcfda",
            "b03ee12284bf414d8bf8dd216f88781e",
            "90223a89420e4d34aa3264ca803534eb",
            "5277975038634e019345b375643b0b48",
            "75daf333867c4c56b360c3be5a9ebc4d",
            "21b1c59f7ff24c8d8ee3819d6e9d6d50",
            "305b25d6348c4c348b7569abfb13e46b",
            "fcdc046a651b420fb1ab3153d46ecaa1",
            "b70b40eb242d4906bd12596cc515ff93",
            "256a166c1fed4eb28614f468a465d91a",
            "ece6730c44594b71bb7261a44d052262",
            "cbaf2ba647c64170a1c4bcfc7dee87ff",
            "235b13cebb12410e92bd7dba9c3caa8d",
            "6ae99c96684a4dcaa47fc524824391d0",
            "874a8b233bdd430a88c0f42c7cb70766",
            "2c36f663fa7c4b7aa68c46f316b1d496",
            "c6cfa1f387314260ace491cb5f291deb",
            "5fccf938c4e04f999ee1c04610a996b1",
            "36a784d7fc0f4974b344634addff9c9f",
            "48cd0820e3a94ea188048d4cba1eb8f6",
            "1636070547cf4219ba0e5e77e65b5813",
            "ebfea17a4e6a4bd3838f08725f9fde7e",
            "6cec83f5fdda4b28b4adf588e405c456",
            "8101ec2ceaf448d8a1353c7ef65c04c2",
            "0f1ec1465eaf40d7b17aae844e968fd9",
            "41d9a4326ff24b7fbe236df8e5e12f0b",
            "5ce0560d94844e8596e5d6919e2de0d3",
            "0ae57d6b94fe40e4b821fa381f6ef6ad",
            "f202f6c337184927b5b4eb50539643ca",
            "17733936ee194805aa7d126adebe9944"
          ]
        },
        "id": "3f-UgLMel4fl",
        "outputId": "911cb6cd-989a-40de-bfd6-975651d2faa6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/333 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfe6318765d44e95a2b37e4d4c6dfa60"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e511d96be9784294a8fcad8027311f89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b70b40eb242d4906bd12596cc515ff93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48cd0820e3a94ea188048d4cba1eb8f6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "WOaNQVs81VkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "fm6bcFR7syJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load the model you want to fine tune"
      ],
      "metadata": {
        "id": "643XRzsP1-lt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"DeadBeast/mbert-base-cased-finetuned-bengali-fakenews\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "187d5d0de9844cc5afc76c62762420b5",
            "34c13dd980914689912f2d2d1c08e897",
            "d69e7eeac2954e269c06c8b378ee7161",
            "51c71abf6b5942a39688b29ac43fff92",
            "c7af877b823f487a8549f206e10cb3d4",
            "afccc8ecb6ec4ced80ddaf9c03c563c1",
            "7fe1c000185b4463ace31270bf726e47",
            "2870cec7a9844a578fe5a7ca4b6ba9ed",
            "748bfc56087145eb981f4b408ec89007",
            "4a6d41d9b2714bc8b4bf645e6263ba67",
            "b7f906f507b544b4bab4a2798e1b1fd9",
            "41b26b104aea43df97d3a2172b37fd32",
            "05ac8c3f8fde4c08af32a219575ea874",
            "6c799f24c2c843929a3673275be3c1ce",
            "001ec51c0f9341c1a0ddd758ac576672",
            "6ed0dc3a56d941ba9256d394c2fd51dd",
            "eca3fb960c9e46428a6ed1efffe6a658",
            "5e78b46cec6642bea75e00e3e2422ae8",
            "deeffef927f04a4c94d2c5840caaead0",
            "2488ae6d1e5544ad83c4cffe13e6a371",
            "f34a7d412cb3468797a4ee13f3e82cd6",
            "8c430664377449079c08cfa4aa237cdc"
          ]
        },
        "outputId": "32310618-7ab5-47ef-87f6-44589418d455",
        "id": "S0onVsUf2f9D"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/850 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "187d5d0de9844cc5afc76c62762420b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/712M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41b26b104aea43df97d3a2172b37fd32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#All Test original model before fine-tune"
      ],
      "metadata": {
        "id": "AmpSmcQhHZwt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "6H5KhufNHZw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 1: aug_test\n"
      ],
      "metadata": {
        "id": "kiqQDieKHZw7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#test_df is loaded from load dataset section"
      ],
      "metadata": {
        "id": "zI0t6kMUHZw7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7624431-7463-489d-b05a-d625fc1bf914",
        "id": "9S4UF8h-HZw8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    650\n",
              "1    650\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b2a69d91-1a3d-45f2-de42-4a3c05d80e6b",
        "id": "pAFfG8O4HZw8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "1295  শতাব্দীর ‘পাগলামি’। বিনোদন ডেস্ক : ফুটপাতের ‍ও...      1\n",
              "1296  দিনাজপুরে ছাত্রদের ওপর পুলিশের গুলি, নিহত ১। স...      1\n",
              "1297  খুলনা উপকূলে সতকর্তা জারি। ফাইল ছবি ঘূর্ণিঝড় ত...      1\n",
              "1298  অবশেষে আইনজীবী পেলেন বাবু সোনার স্ত্রী ও প্রেম...      1\n",
              "1299  কোটার দাবিতে প্রতিবন্ধী শিক্ষার্থীরাও শাহবাগে।...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cbc82c15-675d-4b59-b676-ac5acfb91edd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1295</th>\n",
              "      <td>শতাব্দীর ‘পাগলামি’। বিনোদন ডেস্ক : ফুটপাতের ‍ও...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296</th>\n",
              "      <td>দিনাজপুরে ছাত্রদের ওপর পুলিশের গুলি, নিহত ১। স...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>খুলনা উপকূলে সতকর্তা জারি। ফাইল ছবি ঘূর্ণিঝড় ত...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>অবশেষে আইনজীবী পেলেন বাবু সোনার স্ত্রী ও প্রেম...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>কোটার দাবিতে প্রতিবন্ধী শিক্ষার্থীরাও শাহবাগে।...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cbc82c15-675d-4b59-b676-ac5acfb91edd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cbc82c15-675d-4b59-b676-ac5acfb91edd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cbc82c15-675d-4b59-b676-ac5acfb91edd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "thHMB3CRHZw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "umhOXPT7HZw9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "VkKMZsUSHZw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "_a5z3z73HZw-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c81521-8f27-4376-f602-051981d3dd91",
        "id": "z-wNiSmjHZw-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.10\n",
            "  Test Loss: 5.02\n",
            "  Test took: 0:00:45\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "id": "xvC7kTCOHZw_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca421c39-a297-468c-d089-031c4992154b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8574df5b-a1f5-44cd-d3d2-3918ad4d92ce",
        "id": "ysRgYjYeHZxA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.17      0.20      0.18       650\n",
            "           1       0.01      0.01      0.01       650\n",
            "\n",
            "    accuracy                           0.10      1300\n",
            "   macro avg       0.09      0.10      0.09      1300\n",
            "weighted avg       0.09      0.10      0.09      1300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "outputId": "96398ccd-38ea-4657-8714-579324b700f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygGmXLOcHZxA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.81183245127642\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "outputId": "d11dcf12-3979-4975-8c94-6e4602514dfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-oGckSbOHZxA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6339550295857989\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 2: original test dataset of 1200\n"
      ],
      "metadata": {
        "id": "IjzJQgLzHZxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path3 = '/content/drive/MyDrive/datasets/test.csv'\n",
        "# path3 = 'translated_test.csv'\n",
        "test_df = pd.read_csv(path3)"
      ],
      "metadata": {
        "id": "BCOxjZGAHZxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8073c04-b70c-4a79-e208-5d1e8aa34ed6",
        "id": "_nEuNXnwHZxB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4af8f7-7e16-4d3b-ffc2-7555e33da0bf",
        "id": "QgXT4dlmHZxB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9dc130e8-131c-4ba0-abfb-3ffc6b587d11\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9dc130e8-131c-4ba0-abfb-3ffc6b587d11')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9dc130e8-131c-4ba0-abfb-3ffc6b587d11 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9dc130e8-131c-4ba0-abfb-3ffc6b587d11');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "nyTiFdl3HZxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "WnESHOQxHZxC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "bC7btRmeHZxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "ISaxQKN0HZxD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05882fd-f797-4b86-b49d-080ff7ba5cec",
        "id": "hYwjIGOMHZxD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.11\n",
            "  Test Loss: 5.20\n",
            "  Test took: 0:00:43\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "id": "FX-i9_FnHZxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3bbddb73-6090-443b-bf3e-634a0430d8f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  134\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aad196f2-5578-4428-c146-7cc7e00470fb",
        "id": "RJ7OjSQBHZxE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.18      0.22      0.20       600\n",
            "           1       0.01      0.01      0.01       600\n",
            "\n",
            "    accuracy                           0.11      1200\n",
            "   macro avg       0.09      0.11      0.10      1200\n",
            "weighted avg       0.09      0.11      0.10      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "outputId": "ea30ed15-dc85-485f-864b-56ad8b798186",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cBXHxDWHZxE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.7943802451992836\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "outputId": "df92d059-b912-4ffa-9923-07ba10f70957",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nv3qnuMiHZxF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5746138888888889\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 3: translated_test\n"
      ],
      "metadata": {
        "id": "Kiva6152HZxF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path3 = '/content/drive/MyDrive/datasets/translated_test.csv'\n",
        "# path3 = 'translated_test.csv'\n",
        "test_df = pd.read_csv(path3)"
      ],
      "metadata": {
        "id": "0L65efcNHZxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63a53b0-5330-4289-ca8a-96924604086b",
        "id": "mZUNpgr6HZxF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2000\n",
              "1    2000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "651b21fa-2eaa-4a65-e5f5-e07da3490f18",
        "id": "ueTrWt1qHZxG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "3995  ব্রাহ্মণবাড়িয়ায় ওএমএসের ৩০০বস্তা চালসহ ট্রাক আ...      1\n",
              "3996  যুগ্ম-সচিব হলেন ১৫৪ কর্মকর্তা। উপসচিব পদমর্যাদ...      1\n",
              "3997  স্প্রিকল ছিল বিশ্বাসঘাতক ও ঘৃণ্য ব্যক্তি : পুত...      1\n",
              "3998  সাগরে ৩ দিন ভেসে থাকার পর ফিরে এলেন টোমি! ২৫ স...      1\n",
              "3999  চীনা মুদ্রার দর আরো ১০% পড়তে পারে। চীনের আমদান...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cbbc5ed-f45d-447f-ab75-d90fd16d7f9f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>ব্রাহ্মণবাড়িয়ায় ওএমএসের ৩০০বস্তা চালসহ ট্রাক আ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>যুগ্ম-সচিব হলেন ১৫৪ কর্মকর্তা। উপসচিব পদমর্যাদ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>স্প্রিকল ছিল বিশ্বাসঘাতক ও ঘৃণ্য ব্যক্তি : পুত...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>সাগরে ৩ দিন ভেসে থাকার পর ফিরে এলেন টোমি! ২৫ স...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>চীনা মুদ্রার দর আরো ১০% পড়তে পারে। চীনের আমদান...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cbbc5ed-f45d-447f-ab75-d90fd16d7f9f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cbbc5ed-f45d-447f-ab75-d90fd16d7f9f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cbbc5ed-f45d-447f-ab75-d90fd16d7f9f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "q_J6i42HHZxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "7TZQQCN9HZxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "1TWZc4muHZxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "ZjFzryG9HZxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "290b3249-53cd-4c29-8bf9-38a9e5a1bd63",
        "id": "dGDFWWz6HZxH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.34\n",
            "  Test Loss: 3.70\n",
            "  Test took: 0:02:21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "id": "a1UvbqcQHZxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f66450f2-3f22-4946-b2bf-56bad01f7c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  1357\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c6131e-5fc1-496d-baf9-5b0437b56625",
        "id": "qHDkBOfxHZxI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.67      0.50      2000\n",
            "           1       0.02      0.01      0.01      2000\n",
            "\n",
            "    accuracy                           0.34      4000\n",
            "   macro avg       0.21      0.34      0.26      4000\n",
            "weighted avg       0.21      0.34      0.26      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "outputId": "78064b25-9e88-4b3d-c8d3-eb9daa2ac792",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJs19LADHZxI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.4302221985110219\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "outputId": "117f72fa-4636-4717-a5c6-f775315e00c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAnuJGzeHZxJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5678365\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 4: custom fake\n"
      ],
      "metadata": {
        "id": "92mcGWDxHZxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/datasets/test_customfake.csv')\n",
        "# test_df = pd.read_csv('test_customfake.csv')"
      ],
      "metadata": {
        "id": "r3VtbQe-HZxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "348804a4-282e-4f30-9946-8c979cfbd777",
        "id": "TQk9IAkLHZxK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f449d883-77e5-49b7-cae1-6e1f54e29a9c",
        "id": "0X5tgUA9HZxK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    102\n",
              "1    102\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd16dc5b-103f-49c2-8538-1ae63d2f9671",
        "id": "yb572bknHZxK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  label\n",
              "199  বাবুগঞ্জে বৃদ্ধাকে পিটিয়ে হত্যার ঘটনায় গ্রেফতা...      1\n",
              "200  দূষণ কমাতেই লোডশেডিং। বেশ কিছুদিন ধরেই দেশে বে...      0\n",
              "201  পর্দায় চুমু খেতে খেতে ক্লান্ত নায়ক ইমরান হাসমি...      0\n",
              "202  ঢাবির ‘চ’ ইউনিটে পাসের হার ১৯.৪৫ শতাংশ। নিজস্ব...      1\n",
              "203  দৃষ্টিহীন তরুণীকে ধর্ষণ, পুড়িয়ে ফেলা হলো ভ্রূণ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-65d96ebf-da1d-4329-8af5-cf592aac30b0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>বাবুগঞ্জে বৃদ্ধাকে পিটিয়ে হত্যার ঘটনায় গ্রেফতা...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>দূষণ কমাতেই লোডশেডিং। বেশ কিছুদিন ধরেই দেশে বে...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>পর্দায় চুমু খেতে খেতে ক্লান্ত নায়ক ইমরান হাসমি...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>ঢাবির ‘চ’ ইউনিটে পাসের হার ১৯.৪৫ শতাংশ। নিজস্ব...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>দৃষ্টিহীন তরুণীকে ধর্ষণ, পুড়িয়ে ফেলা হলো ভ্রূণ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-65d96ebf-da1d-4329-8af5-cf592aac30b0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-65d96ebf-da1d-4329-8af5-cf592aac30b0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-65d96ebf-da1d-4329-8af5-cf592aac30b0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df = test_df[test_df['label']==0]\n",
        "# test_df.label.value_counts()"
      ],
      "metadata": {
        "id": "JIDW4F37HZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "Jl0A28uVHZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "-bNUbkTdHZxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piIPMlgjHZxM"
      },
      "source": [
        "We can see some of the results by the model here. Our model trains on half of the dataset and achieves around 0.80 in overall f1. Its likely that the model is trained longer it will achieve better performance. I might retrain it later on full data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "VJLzGjEeHZxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "Tk4W_Xx4HZxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0bbfbac-c063-4cf1-eddf-3004c7cce4fd",
        "id": "Elmbm2xjHZxN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.38\n",
            "  Test Loss: 3.77\n",
            "  Test took: 0:00:07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "outputId": "bd1de5ad-0d33-4764-fd38-60e392baa921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0v2Hue0HZxO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  77\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70e630cb-b87c-42d4-c112-1f29e3ade198",
        "id": "aF6goALGHZxP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.43      0.75      0.55       102\n",
            "           1       0.00      0.00      0.00       102\n",
            "\n",
            "    accuracy                           0.38       204\n",
            "   macro avg       0.22      0.38      0.27       204\n",
            "weighted avg       0.22      0.38      0.27       204\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "outputId": "b1e11c56-1c2c-477d-9d5e-fae9cd057958",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81hbqvYWHZxP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.37371754637596794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "id": "voSOTiJAHZxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c930df0-c3c6-428e-bfee-039a75e87053"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8758169934640523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL TRAINING 1 (augx2+fake|real data)"
      ],
      "metadata": {
        "id": "EhQIDJ6il66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "max_len_itr =0\n",
        "\n",
        "for i in range(len(final_df)):\n",
        "  sent = sent = final_df['text'][i]\n",
        "\n",
        "  # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "  input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "  # Update the maximum sentence length.\n",
        "  leng = len(input_ids)\n",
        "  if(leng>max_len):\n",
        "    max_len = leng\n",
        "    max_len_itr = i\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "print('sentence: ', final_df['text'][max_len_itr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjHYMxNtmCsS",
        "outputId": "0ebdc4c8-8b27-423d-cbbf-2577c81e0701"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  8218\n",
            "sentence:  [\"বদিবৃত্তান্ত : এক দশকে আবদুর রহমান বদির নানা ঘটনাবলি । বেশ কয়েক বছর ধরেই বাংলাদেশে সবচেয়ে ভয়াল মাদকের তালিকা ইয়াবা তার'বাবা'নামে এটি ছড়িয়ে পড়েছে দেশের বিভিন্ন স্তরে বিশেষ করে তরুণদের মাঝে । সারা দেশে ইয়াবার মূল যোগান আসে মুলত মায়ানমারের সীমান্তবর্তী বাংলাদেশের সর্বদক্ষিণের এলাকা টেকনাফ থেকে । আর ইয়াবার সাথে জড়িয়ে সবচেয়ে বেশি যে নামটা শোনা যায়, তিনি কক্সবাজার - ৪ আসন থেকে ২০০৮ এবং ২০১৪ দুই মেয়াদে সাংসদ হিসেবে দায়িত্ব পালন করা সাংসদ আবদুর রহমান ইউসুফ । নিঃসন্দেহে টেকনাফ - উখিয়া এলাকার সবচেয়ে আলোচিত ও সমালোচিত মানুষ তিনি । একাধিকবার স্বরাষ্ট্র মন্ত্রণালয়সহ সরকারের একাধিক মাদক ব্যবসায়ীর তালিকার শীর্ষে এসেছে আবদুর রহমান বদির নাম । বদি এবং ইয়াবার এই যুগলবন্দী বুঝতে ক্যালেন্ডারের পাতা পিছনের দিকে উল্টাতে হবে প্রায় পঞ্চাশ বছর । যেতে হবে সত্তরের দশকে বদির বাবা এজাহার মিয়া কোম্পানির সময়ে । ১৬ ফেব্রুয়ারি, ২০১৭ তারিখে বাংলাদেশ প্রতিদিনে প্রকাশিত একটি খবরে জানা যায়, অক্ষরজ্ঞান না থাকলেও দীর্ঘদিন তিনি ছিলেন টেকনাফ অঞ্চলের রাজনীতির নিয়ন্ত্রক । সত্তরের দশক থেকেই স্বর্ণ চোরাচালানের সাথে জড়িত থাকার অভিযোগ ছিল তার বিরুদ্ধে । পাশাপাশি তার প্রকাশ্য ব্যবসা ছিল হোটেল ব্যবসা । জিয়াউর রহমানের শাসনামলে তিনি সক্রিয়ভাবে জড়িত হন বিএনপির রাজনীতিতে । পরে রাজনৈতিক পটপরিবর্তনে যুক্ত হন জাতীয় পার্টিতে যুক্ত হয়ে নির্বাচিত হন উপজেলা চেয়ারম্যান । পরে একাধিকবার নির্বাচিত হয়েছেন টেকনাফ সদর ইউনিয়নের চেয়ারম্যান হিসেবে । ২০১৬ সালের ৩ নভেম্বর দৈনিক সমকালে প্রকাশিত একটি খবর থেকে আরও জানা যায়, তখন থেকেই বাবার প্রভাবেই প্রভাবশালী পদে উঠতে থাকেন আবদুর রহমান বদি । ১৯৮৮ সালে চোরাই পণ্যবাহী একটি ট্রাক আটকে রাখার'অপরাধে'এক শুল্ক কর্মকর্তাকে মারধর করার অভিযোগ আসে তরুণ বদির উপর । মামলাও হয় । কিন্তু সাক্ষীর রহস্যজনক মৃত্যুতে মামলাটি খুব বেশিদূর গড়ায়নি । ১৯৯২ সালে বদি ও সঙ্গে বাবার বিরুদ্ধে কাস্টমস অফিস লুটের অভিযোগ উঠলেও মামলা হয়নি কোনো । রাজনীতিতে বদির আগমন ১৯৯৬ সালের জাতীয় নির্বাচনে । ফেব্রুয়ারির নির্বাচনে অনেক চেষ্টা করেও বিএনপির মনোনয়ন পাননি । তারপর ওই বছরেরই চৈত্র মাসের নির্বাচনে বিএনপির মনোনয়ন পান তিনি । তবে সিনিয়র নেতাদের হস্তক্ষেপে তার মনোনয়ন ফিরিয়ে নেওয়া হয় । তবে এক সময় বদি যোগ দেন আওয়ামী লীগে । ২০০১ এর জাতীয় নির্বাচনে মনোনয়ন না পেলেও বদি ছিলেন আওয়ামী পক্ষে আর বাবা এজাহার মিয়া ছিলেন বিএনপির সমর্থক হিসেবে । অর্থাৎ দুই দিকেই পারবারিক সাম্য বজায় ছিল । ২০০২ সালে বদি টেকনাফ পৌরসভার চেয়ারম্যান নির্বাচিত হন । তারপর থেকেই তার বিরুদ্ধে হত্যা, ধর্ষণ, দুর্নীতির অভিযোগ আসতে থাকে । ২০০৭ সালের তত্ত্বাবধায়ক সরকারের আমলেও তার বিরুদ্ধে দুই ডজন মামলা হয় । এরপর ২০০৮ সালের জাতীয় নির্বাচনে আওয়ামী লীগের ব্যানারে সাংসদ প্রার্থী হন আবদুর রহমান বদি । সেই সময় থেকে কখনোই আর আলোচনার বাইরে যেতে হয়নি তাকে । চলুন দেখে নিই নির্বাচিত সাংসদ হবার পর থেকে বদি কখন কীভাবে কোন খবরে আলোচনায় এসেছেন... # সাংসদ বদির ওপর নাখোশ ট্রাকমালিকরা২৯ মে, ২০১০ ( বিডিনিউজ ) সরকারদলীয় সাংসদ আবদুর রহমান বদির'সিন্ডিকেট বাণিজ্য ', ট্রাকশ্রমিকদের ওপর নির্যাতন ও চাঁদা আদায়ের কারণে স্থানীয় ট্রাকমালিকরা বন্দর থেকে পণ্য বহনকারি পাঁচশরও বেশি ট্রাক প্রত্যাহার করে নেন । # নির্বাচনী কর্মকর্তাকে মারধর সাংসদ বদির বিরুদ্ধে মামলার সিদ্ধান্ত৩১ জানুয়ারি, ২০১১ ( বিডিনিউজ ) সাংসদ আবদুর রহমান বদি ২০১১ সালের ১৫ জানুয়ারি টেকনাফে তার চাচা পৌর নির্বাচনের মেয়র প্রার্থী মোহাম্মদ ইসলামের জনসভায় অংশ নেন । বদির বিরুদ্ধে অভিযোগ ছিল ঘটনাস্থলে নির্বাহী ম্যাজিস্ট্রেট উপস্থিত হলে বদি তাকে মারধর করেন । # উখিয়া - টেকনাফের সাংসদ বদির বিরুদ্ধে মামলা১২ এপ্রিল, ২০১১ ( বিডিনিউজ ) টেকনাফে নির্বাহী ম্যাজিস্ট্রেটকে মারধরের অভিযোগে সরকার দলীয় সাংসদ আবদুর রহমান বদির বিরুদ্ধে মামলা হয় । # দুর্নীতি প্রমাণ হলে পদ ছেড়ে দেব : বদি ১৬ ফেব্রুয়ারি, ২০১৪ ( প্রথম আলো ) দুর্নীতির সব অভিযোগ অস্বীকার করে তিনি বলেন,'আমি দুর্নীতি করেছি বা একটি টাকা বিদেশে পাঠিয়েছি বা একটি পয়সা অবৈধ পথে আয় করেছি কিংবা মাদক ব্যবসা করেছি বা আমার বিরুদ্ধে করা একটি অভিযোগও প্রমাণিত হলে আমি সংসদ সদস্যপদ ছেড়ে দিয়ে সাধারণ জনগণের কাতারে দাঁড়াব ।'বদি বলেন,'প্রায় সাড়ে তিন কোটি টাকা আয়কর দিয়েছি আমি । গত দুই অর্থবছরে সেরা করদাতা হিসেবে আমি কক্সবাজারে পরিচিত । কর - বহির্ভূত একটি টাকাও কোথাও নেই । কোনো কালোটাকাও সাদা করি নাই ।'হলফনামা প্রদর্শন করে তিনি বলেন,'সব মিলিয়ে আমার মোট মূলধন ৯ কোটি ৫২ লাখ ৫৫ হাজার টাকা । এর বাইরে কোথাও একটি টাকা নেই । বিদেশেও আমি কোনো টাকা পাঠাই নাই ।'দুদক জিজ্ঞাসাবাদের বিষয়ে তিনি বলেন,'দুদক আমাকে ডেকেছে । আমি দুদককে স্যালুট দেই । এটি তদন্তাধীন বিষয় । এ নিয়ে কথা বলা ঠিক হবে না । গণমাধ্যমের বিভিন্ন অপপ্রচার নিয়ে আমাকে আমার সপক্ষে যুক্তি দেখাতে বলা হয়েছে । আমি দিয়েছি ।'মিডিয়ার বিরুদ্ধে অপপ্রচারের অভিযোগ তুলে বদি বলেন,'ইতিমধ্যে কক্সবাজারের বেশ কজন সাংবাদিকের বিরুদ্ধে মামলা করেছি । এসব সাংবাদিক আমার চরিত্র হনন করার উদ্দেশ্যে মিথ্যা প্রচারণা চালিয়েছে । কই আমার নাকি ৩৬ কোটি টাকা আছে । এনে দেন আমাকে ওই টাকা ।'# ইয়াবা ব্যবসায়ী তালিকার শীর্ষে বদি৯ ডিসেম্বর, ২০১৪ ( প্রথম আলো ) ২০১৪ সালে করা মাদকদ্রব্য নিয়ন্ত্রণ অধিদপ্তরের ৭৬৪ জন ইয়াবা ব্যবসায়ীর তালিকায় এক নম্বরে ছিলেন সাংসদ আবদুর রহমান বদি । মন্তব্য কলামে বলা হয়েছিল,'তাঁর ছত্রচ্ছায়ায় কিছু ব্যক্তিবর্গ ইয়াবা ব্যবসায় জড়িত ।'২০১৪ সালের ২৩ জানুয়ারি তালিকাটি তৈরি করেছিল অধিদপ্তরের অপারেশন ও গোয়েন্দা বিভাগ । # আয়কর বিভাগ থেকে সাংসদ বদি ও ইয়াবা ব্যবসায়ীকে সম্মাননা১৭ সেপ্টেম্বর, ২০১৪ ( প্রথম আলো ) সম্পদের তথ্য গোপনের অভিযোগে কক্সবাজার - ৪ আসনের সাংসদ আবদুর রহমান বদির বিরুদ্ধে মামলা করে দুদক । ওই মামলা নিষ্পত্তি হওয়ার আগেই আয়কর বিভাগ থেকে কক্সবাজার জেলার সর্বোচ্চ করদাতার সম্মাননা পেয়েছিলেন তিনি । একইভাবে স্বরাষ্ট্র মন্ত্রণালয়ের তৈরি করা ইয়াবা ব্যবসায়ীর তালিকার শীর্ষে থাকা কক্সবাজারের টেকনাফের আবদুস শুক্কুরও পেয়েছিলেন একই সম্মাননা । তিনি সাংসদ আবদুর রহমান বদির ছোট ভাই । # সম্পদের তথ্য গোপন মামলায় সাংসদ বদি কারাগারে১২ অক্টোবরে, ২০১৪ ( বিডিনিউজ ) সম্পদের তথ্য গোপনের মামলায় আত্মসমর্পণের পর কক্সবাজারের সাংসদ আবদুর রহমান বদিকে কারাগারে প্রেরণ করা হয় । # এমপি বদি কারামুক্ত৩০ অক্টোবর, ২০১৪ ( বিডিনিউজ ) দুর্নীতি দমন কমিশনের করা সম্পদের তথ্য গোপন সংক্রান্ত মামলায় উচ্চ আদালত থেকে জামিন পাওয়ার পর কারাগার থেকে ছাড়া পান কক্সবাজারের সংসদ সদস্য আব্দুর রহমান বদি । # ইয়াবা পাচার : বদির স্বজন গ্রেপ্তার১৩ ডিসেম্বর, ২০১৪ ( বিডিনিউজ ) ইয়াবা পাচারে জড়িত হিসেবে মাদক দ্রব্য নিয়ন্ত্রণ অধিদপ্তরের করা তালিকার তিন নম্বর ব্যক্তিকে মং মং সেনকে ( মমসী ) টেকনাফ থেকে পুলিশের হাতে গ্রেপ্তার হন । গ্রেপ্তার মং মং ওই এলাকার সংসদ সদস্য আবদুর রহমান বদির সৎ মায়ের বোনের ছেলে । # বদির ভাইয়ের বাড়ি থেকে রোহিঙ্গা আটক১৪ ডিসেম্বর, ২০১৪ ( বিডিনিউজ ) ইয়াবা পাচারকারী তালিকায় থাকা বদির দুই ভাই মো. শফিক ও মো. ফয়সালকে আটক করতে টেকনাফে তাদের বাড়িতে অভিযান চালায় পুলিশ । সেখানে শফিক ও ফয়সালকে না পাওয়া গেলেও বাড়িতে তল্লাশি চালিয়ে অবৈধভাবে অবস্থান করা মিয়ানমার নাগরিক মো. শামসুল আলমকে পাওয়া যায় । # তিন তালিকাতেই সাংসদ বদি১৮ জুন, ২০১৫ ( প্রথম আলো ) মানব পাচার, ইয়াবা ও রোহিঙ্গাদের বৈধকরণ - এই তিন অপরাধমূলক কর্মকাণ্ডে টালমাটাল পর্যটন শহর কক্সবাজার । সরকারের খাতায় এই তিন অপরাধেরই প্রধান পৃষ্ঠপোষক হিসেবে নাম এসেছে কক্সবাজার - ৪ আসনের ( উখিয়া - টেকনাফ ) সাংসদ আবদুর রহমান বদির । সঙ্গে ছিলেন তার ছয় ভাইসহ ২৬ জন কাছের ও দূরের আত্মীয় । স্বরাষ্ট্র মন্ত্রণালয়ের করা টেকনাফের শীর্ষ ৭৯ মানব পাচারকারীর তালিকায় সাংসদ বদির নাম ছিল ১ নম্বরে । ২০১৪ সালের সেপ্টেম্বর মাসে এই তালিকা করা হয় । একই বছরের ডিসেম্বরে পুলিশ সদর দপ্তরের নির্দেশে আরেকটি তদন্ত হয় । তাতে সাংসদের আট আত্মীয়কে মানব পাচারকারী হিসেবে চিহ্নিত করা হয় । এর আগে মাদকদ্রব্য নিয়ন্ত্রণ অধিদপ্তরের করা ইয়াবা চোরাচালানের সঙ্গে জড়িত ব্যক্তিদের তালিকায়ও সাংসদ বদিকে মাদকের মূল পৃষ্ঠপোষক বলা হয় । ওই তালিকায় তার ১৭ জন আত্মীয়ের নাম আছে । # প্রকৌশলীকে পেটালেন এমপি বদি১২ আগস্ট, ২০১৫ ( বিডিনিউজ ) উখিয়া উপজেলা পরিষদের সহকারী প্রকৌশলীকে মারধর ও গালাগালির অভিযোগ আসে বদির বিরুদ্ধে । # বদির ইয়াবা পাচারের প্রমাণ মেলেনি : স্বরাষ্ট্রমন্ত্রী৩ সেপ্টেম্বর, ২০১৫ ( বিডিনিউজ ) স্বরাষ্ট্র মন্ত্রণালয়ের অধীন মাদকদ্রব্য নিয়ন্ত্রণ অধিদপ্তরের তালিকায় ইয়াবা পাচারের হোতা হিসেবে আব্দুর রহমান বদির নাম এলেও স্বরাষ্ট্রমন্ত্রী আসাদুজ্জামান খান কামাল বলেছিলেন,'এই সংসদ সদস্যের বিরুদ্ধে এখনও কোনো প্রমাণ পাওয়া যায়নি ।'' অনেকের নাম আছে । অনেকে ইমোশনালি নাম দেয় যে এটা হতে পারে । এটা হতে পারে, বা হতে পারে না, তা তো তদন্তের বিষয় । তদন্তে প্রমাণ তো পেতে হবে,'তিনি আরও বলেন'অনেকের নামই আছে । কিন্তু তার ( বদি ) সংশ্লিষ্টতার প্রমাণ পাইনি ।'# দুর্নীতি মামলায় সাংসদ বদির বিচার শুরু৮ সেপ্টেম্বর, ২০১৫ ( বিডিনিউজ ) প্রায় ১১ কোটি টাকার সম্পদের তথ্য গোপনের মামলায় কক্সবাজারের আলোচিত সংসদ সদস্য আব্দুর রহমান বদির বিচার শুরুর আদেশ দেয় আদালত । # ইয়াবা নিয়ে চ্যালেঞ্জ দিলেন বদি২ জানুয়ারি, ২০১৬ ( এনটিভি অনলাইন ) এক সাক্ষাৎকারে আবদুর রহমান বদি ইয়াবার দোষ সাংবাদিকদের ঘাড়ে চাপিয়ে দেন । বদি বলেছিলেন,'ইয়াবা ১০ টাকা দামের আছে । ইয়াবা ১৫ টাকা দামের আছে, ইয়াবা ২০০ টাকা দামের আছে । ২০০ টাকা দামের ইয়াবাগুলো ধরা হলো, ১০ টাকা দামের ইয়াবাগুলো সাংবাদিকদের কাছে বিক্রি করা হলো । সাংবাদিকরা ভাইয়েরা এগুলো নিয়ে চিটাগাংয়ে বিক্রি করছেন । একটু খবর নেন । আমার কথা যদি মিথ্যা হয়! খবর নেন । আমি চ্যালেঞ্জ ঘোষণা করছি । কোনো ইয়াবা ব্যবসায়ীর সঙ্গে যদি কথা বলেছি, এক কাপ চা খেয়েছি, আমার মোবাইল নম্বর ট্র্যাকিং আছে, এ রকম যদি ট্র্যাকিং থাকে সেটা প্রমাণ করতে পারলে জাতীয় সংসদের পবিত্রতা রক্ষার্থে জনগণের কাতারে চলে আসব ।'# আমি সৎ, ব্যবসা করে খাই : এমপি বদি২৯ জুন, ২০১৬ ( বিডিনিউজ ) বদির বিরুদ্ধে করা দুদকের অবৈধ সম্পদ অর্জনের মামলার বিচারকাজ চলাকালে আদালতে দুর্নীতির অভিযোগ অস্বীকার করে বদি বলেন'আমি খেলাপিও না, জ্ঞাত আয়বহির্ভূত কোনো সম্পদও আমি অর্জন করিনি । আমি কোনো অন্যায় করিনি । আমি নির্দোষ ; সৎ ব্যবসায়ী, ব্যবসা করে জীবিকা নির্বাহ করি ।'# সৌদি নাগরিকের সঙ্গে'গোপন'বৈঠকে সাংসদ বদিও : বিজিবি৩১ জুলাই, ২০১৬ ( বিডিনিউজ ) কক্সবাজারের টেকনাফে আটক করা হয় দুই সৌদি নাগরিককে । বিজিবি জানায়, তাদের সঙ্গে বৈঠকে এক আরএসও নেতাসহ স্থানীয় সংসদ সদস্য আব্দুর রহমান বদিও উপস্থিত ছিলেন । # দুর্নীতির দায়ে সাংসদ বদির কারাদণ্ড২ নভেম্বর, ২০১৬ ( বিডিনিউজ ) সম্পদের তথ্য গোপনের অভিযোগে ২০১৪ সালে সাংসদ আবদুর রহমান বদির বিরুদ্ধে মামলা করে দুদক । সেই মামলায় বদিকে দুর্নীতির দায়ে তিন বছরের কারাদণ্ড এবং দশ লাখ টাকা জরিমানা করে আদালত । # সাংসদ বদি জামিনে মুক্ত২০ নভেম্বর, ২০১৬ ( বিডিনিউজ ) ১৮ দিন কারাবাসের পর মুক্তি পান সম্পদের তথ্য গোপনের মামলায় দণ্ডিত সংসদ সদস্য আবদুর রহমান বদি । # তুমি আর নমিনেশন পাচ্ছ না : বদিকে কাদের২ জুন, ২০১৭ ( বিডিনিউজ ) টেকনাফ - শাহপরীর দ্বীপ সড়ক দিয়ে ঘূর্ণিঝড় মোরায় ক্ষতিগ্রস্ত এলাকায় যাওয়ার সময় সড়ক পরিবহন ও সেতুমন্ত্রী ওবায়দুল কাদের সাংসদ বদিকে উদ্দেশ্য করে বলেন,'দুই দুইবার এমপি হইলা । কিন্তু এটুকু সামান্য ক্ষতিগ্রস্ত সড়ক ঠিক করতে পারলা না । জনগণের এই ভোগান্তির জন্য তোমার শিক্ষা পাওয়া উচিত । তোমাকে আগামীবার নমিনেশন দেওয়া হবে না ।'# আত্মসমর্পণ করে জামিন পেলেন সাংসদ বদি২০ মার্চ ২০১৭ ( বিডিনিউজ ) সম্পদের তথ্য গোপন বিষয়ে দুদকের করা একটি মামলায় আদালতে আত্মসমর্পণ করে জামিন নেন আব্দুর রহমান বদি । # ওবায়দুল কাদেরকে আপ্যায়নে বদি সেপ্টেম্বর, ২০১৭২০১৭ সালে মিয়ানমার থেকে কক্সবাজারে রোহিঙ্গা অনুপ্রবেশ শুরু হয় নতুন করে । সেপ্টেম্বরের শুরুতে সড়ক পরিবহন ও সেতুমন্ত্রী ওবায়দুল কাদের উখিয়ায় রোহিঙ্গা ক্যাম্প পরিদর্শনে গেলে তাকে আপ্যায়ন করেন স্থানীয় সাংসদ বদি । ওবায়দুল কাদেরকে মিষ্টিমুখ করাচ্ছেন বদি, এমন একটি ছবি তখন ভাইরাল হয় । এছাড়াও বদি মন্ত্রী এবং সাথের সবাইকে চা - ও খাওয়ান । # ইয়াবা ব্যবসা ঠেকাবেন বদি! ২৫ ডিসেম্বর, ২০১৭ ( প্রথম আলো )'সবাই জানেন, ইয়াবা আসছে টেকনাফ থেকে । তাহলে সেটা কেন বন্ধ করা যাচ্ছে না? এলাকার সাংসদই বা কী বলেন ।'বিজিবি সদর দপ্তরে আয়োজিত সীমান্ত সমস্যা ও সমাধান সম্পর্কিত মতবিনিময় সভায় দিনাজপুর - ২ আসনের সাংসদ ও আওয়ামী লীগের সাংগঠনিক সম্পাদক খালিদ মাহমুদ চৌধুরীর এই প্রশ্নের জবাবে টেকনাফের সাংসদ আবদুর রহমান বদি বলেন,'আমি নিজেও জানি না রিকশাচালক কী করে গাড়ি - বাড়ির মালিক হয়ে যাচ্ছে । আসলে ইয়াবা ব্যবসা করছে মিয়ানমার সেনাবাহিনী ও বৌদ্ধ নেতারা ।'# লিপস্টিক ছাড়া মেয়েদের পুরোপুরি সুন্দর দেখায় না : বদি৭ ফেব্রুয়ারি, ২০১৮ ( বিডিনিউজ ) কক্সবাজারের মেরিন ড্রাইভ টেকনাফের শাহপরীর দ্বীপ পর্যন্ত নিয়ে যাওয়ার প্রয়োজনীয়তা বোঝাতে আব্দুর রহমান বদি বলেন,'একটি মেয়ের ঠোঁটে যতক্ষণ পর্যন্ত লিপস্টিক থাকবে না, ততক্ষণ পর্যন্ত তাকে পরিপূর্ণ সুন্দর দেখা যাবে না ।'বদির এই বক্তব্য নিয়ে সংসদে বেশ সমালোচনাও হয় । # বদি গরিবের বন্ধু : ওবায়দুল কাদের১২ ফেব্রুয়ারি, ২০১৮ ( জাগোনিউজ ) উখিয়ায় উপজেলা আওয়ামী লীগ আয়োজিত একটি পথসভায় সড়ক পরিবহন ও সেতুমন্ত্রী ওবায়দুল কাদের বলেন, কক্সবাজার - ৪ ( উখিয়া - টেকনাফে ) আসনে বর্তমান সংসদ সদস্য আবদুর রহমান বদির কোনো বিকল্প নেই । বদি গরিবের বন্ধু । তাই আগামী নির্বাচনে বদিকে নৌকা মার্কায় ভোট দিয়ে জয়যুক্ত করুন । # মাদকে জড়িত মিডিয়া - প্রশাসনের কিছু লোক : বদি২২ মে, ২০১৮ ( প্রিয় ডট কম ) প্রিয় ডট কমকে দেওয়া একটি সাক্ষাৎকারে মিডিয়া ও প্রশাসনের কিছু লোক মাদক ব্যবসার সাথে জড়িত বলে অভিযোগ করেন বদি । তিনি আরও বলেন,'ইয়াবা একটা নেটওয়ার্ক । এই নেটওয়ার্কের মধ্যে কারও সাথে এমপি বদি কথা বলেছে, এ রকম কোনো তথ্য থাকলে প্রকাশ করেন ।'# ক্রসফায়ার আরও আগে হওয়া উচিত ছিল : এমপি বদি২২ মে, ১৮ ( বাংলা ট্রিবিউন ) বাংলা ট্রিবিউনকে দেওয়া একটি সাক্ষাৎকারে ২০১৮ সালে মাদকবিরোধী অভিযানে ক্রসফায়ার নিয়ে বদি বলেন,'ক্রসফায়ার আরও আগে শুরু হওয়া উচিত ছিল । মাদকের বিরুদ্ধে প্রধানমন্ত্রীর চ্যালেঞ্জ বাস্তবায়নে আইনশৃঙ্খলা বাহিনীর এ অভিযান অব্যাহত রাখতে হবে । এ জন্য আমাদের সবারই সহযোগিতা করা প্রয়োজন । যুব সমাজকে বাঁচাতে এটা অপরিহার্য ।'# নিহত'ইয়াবা কারবারিদের'মধ্যে এমপি বদির বেয়াই ২৫ মে, ২০১৮ ( বিডিনিউজ ) আইনশৃঙ্খলা বাহিনীর মাদকবিরোধী অভিযান চলাকালে পুলিশ কক্সবাজারে সন্দেহভাজন দুই ইয়াবা কারবারির লাশ উদ্ধার করেছিল । তাদের মধ্যে একজন ছিলেন সংসদ সদস্য আবদুর রহমান বদির বেয়াই আক্তার কামাল । # আমি অপরাধী হলে প্রমাণ থাকত : বদি২৫ মে, ২০১৮ ( সময়নিউজ ) সময় নিউজকে দেওয়া একটি সাক্ষাৎকারে ইয়াবা ব্যবসায়ীর তালিকার প্রথমেই তার নাম থাকা প্রসঙ্গে প্রশ্ন করা হলে বদি বলেন,'আমার বিরুদ্ধে একটা প্রমাণ আজ পর্যন্ত কোনো মিডিয়া আনতে পারেনি । আমি যদি সত্যিই অপরাধী হতাম তাহলে এতদিনে অনেক প্রমাণ থাকত । আপনারা নিজে এসে আমার নির্বাচনী এলাকা উখিয়া ও টেকনাফে দেখে যান, মানুষজনকে জিজ্ঞাসা করে যান যে, আসলেই আমি মাদক ব্যবসায়ী কিনা ।'এমপি বদির বেশ কয়েকজন নিকটাত্মীয় ইয়াবা ব্যবসার সঙ্গে জড়িত আছেন, এমন অভিযোগ প্রসঙ্গে বদি বলেন,'ধরেন আপনার নাম জরিনা, আপনার নামে যদি কোনো খারাপ মেয়ে ব্যবসা করে এবং তার বদলে যদি আপনাকে দোষারোপ করা হয় তাহলে আপনার কেমন লাগবে? একই নাম মিলে যাওয়ায় এই ভুল বোঝাবুঝির সৃষ্টি হয়েছে ।'# বদি যখন গায়কমে, ২০১৮২০১৮ সালের মাঝামাঝি আবদুর রহমান বদির নতুন পরিচয় সবার সামনে আসে । একটি অনুষ্ঠানে গান গাওয়ার ভিডিও ফেসবুকে ছড়িয়ে পড়ে ।'পর মানুষে দুঃখ দিলে দুঃখ মনে হয় না । আপন মানুষ দুঃখ দিলে মেনে নেওয়া যায় না ।'নামের একটি গান গেয়েছিলেন বদি । # মাদকবিরোধী অভিযান হঠাৎ শুরু করিনি : প্রধানমন্ত্রী৩০ মে, ২০১৮ ( প্রথম আলো ) ৩০ মে গণভবনে সংবাদ সম্মেলনে মাদকবিরোধী অভিযান নিয়ে করা সাংবাদিকদের প্রশ্নের জবাবে মাদক ব্যবসায়ীদের ব্যাপারে কঠোর হুঁশিয়ারি দেন প্রধানমন্ত্রী শেখ হাসিনা । এক সাংবাদিকের প্রশ্নের জবাবে প্রধানমন্ত্রী বলেন'গডফাদার বলতে আপনারা কাকে কাকে গডফাদার বলছেন, আমি সেটা জানি না । এটুকু বলতে পারি, কে গডফাদার, কে কী সেটা কিন্তু আমরা বিচার করছি না । যারা এর সঙ্গে জড়িত, দীর্ঘদিন থেকে গোয়েন্দা সংস্থা কাজ করেছে । যে কারা এর ভেতরে জড়িত । আমরা কিন্তু হঠাৎ করে যাইনি । যে - ই গডফাদার থাকুক, সে যে বাহিনীতেই থাকুক, কাউকে ছাড়া হচ্ছে না, হবে না । আমি যখন ধরি, ভালো করেই ধরি । ভালো করেই জানেন । কে কী, কার ভাই, কার চাচা, কার কে, ওটা কিন্তু দেখি না । এটা কিন্তু মাথায় রাইখেন ।'# সৌদি আরব গেছেন সাংসদ আবদুর রহমান বদি১ জুন, ২০১৮ ( প্রথম আলো ) ৩০ মে প্রধানমন্ত্রীর কঠোর হুঁশিয়ারির পরদিনই ৩১ মে রাতের ফ্লাইটে মাদক ব্যবসার সাথে জড়িত অভিযুক্ত আবদুর রহমান বদি সৌদি আরব চলে যান । অনেকেই ধারণা করেন, মাদক বিরোধী অভিযান থেকে বাঁচতেই বদি সৌদি আরব চলে যান । এর কয়েকদিন আগে তার কয়েকজন আত্মীয়ও দেশ ছাড়েন সৌদি আরবের উদ্দেশ্যে । অবশ্য বদির তরফ থেকে বলা হয়েছিল, তিনি এবং তার পরিবারের সদস্যরা ওমরাহ করতেই দেশ ছেড়েছেন । # মাদকের যথাযথ প্রমাণ পেলে বদিকেও ছাড়া হবে না : শিল্পমন্ত্রী আমির হোসেন আমু১৮ জুলাই, ২০১৮ ( বিডিনিউজ ) কক্সবাজারের সাংসদ আব্দুর রহমান বদিকে ইঙ্গিত করে তৎকালীন শিল্পমন্ত্রী আমির হোসেন আমু বলেন, মাদক সংশ্লিষ্টতার'যথাযথ প্রমাণ পেলে'তার বিরুদ্ধেও ব্যবস্থা নেওয়া হবে । # ইয়াবা তালিকায় আবার সাংসদ বদির নাম২০ অক্টোবর, ২০১৮ ( প্রথম আলো ) ২০১৮ সালে স্বরাষ্ট্র মন্ত্রণালয়ের করা ইয়াবা ব্যবসায়ীদের হালনাগাদ তালিকায় কক্সবাজারের ৭৩ জন প্রভাবশালী ইয়াবা কারবারির ( গডফাদার ) নাম উঠে আসে । তালিকার শীর্ষে আগের কয়েকটি তালিকার মতো এতেও ছিলেন কক্সবাজার - ৪ আসনের আওয়ামী লীগের বিতর্কিত সাংসদ আবদুর রহমান বদি । স্বরাষ্ট্র মন্ত্রণালয়ের আগের একাধিক তালিকার মতো এতেও সাংসদ বদির পাঁচ ভাই আবদুল শুক্কুর, আবদুল আমিন, মৌলভি মুজিবুর রহমান, মো. সফিক, মো. ফয়সাল, ভাগনে সাহেদুর রহমান নিপু ( ওসি আবদুর রহমানের ছেলে ), বেয়াই শাহেদ কামাল, ফুফাতো ভাই কামরুল হাসান রাসেলসহ ঘনিষ্ঠ আরও কয়েকজনের নাম ছিল । # যারা ভোট দেবেন না তাদের তালিকা চান বদি! ৩ ডিসেম্বর, ২০১৮ ( প্রথম আলো ) আবদুর রহমান বদি আওয়ামী লীগের মনোনয়ন না পেলেও একাদশ জাতীয় নির্বাচনে তার স্ত্রী মনোনয়ন পান । নির্বাচনী প্রচারণায় বদি তার সমর্থকদের উদ্দেশে বলেন, ১০ বছর ধরে তিনি এলাকার দরিদ্র লোকজনকে সহায়তা করছেন । এরপরও যারা তার স্ত্রী শাহীন আক্তারকে ভোট দেবেন না, তাদের তালিকা তাকে দিতে হবে । # ইয়াবার বিরুদ্ধে লড়ব : বদিকে পাশে রেখে বললেন স্ত্রী৩ জানুয়ারি, ২০১৯ ( বিডিনিউজ ) জাতীয় নির্বাচনে সাংসদ নির্বাচিত হবার পর সংসদ ভবনে শপথ অনুষ্ঠানের পর স্বামী বদিকে পাশে রেখেই সাংবাদিকদের প্রশ্নের উত্তরে শাহীন আক্তার বলেন,'মাদক, ইয়াবা ব্যবসাসহ সকল ধরনের অপকর্ম বন্ধ করতে যা যা করণীয়, আমি তাই করব ।'# ইয়াবা কারবারিদের আত্মসমর্পণের আহ্বান বদির১২ জানুয়ারি, ২০১৯ ( প্রথম আলো ) তালিকাভুক্ত ইয়াবা কারবারিদের আত্মসমর্পণ করার আহ্বান জানিয়ে সদ্য সাবেক হওয়া সাংসদ বদি বলেন,'ছেলেহারা মা - বাবা, স্বামীহারা স্ত্রী ও বাবাহারা সন্তানদের কথা চিন্তা করে আপনারা আত্মসমর্পণ করার জন্য প্রস্তুত থাকেন । সবাইকে মিলে টেকনাফের ইয়াবার বদনাম ঘোচাতে হবে । তালিকাভুক্ত ও তালিকার বাইরে যেসব ইয়াবা কারবারি আছেন, তাঁরা সবাই আত্মসমর্পণ করুন । এ ইয়াবা টেকনাফবাসীর জন্য অভিশাপ ।'# এবার আত্মসমর্পণের সমন্বয়ক বদি২৩ জানুয়ারি, ২০১৯ ( প্রথম আলো ) আত্মসমর্পণের আহ্বান জানিয়ে বদি নিজেই যেন হয়ে যান সমন্বয়ক । তার বিরুদ্ধে থাকা অভিযোগ আরও একবার অস্বীকার করে বলেন,'ইয়াবা সিন্ডিকেট মোটা টাকা ঢেলে প্রশাসনের বিভিন্ন তালিকায় অন্যায়ভাবে আমার নাম ঢুকিয়েছিল । আমি ইয়াবা ব্যবসা করি না । যাঁরা অপরাধী, তাঁরাই এখন আত্মসমর্পণ করবেন ।'বদির তিন ভাইসহ ১০ আত্মীয় পুলিশি হেফাজতে থাকা প্রসঙ্গে তিনি বলেন,'ভাই - বোন - ভাগনে যাদের নাম এসে পড়ছে, আমি বলছি তোমরা আইনের আশ্রয় নিয়ে যাও । জড়িত আছে কি নেই, সেটা এখন বলব না । আদালতে গিয়ে প্রমাণ করতে হবে । সবার সঙ্গে কথা বলেছি । পুলিশ ধরে... বাড়ি দিলেই তো সত্য কথা বলবে ।'# টেকনাফকে ইয়াবামুক্ত করতে দোয়া চান বদি২৬ জানুয়ারি, ২০১৯ ( বাংলা ট্রিবিউন ) টেকনাফে আয়োজিত একটি দোয়া মাহফিল সভায় অতিথির বক্তব্যে আবদুর রহমান বদি বলেন,'আজ আমরা শপথ নেবো টেকনাফকে ইয়াবামুক্ত করতে । আমি ইয়াবামুক্ত টেকনাফ করতে চায় । প্রশাসনকে সহযোগিতা করতে চায় । তবে আমার পক্ষে একা সহযোগিতা করা সম্ভব নয়, তাই সবাইকে সঙ্গে নিয়ে কাজ করতে চায় । আল্লাহর কাছে দোয়া করবেন যাতে উখিয়া - টেকনাফকে ইয়াবামুক্ত করতে পারি ।'পুরো ভাষণটি শুনতে - তথ্যসূত্র : প্রথম আলো, বিডিনিউজ টুয়েন্টিফোর, সময় নিউজ, প্রিয় ডট কম, জাগো নিউজ, সমকাল, বাংলা ট্রিবিউন, এনটিভি অনলাইন, বাংলাদেশ প্রতিদিন, পরিবর্তন ডট কম ।\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in final_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "Di5Ii3japzTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', final_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "PNLWYZP-oKns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0oUn0Olq_Or",
        "outputId": "3e242a4f-4638-44e4-f96d-348cd91086d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5,961 training samples\n",
            "1,053 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "0QLU1GDVrPqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "##this section HAS BEEN MOVED UP\n",
        "\n",
        "\n",
        "# # from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# # Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# # linear classification layer on top. \n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"Tahsin-Mayeesha/bangla-fake-news-mbert\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "#                     # You can increase this for multi-class tasks.   \n",
        "#     output_attentions = False, # Whether the model returns attentions weights.\n",
        "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# )\n",
        "\n",
        "# # Tell pytorch to run this model on the GPU.\n",
        "# model.cuda()"
      ],
      "metadata": {
        "id": "Q1TqBQ9Rr-Pt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "id": "DYFhvbHWsgG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "eNweRhQCsl00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0RmMrCAs5wL",
        "outputId": "95e8a419-5eeb-43be-a67d-636ebd575922"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:01:05.\n",
            "  Batch    80  of    373.    Elapsed: 0:02:09.\n",
            "  Batch   120  of    373.    Elapsed: 0:03:13.\n",
            "  Batch   160  of    373.    Elapsed: 0:04:17.\n",
            "  Batch   200  of    373.    Elapsed: 0:05:20.\n",
            "  Batch   240  of    373.    Elapsed: 0:06:25.\n",
            "  Batch   280  of    373.    Elapsed: 0:07:29.\n",
            "  Batch   320  of    373.    Elapsed: 0:08:33.\n",
            "  Batch   360  of    373.    Elapsed: 0:09:37.\n",
            "\n",
            "  Average training loss: 0.23\n",
            "  Training epcoh took: 0:09:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:01:04.\n",
            "  Batch    80  of    373.    Elapsed: 0:02:08.\n",
            "  Batch   120  of    373.    Elapsed: 0:03:12.\n",
            "  Batch   160  of    373.    Elapsed: 0:04:16.\n",
            "  Batch   200  of    373.    Elapsed: 0:05:20.\n",
            "  Batch   240  of    373.    Elapsed: 0:06:25.\n",
            "  Batch   280  of    373.    Elapsed: 0:07:29.\n",
            "  Batch   320  of    373.    Elapsed: 0:08:33.\n",
            "  Batch   360  of    373.    Elapsed: 0:09:37.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:09:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:01:04.\n",
            "  Batch    80  of    373.    Elapsed: 0:02:08.\n",
            "  Batch   120  of    373.    Elapsed: 0:03:12.\n",
            "  Batch   160  of    373.    Elapsed: 0:04:16.\n",
            "  Batch   200  of    373.    Elapsed: 0:05:20.\n",
            "  Batch   240  of    373.    Elapsed: 0:06:24.\n",
            "  Batch   280  of    373.    Elapsed: 0:07:28.\n",
            "  Batch   320  of    373.    Elapsed: 0:08:32.\n",
            "  Batch   360  of    373.    Elapsed: 0:09:36.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:09:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    373.    Elapsed: 0:01:04.\n",
            "  Batch    80  of    373.    Elapsed: 0:02:08.\n",
            "  Batch   120  of    373.    Elapsed: 0:03:12.\n",
            "  Batch   160  of    373.    Elapsed: 0:04:16.\n",
            "  Batch   200  of    373.    Elapsed: 0:05:20.\n",
            "  Batch   240  of    373.    Elapsed: 0:06:24.\n",
            "  Batch   280  of    373.    Elapsed: 0:07:28.\n",
            "  Batch   320  of    373.    Elapsed: 0:08:32.\n",
            "  Batch   360  of    373.    Elapsed: 0:09:37.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:09:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:37\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:42:16 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TM_fnfn : tahsin mayeesha finetune+finetune (first fine tuned with regular train, then model summarized train data)\n",
        "model.save_pretrained('/content/drive/MyDrive/saved_models/deadbeast-mbert_aug_fk_augx2_cbuet_para/') #aug-fk means trained with augmented data + fake data"
      ],
      "metadata": {
        "id": "CuZSUSwvyb-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model from saved\n"
      ],
      "metadata": {
        "id": "m1y2mQdbwGRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#don't run this cell if you aren't starting from here\n",
        "#loading models\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/saved_models/deadbeast-mbert_aug_fk_augx2_cbuet_para/\",\n",
        "    num_labels = 2\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model = loaded_model\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3267b9dc-dca5-466c-f39c-25a4a6247596",
        "id": "BUMXkhrU7hcq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#All Test your fine tuned model"
      ],
      "metadata": {
        "id": "9JAdHhQcy0sr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "dvu-iQtw0qqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 1: aug_test\n"
      ],
      "metadata": {
        "id": "oIvKVZNQGmI5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aug_test = pd.read_csv('/content/drive/MyDrive/datasets/aug_test.csv')\n",
        "test_df = aug_test[['text','label']]"
      ],
      "metadata": {
        "id": "ylK_ZYMCGmJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5b5bdaf-c414-4313-a365-c3fb1279663f",
        "id": "PDtmDBzgGmJH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    650\n",
              "1    650\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03646e04-7f42-43d1-baf5-6ff359e42a78",
        "id": "AegLChvSGmJI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "1295  শতাব্দীর ‘পাগলামি’। বিনোদন ডেস্ক : ফুটপাতের ‍ও...      1\n",
              "1296  দিনাজপুরে ছাত্রদের ওপর পুলিশের গুলি, নিহত ১। স...      1\n",
              "1297  খুলনা উপকূলে সতকর্তা জারি। ফাইল ছবি ঘূর্ণিঝড় ত...      1\n",
              "1298  অবশেষে আইনজীবী পেলেন বাবু সোনার স্ত্রী ও প্রেম...      1\n",
              "1299  কোটার দাবিতে প্রতিবন্ধী শিক্ষার্থীরাও শাহবাগে।...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c6ac32b4-0d7f-489e-aec3-c0bef0a65347\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1295</th>\n",
              "      <td>শতাব্দীর ‘পাগলামি’। বিনোদন ডেস্ক : ফুটপাতের ‍ও...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1296</th>\n",
              "      <td>দিনাজপুরে ছাত্রদের ওপর পুলিশের গুলি, নিহত ১। স...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1297</th>\n",
              "      <td>খুলনা উপকূলে সতকর্তা জারি। ফাইল ছবি ঘূর্ণিঝড় ত...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1298</th>\n",
              "      <td>অবশেষে আইনজীবী পেলেন বাবু সোনার স্ত্রী ও প্রেম...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1299</th>\n",
              "      <td>কোটার দাবিতে প্রতিবন্ধী শিক্ষার্থীরাও শাহবাগে।...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6ac32b4-0d7f-489e-aec3-c0bef0a65347')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6ac32b4-0d7f-489e-aec3-c0bef0a65347 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6ac32b4-0d7f-489e-aec3-c0bef0a65347');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "v6hVWPwIGmJI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "7XlVUP7aGmJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "fICEgEjTGmJJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "yejMzGp5GmJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9225a5c9-1b94-4e48-aebf-4bfe5db5ae49",
        "id": "0bVJpX6KGmJK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.98\n",
            "  Test Loss: 0.06\n",
            "  Test took: 0:00:46\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "id": "6JPiRLm-GmJN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4141c74d-1465-49ca-998d-6ab921efe601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  1280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ab44935-1743-4a71-d684-0f3b9e3b307e",
        "id": "wCEGST31GmJN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.98       650\n",
            "           1       0.99      0.98      0.98       650\n",
            "\n",
            "    accuracy                           0.98      1300\n",
            "   macro avg       0.98      0.98      0.98      1300\n",
            "weighted avg       0.98      0.98      0.98      1300\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "outputId": "2736ec90-213a-4994-cf93-e291a9c4df36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvlvIwXfGmJN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9692720645416034\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "outputId": "16b21665-49c6-4e2b-ae85-281a1bb9fd89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrFm-b-iGmJO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.44786745562130176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 2: original test dataset of 1200\n"
      ],
      "metadata": {
        "id": "jwqG3W2S0BpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path3 = '/content/drive/MyDrive/datasets/test.csv'\n",
        "# path3 = 'translated_test.csv'\n",
        "test_df = pd.read_csv(path3)"
      ],
      "metadata": {
        "id": "6WTPWnq_0Bpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "551598ac-3b3c-4540-f595-b4f47457f086",
        "id": "2heioadv0Bpk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b724ab9-1a41-4501-cfbf-8960efe6a67e",
        "id": "5fM1_5XG0Bpk"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bb485d5-178b-43fb-a200-ad594071472b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bb485d5-178b-43fb-a200-ad594071472b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bb485d5-178b-43fb-a200-ad594071472b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bb485d5-178b-43fb-a200-ad594071472b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "zlgGMVdW0Bpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "HCbICwEE0Bpl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "lS_4Wyv_0Bpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "Uujsvd0N0Bpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4807204e-710e-464f-83a6-bec32612b85f",
        "id": "_BF5V1HU0Bpn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.94\n",
            "  Test Loss: 0.33\n",
            "  Test took: 0:00:42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "id": "kZVkYYHZ4V12",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50901bf8-5f17-4e10-8387-3e2fc09b02f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  1132\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1654cd28-97c3-46e9-dacf-7d3d3dda9f42",
        "id": "5CJOm-6L0Bpo"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.95      0.94       600\n",
            "           1       0.95      0.93      0.94       600\n",
            "\n",
            "    accuracy                           0.94      1200\n",
            "   macro avg       0.94      0.94      0.94      1200\n",
            "weighted avg       0.94      0.94      0.94      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "outputId": "d56e563a-4f60-4eb9-8462-f82178e7564e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OL7OcX1v0Bpr"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8869081356413431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "outputId": "5a1ded0f-4a02-46d9-9b4c-6ba9c209c084",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXNDV8py0Bps"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.537986111111111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 3: translated_test\n"
      ],
      "metadata": {
        "id": "1WPqNQG5U05h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path3 = '/content/drive/MyDrive/datasets/translated_test.csv'\n",
        "# path3 = 'translated_test.csv'\n",
        "test_df = pd.read_csv(path3)"
      ],
      "metadata": {
        "id": "WfP8FxkHU05h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a94628f3-de44-4d51-eb48-429d8fa3bcf8",
        "id": "wLNcavRNU05i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2000\n",
              "1    2000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4555910f-5f66-4b57-f856-03654714d07c",
        "id": "6cRh2uPuU05i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                   text  label\n",
              "3995  ব্রাহ্মণবাড়িয়ায় ওএমএসের ৩০০বস্তা চালসহ ট্রাক আ...      1\n",
              "3996  যুগ্ম-সচিব হলেন ১৫৪ কর্মকর্তা। উপসচিব পদমর্যাদ...      1\n",
              "3997  স্প্রিকল ছিল বিশ্বাসঘাতক ও ঘৃণ্য ব্যক্তি : পুত...      1\n",
              "3998  সাগরে ৩ দিন ভেসে থাকার পর ফিরে এলেন টোমি! ২৫ স...      1\n",
              "3999  চীনা মুদ্রার দর আরো ১০% পড়তে পারে। চীনের আমদান...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-15e94c52-20c7-4f1b-8524-c86d635d5881\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>ব্রাহ্মণবাড়িয়ায় ওএমএসের ৩০০বস্তা চালসহ ট্রাক আ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>যুগ্ম-সচিব হলেন ১৫৪ কর্মকর্তা। উপসচিব পদমর্যাদ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>স্প্রিকল ছিল বিশ্বাসঘাতক ও ঘৃণ্য ব্যক্তি : পুত...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>সাগরে ৩ দিন ভেসে থাকার পর ফিরে এলেন টোমি! ২৫ স...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>চীনা মুদ্রার দর আরো ১০% পড়তে পারে। চীনের আমদান...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-15e94c52-20c7-4f1b-8524-c86d635d5881')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-15e94c52-20c7-4f1b-8524-c86d635d5881 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-15e94c52-20c7-4f1b-8524-c86d635d5881');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "_8PyGH2kU05j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "qg9t-ao_U05j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "eJF9GY5WU05m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "QtfFAGL9U05m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1d92ede-1ff7-4814-a194-56aebc449d35",
        "id": "RQJhAKg3U05m"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.89\n",
            "  Test Loss: 0.52\n",
            "  Test took: 0:02:21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "id": "8wnPtbKM4SW_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7913332-fa11-4a7e-a828-c40c07350cef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  3553\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c694e648-0e15-43d9-9ffb-a02ec4df1fcb",
        "id": "9aha998vU05n"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.80      0.88      2000\n",
            "           1       0.83      0.98      0.90      2000\n",
            "\n",
            "    accuracy                           0.89      4000\n",
            "   macro avg       0.90      0.89      0.89      4000\n",
            "weighted avg       0.90      0.89      0.89      4000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "id": "xUkVVWU2YisY",
        "outputId": "e6f60c7a-1e87-44a8-ff35-5a71c6d334f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.788599342621561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "id": "mmPS6OtTZFrX",
        "outputId": "229c50a7-0729-4245-ccae-1ba197bfe044",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.55929125\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing 4: custom fake\n"
      ],
      "metadata": {
        "id": "3YLLgVE9U05o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/datasets/test_customfake.csv')\n",
        "# test_df = pd.read_csv('test_customfake.csv')"
      ],
      "metadata": {
        "id": "Mx2ws4uzU05p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fac36684-4114-45e4-b29c-2e6e3f901cae",
        "id": "_5E0n5p_U05p"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(204, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 124
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5103e028-1816-4a65-fdfc-03adfc79dbfd",
        "id": "rtnwF_xkU05p"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    102\n",
              "1    102\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42288cb6-e89b-471c-ecfd-89b1c44908f2",
        "id": "_EIqNug6U05q"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  text  label\n",
              "199  বাবুগঞ্জে বৃদ্ধাকে পিটিয়ে হত্যার ঘটনায় গ্রেফতা...      1\n",
              "200  দূষণ কমাতেই লোডশেডিং। বেশ কিছুদিন ধরেই দেশে বে...      0\n",
              "201  পর্দায় চুমু খেতে খেতে ক্লান্ত নায়ক ইমরান হাসমি...      0\n",
              "202  ঢাবির ‘চ’ ইউনিটে পাসের হার ১৯.৪৫ শতাংশ। নিজস্ব...      1\n",
              "203  দৃষ্টিহীন তরুণীকে ধর্ষণ, পুড়িয়ে ফেলা হলো ভ্রূণ...      1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34c5e43f-daac-407a-9339-99d86a2a9cf3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>বাবুগঞ্জে বৃদ্ধাকে পিটিয়ে হত্যার ঘটনায় গ্রেফতা...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>দূষণ কমাতেই লোডশেডিং। বেশ কিছুদিন ধরেই দেশে বে...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>পর্দায় চুমু খেতে খেতে ক্লান্ত নায়ক ইমরান হাসমি...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>ঢাবির ‘চ’ ইউনিটে পাসের হার ১৯.৪৫ শতাংশ। নিজস্ব...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>দৃষ্টিহীন তরুণীকে ধর্ষণ, পুড়িয়ে ফেলা হলো ভ্রূণ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34c5e43f-daac-407a-9339-99d86a2a9cf3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34c5e43f-daac-407a-9339-99d86a2a9cf3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34c5e43f-daac-407a-9339-99d86a2a9cf3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test_df = test_df[test_df['label']==0]\n",
        "# test_df.label.value_counts()"
      ],
      "metadata": {
        "id": "ItoFrccbU05q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "2D0iW9SaU05q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "# print('Original: ', test_df['text'][0])\n",
        "# print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "id": "BERJz3QzU05q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "8KSbkjh1U05r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "Hvx91ZRyU05r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#changedhere\n",
        "model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "y_score = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        #changedhere\n",
        "        outputs = model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        y_sc, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_sc = torch.nn.functional.softmax(y_sc)\n",
        "        y_sc = y_sc.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        y_score.extend(y_sc)\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0488cc9-97d9-46e7-f3ad-2bf90185f6ed",
        "id": "Fl_uaUHJU05s"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.78\n",
            "  Test Loss: 1.20\n",
            "  Test took: 0:00:07\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#how many correct value did the model predict?\n",
        "cnt = 0\n",
        "for x in range(len(y_pred)):\n",
        "  if(y_true[x]==y_pred[x]):\n",
        "    cnt = cnt+1\n",
        "\n",
        "print('correct prediction: ',cnt)\n"
      ],
      "metadata": {
        "id": "w34GnXekujj2",
        "outputId": "53f45e14-0275-40a6-eae7-1054fd511396",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "correct prediction:  159\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cdef01c-b1b3-400c-a3d9-9731826f382a",
        "id": "n8kyWWFVU05t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.57      0.72       102\n",
            "           1       0.70      0.99      0.82       102\n",
            "\n",
            "    accuracy                           0.78       204\n",
            "   macro avg       0.84      0.78      0.77       204\n",
            "weighted avg       0.84      0.78      0.77       204\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(matthews_corrcoef(y_true, y_pred))"
      ],
      "metadata": {
        "id": "fRhpCizBVAxc",
        "outputId": "6f8092de-9067-4ef8-a532-fd2d5fb425fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6162612332901862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(roc_auc_score(y_true, y_score))"
      ],
      "metadata": {
        "id": "e8SQRiEu1PZd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b1d7828-454b-4f2d-c7a5-20e3a7c235a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7433679354094579\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "PVbzepNk5h-X",
        "SaUFAGkoOjw9",
        "NGquUlcjUKjK",
        "1e8eKa460zXB",
        "643XRzsP1-lt",
        "AmpSmcQhHZwt",
        "EhQIDJ6il66B",
        "m1y2mQdbwGRR"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bfe6318765d44e95a2b37e4d4c6dfa60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_512689cfef3e468db77a51681b621c4d",
              "IPY_MODEL_dbd814fc81ab430b81005e2392fbf51a",
              "IPY_MODEL_f78d45bf8dd549c3ba57ae04bd9dde33"
            ],
            "layout": "IPY_MODEL_9e1fc86641824764ad529c14037eee68"
          }
        },
        "512689cfef3e468db77a51681b621c4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f9ff978511440acaedd2b7ebafa871f",
            "placeholder": "​",
            "style": "IPY_MODEL_205b9765468545b192495fb4f894d86b",
            "value": "Downloading: 100%"
          }
        },
        "dbd814fc81ab430b81005e2392fbf51a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75e8ba8530d540b88214765f7adf43fa",
            "max": 333,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f4ef44610f0541a4a5771d472269e6f0",
            "value": 333
          }
        },
        "f78d45bf8dd549c3ba57ae04bd9dde33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_defffe577c8f4997ba2cda14b0e22480",
            "placeholder": "​",
            "style": "IPY_MODEL_de129d4ac26c4e4ebe8ac2d10be4cf15",
            "value": " 333/333 [00:00&lt;00:00, 5.35kB/s]"
          }
        },
        "9e1fc86641824764ad529c14037eee68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9ff978511440acaedd2b7ebafa871f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "205b9765468545b192495fb4f894d86b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75e8ba8530d540b88214765f7adf43fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ef44610f0541a4a5771d472269e6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "defffe577c8f4997ba2cda14b0e22480": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de129d4ac26c4e4ebe8ac2d10be4cf15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e511d96be9784294a8fcad8027311f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8882e325aa9745c98d17ff927e85cbc7",
              "IPY_MODEL_a7e4dc31653b4d459472986d8702088d",
              "IPY_MODEL_0d09d775f6ee4cbbbb08eb7a707dcfda"
            ],
            "layout": "IPY_MODEL_b03ee12284bf414d8bf8dd216f88781e"
          }
        },
        "8882e325aa9745c98d17ff927e85cbc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90223a89420e4d34aa3264ca803534eb",
            "placeholder": "​",
            "style": "IPY_MODEL_5277975038634e019345b375643b0b48",
            "value": "Downloading: 100%"
          }
        },
        "a7e4dc31653b4d459472986d8702088d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_75daf333867c4c56b360c3be5a9ebc4d",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_21b1c59f7ff24c8d8ee3819d6e9d6d50",
            "value": 995526
          }
        },
        "0d09d775f6ee4cbbbb08eb7a707dcfda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_305b25d6348c4c348b7569abfb13e46b",
            "placeholder": "​",
            "style": "IPY_MODEL_fcdc046a651b420fb1ab3153d46ecaa1",
            "value": " 996k/996k [00:01&lt;00:00, 712kB/s]"
          }
        },
        "b03ee12284bf414d8bf8dd216f88781e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90223a89420e4d34aa3264ca803534eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5277975038634e019345b375643b0b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75daf333867c4c56b360c3be5a9ebc4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21b1c59f7ff24c8d8ee3819d6e9d6d50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "305b25d6348c4c348b7569abfb13e46b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcdc046a651b420fb1ab3153d46ecaa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b70b40eb242d4906bd12596cc515ff93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_256a166c1fed4eb28614f468a465d91a",
              "IPY_MODEL_ece6730c44594b71bb7261a44d052262",
              "IPY_MODEL_cbaf2ba647c64170a1c4bcfc7dee87ff"
            ],
            "layout": "IPY_MODEL_235b13cebb12410e92bd7dba9c3caa8d"
          }
        },
        "256a166c1fed4eb28614f468a465d91a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ae99c96684a4dcaa47fc524824391d0",
            "placeholder": "​",
            "style": "IPY_MODEL_874a8b233bdd430a88c0f42c7cb70766",
            "value": "Downloading: 100%"
          }
        },
        "ece6730c44594b71bb7261a44d052262": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c36f663fa7c4b7aa68c46f316b1d496",
            "max": 1962014,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6cfa1f387314260ace491cb5f291deb",
            "value": 1962014
          }
        },
        "cbaf2ba647c64170a1c4bcfc7dee87ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5fccf938c4e04f999ee1c04610a996b1",
            "placeholder": "​",
            "style": "IPY_MODEL_36a784d7fc0f4974b344634addff9c9f",
            "value": " 1.96M/1.96M [00:01&lt;00:00, 2.09MB/s]"
          }
        },
        "235b13cebb12410e92bd7dba9c3caa8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ae99c96684a4dcaa47fc524824391d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "874a8b233bdd430a88c0f42c7cb70766": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2c36f663fa7c4b7aa68c46f316b1d496": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6cfa1f387314260ace491cb5f291deb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5fccf938c4e04f999ee1c04610a996b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36a784d7fc0f4974b344634addff9c9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48cd0820e3a94ea188048d4cba1eb8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1636070547cf4219ba0e5e77e65b5813",
              "IPY_MODEL_ebfea17a4e6a4bd3838f08725f9fde7e",
              "IPY_MODEL_6cec83f5fdda4b28b4adf588e405c456"
            ],
            "layout": "IPY_MODEL_8101ec2ceaf448d8a1353c7ef65c04c2"
          }
        },
        "1636070547cf4219ba0e5e77e65b5813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f1ec1465eaf40d7b17aae844e968fd9",
            "placeholder": "​",
            "style": "IPY_MODEL_41d9a4326ff24b7fbe236df8e5e12f0b",
            "value": "Downloading: 100%"
          }
        },
        "ebfea17a4e6a4bd3838f08725f9fde7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ce0560d94844e8596e5d6919e2de0d3",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0ae57d6b94fe40e4b821fa381f6ef6ad",
            "value": 112
          }
        },
        "6cec83f5fdda4b28b4adf588e405c456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f202f6c337184927b5b4eb50539643ca",
            "placeholder": "​",
            "style": "IPY_MODEL_17733936ee194805aa7d126adebe9944",
            "value": " 112/112 [00:00&lt;00:00, 2.16kB/s]"
          }
        },
        "8101ec2ceaf448d8a1353c7ef65c04c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0f1ec1465eaf40d7b17aae844e968fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41d9a4326ff24b7fbe236df8e5e12f0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ce0560d94844e8596e5d6919e2de0d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae57d6b94fe40e4b821fa381f6ef6ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f202f6c337184927b5b4eb50539643ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17733936ee194805aa7d126adebe9944": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "187d5d0de9844cc5afc76c62762420b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34c13dd980914689912f2d2d1c08e897",
              "IPY_MODEL_d69e7eeac2954e269c06c8b378ee7161",
              "IPY_MODEL_51c71abf6b5942a39688b29ac43fff92"
            ],
            "layout": "IPY_MODEL_c7af877b823f487a8549f206e10cb3d4"
          }
        },
        "34c13dd980914689912f2d2d1c08e897": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afccc8ecb6ec4ced80ddaf9c03c563c1",
            "placeholder": "​",
            "style": "IPY_MODEL_7fe1c000185b4463ace31270bf726e47",
            "value": "Downloading: 100%"
          }
        },
        "d69e7eeac2954e269c06c8b378ee7161": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2870cec7a9844a578fe5a7ca4b6ba9ed",
            "max": 850,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_748bfc56087145eb981f4b408ec89007",
            "value": 850
          }
        },
        "51c71abf6b5942a39688b29ac43fff92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a6d41d9b2714bc8b4bf645e6263ba67",
            "placeholder": "​",
            "style": "IPY_MODEL_b7f906f507b544b4bab4a2798e1b1fd9",
            "value": " 850/850 [00:00&lt;00:00, 60.1kB/s]"
          }
        },
        "c7af877b823f487a8549f206e10cb3d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afccc8ecb6ec4ced80ddaf9c03c563c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fe1c000185b4463ace31270bf726e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2870cec7a9844a578fe5a7ca4b6ba9ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748bfc56087145eb981f4b408ec89007": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a6d41d9b2714bc8b4bf645e6263ba67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7f906f507b544b4bab4a2798e1b1fd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41b26b104aea43df97d3a2172b37fd32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_05ac8c3f8fde4c08af32a219575ea874",
              "IPY_MODEL_6c799f24c2c843929a3673275be3c1ce",
              "IPY_MODEL_001ec51c0f9341c1a0ddd758ac576672"
            ],
            "layout": "IPY_MODEL_6ed0dc3a56d941ba9256d394c2fd51dd"
          }
        },
        "05ac8c3f8fde4c08af32a219575ea874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eca3fb960c9e46428a6ed1efffe6a658",
            "placeholder": "​",
            "style": "IPY_MODEL_5e78b46cec6642bea75e00e3e2422ae8",
            "value": "Downloading: 100%"
          }
        },
        "6c799f24c2c843929a3673275be3c1ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deeffef927f04a4c94d2c5840caaead0",
            "max": 711504045,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2488ae6d1e5544ad83c4cffe13e6a371",
            "value": 711504045
          }
        },
        "001ec51c0f9341c1a0ddd758ac576672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f34a7d412cb3468797a4ee13f3e82cd6",
            "placeholder": "​",
            "style": "IPY_MODEL_8c430664377449079c08cfa4aa237cdc",
            "value": " 712M/712M [00:57&lt;00:00, 8.40MB/s]"
          }
        },
        "6ed0dc3a56d941ba9256d394c2fd51dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca3fb960c9e46428a6ed1efffe6a658": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e78b46cec6642bea75e00e3e2422ae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "deeffef927f04a4c94d2c5840caaead0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2488ae6d1e5544ad83c4cffe13e6a371": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f34a7d412cb3468797a4ee13f3e82cd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c430664377449079c08cfa4aa237cdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}