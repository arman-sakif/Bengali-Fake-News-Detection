{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Pips"
      ],
      "metadata": {
        "id": "PVbzepNk5h-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOq7B_40lDK9",
        "outputId": "6020843e-84b1-4b4e-f3f8-a09f0b23094a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLXleXuvNmOV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Ni-8Uqswow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24d63a39-b67e-455a-adc2-f0ea71592746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaUFAGkoOjw9"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeHFP-aKe8yS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEtV-2-RNpO5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQJ_1ZHyvhne"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import *\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "#note: importing something 2nd time does not cause any performance loss \n"
      ],
      "metadata": {
        "id": "spCh2Lun43Td"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load Datasets"
      ],
      "metadata": {
        "id": "PeSKEGgL6RaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = '/content/drive/MyDrive/datasets/train.csv'\n",
        "path2 = '/content/drive/MyDrive/datasets/modelsum_train.csv'\n",
        "path3 = '/content/drive/MyDrive/datasets/test.csv'"
      ],
      "metadata": {
        "id": "PKsvtoZ-6QuU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df = pd.read_csv(path1)\n",
        "test_df = pd.read_csv(path3)"
      ],
      "metadata": {
        "id": "J5EqTc526gg2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape, test_df.shape"
      ],
      "metadata": {
        "id": "ycik9pTI6m26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28cdd1f4-5295-4a19-affc-73780e621508"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10016, 2), (1200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#this is necessary because model won't run if there are NAN values. Though Training set is clean, this is for double check\n",
        "final_df = final_df.dropna() \n",
        "final_df.label.value_counts()"
      ],
      "metadata": {
        "id": "Xw2nWrN06ufX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7a90544-bab4-41cd-f3e8-fcd3296eb627"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5008\n",
              "0    5008\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.label.value_counts()"
      ],
      "metadata": {
        "id": "FJ8u5GuJ6qiD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b926424c-5f7a-4943-9351-84d0f75f25b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5008\n",
              "0    5008\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.head()"
      ],
      "metadata": {
        "id": "ae5rhzVm6ySx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf264505-53c2-4edc-c59c-40c99f94707e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      1  হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শো...\n",
              "1      1  মালয়েশিয়ায় কর্মী পাঠানোর ব্যবস্থা নেয়ার সুপারি...\n",
              "2      1  প্রেমের প্রস্তাবে রাজি না হওয়ায় স্কুলছাত্রীকে ...\n",
              "3      1  মেডিয়েশনই মামলাজট নিরসনের পথ : বিচারপতি আহমেদ ...\n",
              "4      1  টকশোতে বক্তব্য দিতে গিয়ে জাপা নেতার মৃত্যুমাদা..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ff27d156-9575-459e-8e78-7387fcda6a0d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শো...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>মালয়েশিয়ায় কর্মী পাঠানোর ব্যবস্থা নেয়ার সুপারি...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>প্রেমের প্রস্তাবে রাজি না হওয়ায় স্কুলছাত্রীকে ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>মেডিয়েশনই মামলাজট নিরসনের পথ : বিচারপতি আহমেদ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>টকশোতে বক্তব্য দিতে গিয়ে জাপা নেতার মৃত্যুমাদা...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ff27d156-9575-459e-8e78-7387fcda6a0d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ff27d156-9575-459e-8e78-7387fcda6a0d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ff27d156-9575-459e-8e78-7387fcda6a0d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#prerequisites for model train/test"
      ],
      "metadata": {
        "id": "1e8eKa460zXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertTokenizer, AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('csebuetnlp/banglabert')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3bc2f42755e43b8addd126db7ac8573",
            "0968be02156441c98ccf60e028e7b6eb",
            "65a363ffc8da4af2936e6074d8c99918",
            "085f736599194a9a947ce31301482253",
            "027d9b1021af4b33bf394fb4ccdc5aad",
            "94b5e2e0692f4ba881891cefcb846a4d",
            "d0d778b77906414a833617e28959bf4a",
            "e8fa4d2861eb42319af1883e9c347b6d",
            "e65b59a9389d4adabb8a5caad0e9a9f0",
            "a2db8cb2415741328a77da14ffc16884",
            "c2ae663cfd8841ad935e35e9b8a9c360",
            "51a2514a62bb4dba8a5c0b7c540f0bae",
            "6034aac1e738498fb47a81209e8188a8",
            "d35216bcbc4f45fe8b2a640af685b5d8",
            "4754ffbeaaa94223aba3a4d184cd8114",
            "ddad42fb0e5641b1a9061412327e19ee",
            "71287fb2ead540e3bb63760c1af5364f",
            "79f428ec0a154105a0b78c71506e1246",
            "bc9876037eef4bf2b2a9808587d9b922",
            "7f1bd4a479ce46608ea7c91e4a7b3932",
            "fd20d71fe0ff416ca25178daf56a2f91",
            "bad96de964164378ab9e6009a1c47765",
            "82b876a871f94638b39c249019cf0b42",
            "8484962a482a4e65ba992d048b743957",
            "59c6fc4013bf43abac6bd660fa99bd5c",
            "cd04ad4207344931b299085ac2b97010",
            "5a7d3903965a4514a76dbd67c11c7dea",
            "f55487bb3fed4a46b601a2b3be838968",
            "99a975912d584c71bce1d8b13cca9f52",
            "2f1f1937a3f34ace8f892e89a6e64e05",
            "ea8763a67dcd42f8a10a54d8e1066417",
            "f5918c008e4f4e4091e6e6482a977814",
            "355d879e18d24e9ab90a60c51ea59d62",
            "e0cb278e85af450fa4a294a07a2d12c1",
            "d3e237441683473ab5f94f94ee0147a8",
            "d5b86415119e489a8e8576e4e6034f32",
            "55c8379f1b4147d69dc6eca7bc1b8462",
            "9d1b155f53df4b9db376f578a021dd26",
            "478da4110a15429e97141cb65c735131",
            "49411b4d82df440b9176df393e02b440",
            "5a986a0216044e41923ce7cc8853c8d5",
            "512f5bf7fdcc4853a5e6f5ef1fd2a0e1",
            "4d05c1d207594c24840a5aaa931cb544",
            "31b5f253cff442748bdb559a542276c0"
          ]
        },
        "id": "3f-UgLMel4fl",
        "outputId": "515e4dda-9aed-4778-a6f3-1dccf6610f35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/119 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3bc2f42755e43b8addd126db7ac8573"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/586 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "51a2514a62bb4dba8a5c0b7c540f0bae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/528k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "82b876a871f94638b39c249019cf0b42"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e0cb278e85af450fa4a294a07a2d12c1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
            "Model config ElectraConfig {\n",
            "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"electra\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "metadata": {
        "id": "WOaNQVs81VkV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import time\n",
        "# import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "metadata": {
        "id": "fm6bcFR7syJH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL TRAINING 1 (train data)"
      ],
      "metadata": {
        "id": "EhQIDJ6il66B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = 0\n",
        "max_len_itr =0\n",
        "\n",
        "for i in range(len(final_df)):\n",
        "  sent = sent = final_df['text'][i]\n",
        "\n",
        "  # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "  input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "  # Update the maximum sentence length.\n",
        "  leng = len(input_ids)\n",
        "  if(leng>max_len):\n",
        "    max_len = leng\n",
        "    max_len_itr = i\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "print('sentence: ', final_df['text'][max_len_itr])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjHYMxNtmCsS",
        "outputId": "b1d9631d-fb00-4805-e7ee-1eef7003e5c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  8345\n",
            "sentence:  আমেরিকা বিরোধী জর্জ সরস ট্রাম্পের বিরুদ্ধে এনএফএল দিয়ে অস্ত্র আটক করেছেআমরা এইমাত্র এনএফএলকে সমর্থন না করার আরেকটি কারণ আবিষ্কার করলাম যে ব্যক্তিটি সবচেয়ে এন্টি-আমেরিকান, যাকে আমরা জানি সে এখন ন্যাশনাল ফুটবল লীগ প্লেয়ারস অ্যাসোসিয়েশন (এনএফএলপিএ)-এর সাথে যুক্ত। এনএফএলপিএ সম্প্রতি আর্থিক ভাবে এমন এক সত্যকে সমর্থন করেছে যে দূর-বাম সংগঠনের তালিকা তৈরি করেছে, প্লানড প্যারেন্টহুড থেকে শুরু করে অবৈধ অভিবাসীদের বিতাড়নের প্রতিবাদে সংগঠন, যাদের মধ্যে অনেকের ঘটনা রয়েছে।এই ধরনের একজন ব্যক্তি ওপেন সোসাইটি ফাউন্ডেশন ছাড়া আর কেউ নন, যার প্রধান কোটিপতি জর্জ সোরস.২য় ভোট পেয়েছেন এনএফএলপিএ সোরোস সেন্টার ফর কমিউনিটি চেঞ্জ এ্যাকশন নামক প্রতিষ্ঠানের সামাজিক ন্যায়বিচার শাখাকে আর্থিক সহায়তা প্রদান করছে। ওয়াশিংটন ফ্রি বিকন-এর মতে এই প্রতিষ্ঠানটি নভেম্বরের আগে এবং পরে প্রেসিডেন্ট ডোনাল্ড ট্রাম্প এবং রিপাবলিকানদের বিরুদ্ধে সরাসরি ব্যবস্থা গ্রহণ করেছে।এনএফএলপিএ কমপক্ষে ২০১৩ সালের দিকে ডেটিং করে বেশ কয়েকটি সুদূরপ্রসারী এবং বিরোধী-ট্রাম্প কারণ দান করছে। মার্কিন যুক্তরাষ্ট্রে সর্বাধিক মৌলিক এবং দূর-বাম কারণগুলির কয়েকটি তহবিলের একটি দীর্ঘ ইতিহাস রয়েছে। তিনি ২০১২ সালের ওয়াল স্ট্রিট দখল প্রতিবাদকে সমর্থন করেছেন বলে জানা যায়, ন্যাশনাল রিসোর্স ডিফেন্স কাউন্সিল, একটি ট্রাম বিরোধী পরিবেশবাদী সংগঠন, পরিকল্পিত প্যারেন্টহুড সহ গর্ভপাত-পন্থী আন্দোলন এবং অসংখ্য অ্যান্টি-ট্রাম্প প্রতিরোধের কারণও রয়েছে। সোরোস ওয়াশিংটনের উইমেনস মার্চের মূল অংশীদারদের অন্তত ৫৬ টি তহবিল দিয়েছে, যা ট্রাম্পের উদ্বোধনের পরের দিন ঘটেছিল। আরেকটি মাঠপর্যায়ের স্বত:স্ফূর্ত অভিযানের জন্য তহবিল গঠন করা হয়েছে, এবং এটি আরও স্বতঃস্ফূর্তভাবে পরিচালিত হবে।এই ১৮৭টি সংস্থা সরাসরি জর্জ সোরোসের অর্থায়নে পরিচালিত এই তালিকার কয়েকটি নাম আপনাকে হতবাক করবে গর্ভপাত গ্রুপ, উন্মুক্ত সীমান্ত, অভিবাসী গ্রুপ, গ্রুপ, গ্রুপকে আমরা যেভাবে ভোট দিই, বৈশ্বিক স্বাস্থ্যসেবা, জলবায়ু পরিবর্তন, ক্যাথলিক, সমাজতান্ত্রিক এবং কমিউনিস্টদের পরিবর্তন করতে।সোরোসের আসলে একটা দল রয়েছে, যাদের লক্ষ্য হল ধনী যিহুদিদের কাছ থেকে টাকাপয়সা নিয়ে কম লোকেদের কাছে তা দেওয়া।গতকাল প্রকাশিত একটি ভিডিওতে জর্জ সোরোস (একজন ইহুদি) স্বীকার করেছেন যে তিনি দ্বিতীয় বিশ্বযুদ্ধের সময় ইহুদিদের কাছ থেকে সম্পত্তি বাজেয়াপ্ত করতে সাহায্য করেছেন, এই ধারণা যে সোরোস এমন একটি দলকে অর্থায়ন করছে তা আসলে অত আশ্চর্যজনক নয়। তারা সবাই এখানে।১৮৭ টি দল আমেরিকাকে ধ্বংস করতে ব্যবহৃত হচ্ছে, ধন্যবান কোটিপতি জর্জ সোরোস।এখানে সেই সব দল যারা ট্রাম্পের নির্বাচনকে আমেরিকা দখলের অজুহাত হিসেবে ব্যবহার করছে: জর্জ সোরোস এবং তার যৌথবাদী সক্রিয়তা নিয়ে অনেক নিবন্ধ লেখা হয়েছে।সোরোস একজন ব্যবসায়ী, বিনিয়োগকারী, জনহিতৈষী এবং লেখক যিনি ইহুদি-হাঙ্গেরিয়ান বংশোদ্ভূত এবং দ্বৈত নাগরিকত্বের অধিকারী।তিনি সোরোস ফান্ড ম্যানেজমেন্টের চেয়ারম্যান।আবিষ্কার নেটওয়ার্কস সোরোস এবং তার ওপেন সোসাইটি ইনস্টিটিউটের অর্থায়নে পরিচালিত সংস্থাগুলির একটি বিস্তৃত তালিকা প্রকাশ করেছে। এই দলগুলির মধ্যে কয়েকটি সক্রিয়ভাবে রাষ্ট্রপতি ডোনাল্ড ট্রাম্পের বিরোধিতা করেছে এবং তার সমাবেশে দেখা সাম্প্রতিক সহিংসতা ও বিশৃঙ্খলার স্তরের অংশ হতে পারে।অনেক গোষ্ঠীই সমর্থন করে: উন্মুক্ত সীমানা, রাজক্ষমা, অবৈধ ভোটের অধিকার প্রদান, মুসলিম অভিবাসন এবং সামাজিক ন্যায়বিচার। সাম্প্রতিক বছরগুলিতে জর্জ সোরোস এবং তাঁর ওপেন সোসাইটি ইনস্টিটিউট (ওএসআই) থেকে সরাসরি তহবিল এবং সহায়তা পেয়েছে এমন সংস্থাগুলি নিম্নরূপ:(ডিসকভারদ্যনেটওয়ার্কস.অর্গ এর গ্রুপ বিভাগে প্রতিটির সমন্বিত প্রোফাইল পাওয়া যায়): অ্যাডভান্সমেন্ট প্রকল্প: এই সংস্থা বাম বিশ্বের মতামত এবং মূল্যগুলি বিস্তৃতভাবে একটি অত্যাধুনিক যোগাযোগ বিভাগের মাধ্যমে যতটা সম্ভব ছড়িয়ে দেওয়ার সময় রঙের সম্প্রদায়গুলিকে রাজনৈতিকভাবে সমন্বয়মূলক ইউনিটগুলিতে সংগঠিত করার জন্য কাজ করে। এয়ার আমেরিকা রেডিও: এখন বিলুপ্ত, এটি একটি স্ব-চিহ্নিত উদার রেডিও নেটওয়ার্ক ছিল। আমাদের সবাই বা না: এই সংস্থা ভোটিং আইনগুলি পরিবর্তন করতে চায় যা প্রাক্তন-বন্দী, চরমপন্থীদের এবং এমনকি বর্তমান কারাবন্দীদের রাজনৈতিক নির্বাচনে তাদের ব্যালটগুলি নিক্ষেপ করতে অনুমতি দেওয়ার জন্য রাষ্ট্র থেকে রাজ্যে পরিবর্তিত হয়। ন্যায়বিচার গ্রুপ হিসাবে পরিচিত: প্রজাতন্ত্রের এই সক্রিয়তার জন্য ধারাবাহিকভাবে একটি ফেডারেল বিচারক হিসাবে পরিচিত।আমেরিকা একত্রিত হচ্ছে: সোরোস এই গ্রুপ তৈরিতে একটি প্রধান ভূমিকা পালন করেছে, যার উদ্দেশ্য ছিল গণতন্ত্রপন্থী ভোটার-মোবাইলাইজেশন প্রোগ্রামগুলির সমন্বয় এবং সংগঠিত করা। আমেরিকা ভোটস: সোরোসও এই গ্রুপ তৈরিতে একটি প্রধান ভূমিকা পালন করেছে, যার ভোটের প্রচারণা সম্ভাব্য গণতান্ত্রিক ভোটারদের লক্ষ্য করে। আমেরিকা এস ভয়েস: এই উন্মুক্ত বর্ডার গ্রুপ বিস্তৃত অভিবাসন সংস্কার প্রচার করতে চায় যার মধ্যে অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমার পক্ষে একটি শক্তিশালী এজেন্ডা রয়েছে। আমেরিকান বার অ্যাসোসিয়েশন কমিশন অন ইমিগ্রেশন পলিসি: এই সংস্থা নিয়োগকর্তা এবং শিক্ষা, স্বাস্থ্যসেবা বা অভিবাসন অবস্থা যাচাই করার জন্য অন্যান্য সামাজিক পরিষেবা প্রদানকারী ব্যক্তিদের আইনের বিরোধিতা করে।আমেরিকান ব্রিজ ২১শ শতাব্দী: এই সুপার প্যাক গণতান্ত্রিক রাজনৈতিক প্রার্থীদের তাদের রিপাবলিকান শত্রুদের পরাজিত করতে সাহায্য করার জন্য ডিজাইন করা বিরোধী গবেষণা পরিচালনা করে। আমেরিকান সিভিল লিবার্টিস ইউনিয়ন: এই দলটি মার্কিন সরকারের ৯/১১ পরবর্তী সমস্ত জাতীয় নিরাপত্তা ব্যবস্থার বিরোধিতা করে।এটি উন্মুক্ত সীমান্ত সমর্থন করে, সন্দেহভাজন সন্ত্রাসী এবং তাদের সহায়তাকারীদের প্রতিরক্ষায় দ্রুত এগিয়ে এসেছে এবং প্রাক্তন নিউ লেফট সন্ত্রাসী বার্নার্ডিন ডর্নকে এর উপদেষ্টা বোর্ডের জন্য নিযুক্ত করেছে। আমেরিকান সংবিধান সোসাইটি ফর ল এন্ড পলিসি: এই ওয়াশিংটন, ডিসি-ভিত্তিক চিন্তাবিদরা তরুণ আইন শিক্ষার্থীদের নিয়োগ, দীক্ষা এবং সংগঠিত করে ক্ষমতার অবস্থান অর্জনে সাহায্য করে বাম দিকে আমেরিকান আইনশাস্ত্রকে স্থানান্তরিত করার চেষ্টা করে।এটি বামপন্থী ডেমোক্রেটদের একটি উৎপীড়ক মঞ্চও সরবরাহ করে যা তাদের রাজনৈতিক প্রতিপক্ষের নিন্দা করে। আমেরিকান ফ্যামিলি ভয়েস: এই দলটি রিপাবলিকানদের বিরুদ্ধে অন্যায়ের অভিযোগ আনে এমন মিডিয়া প্রচারণা তৈরি এবং সমন্বয় সাধন করে। আমেরিকান ফেডারেশন অফ টিচারস: ১৯৯৭ সালে দীর্ঘদিনের এএফটি প্রেসিডেন্ট আলবার্ট শ্যাঙ্কার মারা যাওয়ার পরে, তিনি সান্ড্রা ফেল্ডম্যানের স্থলাভিষিক্ত হন, যিনি ধীরে ধীরে ইউনিয়নটিকে নতুন শ্রম আন্দোলনের সবচেয়ে শক্তিশালী বামপন্থী উপাদানগুলির সাথে সংযুক্ত করেন।২০০৪ সালে ফেল্ডম্যানের মৃত্যুর পর, এডওয়ার্ড ম্যাকএলরয় তার স্থলাভিষিক্ত হন এবং ২০০৮ সালে র্যান্ডি ওয়েঙ্গার্টেন তার স্থলাভিষিক্ত হন।আমেরিকান ফ্রেন্ডস সার্ভিস কমিটি: এই দলটি যুক্তরাষ্ট্রকে সারা বিশ্বের মানুষের দুঃখকষ্টের প্রধান কারণ হিসেবে দেখে থাকে।যেমন, এটা আমেরিকাকে একতরফা নিরস্ত্রীকরণ, আমেরিকান সীমানা বিলোপ, অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমা, মৃত্যুদণ্ড বিলোপ এবং প্যাট্রিয়ট অ্যাক্ট বাতিলের পক্ষে। আমেরিকান ইমিগ্রেশন কাউন্সিল: এই অলাভজনক সংস্থা উন্মুক্ত সীমান্ত লবির বিশিষ্ট সদস্য।এটি আমেরিকান ইমিগ্রেশন ল ফাউন্ডেশনে বসবাসকারী অবৈধ এলিয়েনদের অধিকার এবং ক্ষমা প্রসারিত করে: এই দলটি অবৈধ এলিয়েনদের জন্য ক্ষমাকে সমর্থন করে, যার পক্ষে এটি মার্কিন সরকারের বিরুদ্ধে মামলা করে। আমেরিকান ইন্ডিপেন্ডেন্ট নিউজ নেটওয়ার্ক: এই সংস্থাটি প্রগতিশীল পরিবর্তনের পক্ষে সমর্থনকারী প্রভাব সাংবাদিকতা প্রচার করে।আমেরিকান ইনস্টিটিউট ফর সোসাল জাস্টিস: এআইএসজে এর লক্ষ্য হচ্ছে দক্ষ সম্প্রদায়ের সংগঠক তৈরি করা যারা শহুরে পরিষেবা, মাদক নিষেধাজ্ঞা, অপরাধ প্রতিরোধ, গৃহায়ণ, পাবলিক সেক্টরের কাজ, স্বাস্থ্যসেবা এবং পাবলিক স্কুলগুলিতে বর্ধিত সরকারী ব্যয় বৃদ্ধির জন্য বিক্ষোভ করে দরিদ্র সম্প্রদায়কে রূপান্তরিত করতে পারে। আমেরিকান লাইব্রেরি অ্যাসোসিয়েশন: এই দলটি সন্ত্রাসের বিরুদ্ধে বুশ প্রশাসনের যুদ্ধ এর একটি স্পষ্টবাদী সমালোচক, মার্কিন প্যাট্রিয়ট অ্যাক্টের ধারা ২১৫, যা লাইব্রেরি ব্যবহারকারীদের সাংবিধানিক অধিকার এবং গোপনীয়তা অধিকারের বর্তমান বিপদ বলে অভিহিত করে।দ্য আমেরিকান প্রসপেক্ট, ইনক: এই কর্পোরেশন তরুণ বামপন্থী সাংবাদিকদের প্রশিক্ষণ দেয় এবং বামপন্থী নেতাদের জন্য কৌশল সভার আয়োজন করে।অ্যামনেস্টি ইন্টারন্যাশনাল: এই সংস্থা যুক্তরাষ্ট্র আর ইজরায়েলে মানবাধিকার লঙ্ঘনের জন্য তাদের সমালোচনার একটা অসামঞ্জস্য ভাগ ঠিক করে। ফলিত গবেষণা কেন্দ্র: আমেরিকাকে এমন একটা জাতি হিসাবে দেখা যেখানে কাঠামোগত বর্ণবাদ সমাজের কাঠামোর মধ্যে গভীরভাবে প্রোথিত, আরসি চেষ্টা করে একটা ন্যায় আর সমান সমাজ গড়ে তুলতে আমাদের সব থেকে শক্তিশালী প্রতিষ্ঠান থেকে সুনির্দিষ্ট পরিবর্তন দাবি করে।আরব আমেরিকান ইনস্টিটিউট ফাউন্ডেশন: আরব আমেরিকান ইনস্টিটিউট ৯/১১ পরবর্তী সময়ে আরব আমেরিকানদের বিরুদ্ধে পরিচালিত ব্যাপক নাগরিক স্বাধীনতা লঙ্ঘনের নিন্দা করে এবং ইস্রায়েলকে ফিলিস্তিনি জনগণের নৃশংস নিপীড়নকারী হিসাবে চিহ্নিত করে। অ্যাসপেন ইনস্টিটিউট: এই সংস্থা মৌলিক পরিবেশবাদ প্রচার করে এবং আমেরিকাকে এমন একটি জাতি হিসাবে দেখে যা গভীর আসনের কাঠামোগত বর্ণবাদ দ্বারা জর্জরিত।অ্যাসোসিয়েশন অফ কমিউনিটি অরগানাইজেশন ফর রিফর্ম নাউ: এই দলটি বামপন্থী ডেমোক্রেটদের পক্ষে ভোটার আন্দোলন পরিচালনা করে।এই উদ্যোগগুলো প্রতারণা এবং দুর্নীতির দ্বারা কুখ্যাতভাবে ক্ষতিগ্রস্ত হয়েছে। ব্যালট ইনিশিয়েটিভ স্ট্র্যাটেজি সেন্টার: এই সংস্থা একটি জাতীয় প্রগতিশীল কৌশলকে এগিয়ে নিয়ে যাওয়ার চেষ্টা করছে ভোটের মাধ্যমে রাষ্ট্র-স্তরের আইনী প্রস্তাবগুলি যা একটি পিটিশন (উদ্যোগ) প্রক্রিয়ার মাধ্যমে সফলভাবে পাস হয় এবং তারপর জনগণের দ্বারা ভোট দেওয়া হয়। বিল অফ রাইটস ডিফেন্স কমিটি: এই দলটি সক্রিয় কর্মীদের জন্য একটি বিস্তারিত ব্লুপ্রিন্ট সরবরাহ করে যারা তাদের স্থানীয় শহর, শহর এবং এমনকি কলেজ ক্যাম্পাসগুলিকে তাদের দেশপ্রেম আইনের বিরোধিতা প্রকাশ্যে ঘোষণা করতে এবং নিজেদের নাগরিক স্বাধীনতা নিরাপদ অঞ্চল হিসাবে চিহ্নিত করতে আগ্রহী।সংগঠনটি সন্ত্রাসবাদের জন্য বস্তুগত সহায়তা প্রদানের জন্য ২০০৫ সালে দোষী সাব্যস্ত হওয়া মৌলবাদী অ্যাটর্নি লিন স্টুয়ার্টের প্রতিরক্ষায়ও এসেছিল। ব্ল্যাক অ্যালায়েন্স ফর জাস্ট ইমিগ্রেশন: এই সংস্থা কালো জাতিগত পরিচয়ের উপর কেন্দ্রীভূত সামাজিক ও অর্থনৈতিক ন্যায়বিচারের জন্য একটি ঐক্যবদ্ধ আন্দোলন তৈরি করতে চায়। ব্লুপ্রিন্ট নর্থ ক্যারোলিনা: এই দলটি উত্তর ক্যারোলিনায় রাষ্ট্রীয় নীতি প্রভাবিত করতে চায় যাতে রাজ্যের বাসিন্দারা আরও প্রগতিশীল নীতিগুলি যেমন স্বাস্থ্যসেবা, উচ্চতর মজুরি, আরও সাশ্রয়ী মূল্যের হাউজিং, নিরাপদ, পরিষ্কার পরিবেশ এবং প্রজনন স্বাস্থ্যসেবা অ্যাক্সেস থেকে উপকৃত হয়।ব্রেনান সেন্টার ফর জাস্টিস: এই চিন্তাবিদ ট্যাঙ্ক/আইনী একটিভিস্ট গ্রুপ পাণ্ডিত্যপূর্ণ গবেষণা তৈরি করে, প্রচার মাধ্যমের প্রচারণা বৃদ্ধি করে, এমিকাসের সংক্ষিপ্ত নথি প্রকাশ করে, সক্রিয় কর্মীদের জন্য বোনো সমর্থন প্রদান করে এবং মৌলিক পরিবর্তনের জন্য পরীক্ষামূলক মামলা দায়ের করে।ব্রুকিংস ইনস্টিটিউশন: এই সংগঠনটি বিভিন্ন আন্তর্জাতিকতাবাদী এবং রাষ্ট্র-পৃষ্ঠপোষক প্রোগ্রামগুলির সাথে জড়িত, যার মধ্যে একটি জাতিসংঘ-শাসিত বিশ্ব সরকার প্রতিষ্ঠার জন্য উত্সাহী।ব্রুকিংস ফেলোগণ ব্যবসা ও ব্যাংকিং-এর উপর বৈশ্বিক সহযোগিতা, কিয়োটো প্রটোকলের সম্প্রসারণ এবং শিশুদের জন্য জাতীয়কৃত স্বাস্থ্য বীমার আহবান জানিয়েছেন।নয় জন ব্রুকিংস অর্থনীতিবিদ ২০০৩ সালে প্রেসিডেন্ট বুশের বিরুদ্ধে একটি পিটিশনে স্বাক্ষর করেছেন। আমেরিকার ভবিষ্যৎ এর জন্য ক্যাম্পেইন: এই দলটি কর বৃদ্ধি, সামাজিক ঔষধ, এবং সামাজিক কল্যাণ কর্মসূচির নাটকীয় সম্প্রসারণ সমর্থন করে। উন্নততর স্বাস্থ্যসেবার জন্য ক্যাম্পেইন: এই সংস্থাটি একক প্রদায়ক, সরকার পরিচালিত, সার্বজনীন স্বাস্থ্যসেবা ব্যবস্থাকে সমর্থন করে।ক্যাম্পেইন ফর ইয়থ জাস্টিস: এই সংগঠন দাবি করে যে, কিশোর-কিশোরীদের প্রাপ্তবয়স্ক অপরাধ-বিচার ব্যবস্থায় স্থানান্তরিত করা, অপরাধ-প্রতিরোধের উচ্চ হারের দিকে পরিচালিত করে, কারারুদ্ধ করে রাখে এবং অপ্রয়োজনীয় ঝুঁকিতে আটক রাখে, তাদের প্রতিরোধের মূল্য খুব কম এবং জনগণের নিরাপত্তা বৃদ্ধি করে না।ক্যাম্পাস প্রোগ্রেস: সোরোস-ব্যাংকরোলড সেন্টার ফর আমেরিকান প্রগ্রেসের একটি প্রকল্প, এই দলটি কলেজ এবং বিশ্ববিদ্যালয় ক্যাম্পাসগুলিতে প্রগতিশীল কণ্ঠস্বরকে শক্তিশালী করার চেষ্টা করে, ক্যাম্পাসে ডানপন্থী দলগুলোর ক্রমবর্ধমান প্রভাব মোকাবেলা করে এবং নতুন প্রজন্মের প্রগতিশীল নেতাদের ক্ষমতায়ন করে।কাসা ডি ম্যারিল্যান্ড: এই সংস্থাটি মার্কিন যুক্তরাষ্ট্রে বর্তমানে বসবাসরত অবৈধ এলিয়েনদের ক্ষমা সহ প্রসারিত অধিকারগুলির প্রচার করা নীতিগুলির পক্ষে ভোট দেওয়ার জন্য বিধায়কদের তীব্রভাবে লবি করে। ক্যাটালিস্ট: এটি একটি লাভজনক রাজনৈতিক পরামর্শ যা প্রগতিশীল সংস্থাগুলিকে সাহায্য করতে চায়, প্রতিটি ভোট-বয়স আমেরিকানের একটি শক্তিশালী জাতীয় ভোটার ডাটাবেস নির্মাণ এবং পরিচালনা করে নাগরিক অংশগ্রহণ এবং নির্বাচনী সাফল্যের পরিমাপযোগ্য বৃদ্ধি উপলব্ধি করতে।ক্যাথলিক ফর চয়েজ: এই নামমাত্র ক্যাথলিক সংস্থা মহিলাদের গর্ভপাত-অন-চাহিদার অধিকার সমর্থন করে। অ্যালায়েন্স ফর দ্য কমন গুড: এই রাজনৈতিক অলাভজনক গ্রুপ বামপন্থী প্রার্থী, কারণ এবং আইন প্রণয়নের জন্য ক্যাথলিক সম্প্রদায়ের কাছ থেকে সমর্থন আদায়ের জন্য নিবেদিত। আমেরিকান অগ্রগতির জন্য কেন্দ্র: এই বামপন্থী চিন্তাবিদের নেতৃত্বে প্রাক্তন ক্লিনটন চিফ অফ স্টাফ জন পোডেস্টা, হিলারি ক্লিনটনের সাথে ঘনিষ্ঠভাবে কাজ করেন এবং অসংখ্য প্রাক্তন ক্লিনটন প্রশাসন কর্মী নিয়োগ করেন।এটি একটি প্রগতিশীল আমেরিকা সম্পর্কে একটি দীর্ঘমেয়াদী ধারণা গড়ে তুলতে এবং নতুন প্রগতিশীল ধারণা ও নীতি প্রস্তাব তৈরির জন্য একটি ফোরাম তৈরি করতে প্রতিশ্রুতিবদ্ধ।সেন্টার ফর কমিউনিটি চেঞ্জ: এই দলটি বামপন্থী রাজনৈতিক ইস্যু প্রচারণার নেতৃত্ব দেওয়ার জন্য কর্মীদের নিয়োগ এবং প্রশিক্ষণ দেয়।দারিদ্রের সাথে সম্পর্কিত প্রধান জাতীয় বিষয়গুলির প্রতি দৃষ্টি আকর্ষণ করে সামাজিক কল্যাণ কর্মসূচির জন্য বর্ধিত তহবিল গঠন করে, কেন্দ্রটি প্রখ্যাত মৌলবাদী সংগঠক শৌল আলিনস্কির শেখানো কৌশলগুলির উপর তার প্রশিক্ষণ কর্মসূচির ভিত্তি করে। সাংবিধানিক অধিকারের জন্য কেন্দ্র: এই ক্যাস্ট্রোপন্থী সংগঠনটি উন্মুক্ত সীমান্ত লবির মূল সদস্য, মার্কিন সরকারের ৯/১১ পরবর্তী সমস্ত সন্ত্রাসবাদ বিরোধী পদক্ষেপের বিরোধিতা করেছে এবং অভিযোগ করেছে যে আমেরিকান অবিচার আন্তর্জাতিক সন্ত্রাসবাদের কাজকে প্ররোচিত করে। অর্থনৈতিক ও নীতি গবেষণা কেন্দ্র: এই দলটি কল্যাণ সংস্কারের বিরোধিতা করে, জীবিত মজুরি আইন সমর্থন করে, কর কর্তন প্রত্যাখ্যান করে এবং ধারাবাহিকভাবে সমাজতান্ত্রিক শাসকদের কৃতিত্বগুলিকে প্রশংসা করে, বিশেষত ভেনিজুয়েলা। সমস্ত উত্পাদনশীল মিশন, মহিলাদের জন্য নিরাপদ গর্ভপাতের নিশ্চয়তা দেয়।সংস্থাটি নিম্ন-আয়ের মহিলাদের জন্য করদাতা-অর্থায়িত গর্ভপাত (মেডিকেডের মাধ্যমে) অ্যাক্সেসের দাবি করে রাজ্য ও ফেডারেল মামলা দায়ের করেছে। দায়ী ঋণ কেন্দ্রের: এই সংস্থাটি সাব-প্রাইম বন্ধক সংকটের একটি প্রধান খেলোয়াড় ছিল।ফিল কারপেন (আমেরিকানদের প্রোস্পারিটি নীতির ভাইস প্রেসিডেন্ট) এর মতে, সিআরএল বাতিল করে দিয়েছে আর ব্যাংকগুলোকে হয়রানি করেছে অযোগ্য ঋণগ্রহীতাদের খারাপ ঋণ দিতে।এছাড়াও, সিআরএল বাজেট এবং নীতি অগ্রাধিকারের উপর ফ্যানি মে সেন্টারকে উচ্চ ঝুঁকির ঋণের শর্ত হিসাবে কাজ করতে সক্ষম করে এমন একটি চুক্তি নিয়ে আলোচনা করেছে: কর কর্তন সাধারণত ধনীদের সহায়তা করে এমন প্রাঙ্গণ থেকে যুক্তি দিয়ে, এই সংস্থাটি নিম্ন আয়ের লোকদের জন্য সামাজিক কল্যাণ কর্মসূচির উপর বৃহত্তর কর ব্যয়কে সমর্থন করে। উইসকনসিন স্ট্র্যাটেজি (সিওএস) কেন্দ্র: যাদের আয় গড়ের উপরে তাদের উপর আরোপিত উচ্চতর করের মাধ্যমে সম্পদকে পুনর্বণ্টনের লক্ষ্যে, কাওস যুক্তি দেখায় যে এটি গুরুত্বপূর্ণ যে রাষ্ট্রীয় সরকার কর্পোরেশন এবং ধনী সহ সমাজের সমস্ত অংশ থেকে ন্যায্য অবদান সংগ্রহ করতে সক্ষম হবে।চেঞ্জ আমেরিকা নাউ: ২০০৬ সালের ডিসেম্বর মাসে গঠিত চেঞ্জ আমেরিকা নাউ নিজেকে একটি স্বাধীন রাজনৈতিক সংস্থা হিসাবে বর্ণনা করেছে যা রিপাবলিকান কংগ্রেসের ব্যর্থ নীতি সম্পর্কে নাগরিকদের শিক্ষিত করার জন্য তৈরি করা হয়েছিল এবং একটি গণতান্ত্রিক এজেন্ডা দ্বারা প্রদত্ত প্রতিশ্রুতির সাথে ব্যর্থতার রেকর্ডের বিপরীতে।ওয়াশিংটনে দায়িত্ব ও নৈতিকতার জন্য নাগরিক: এই দলটি সরকারি কর্মকর্তাদের বিরুদ্ধে মামলা দায়ের করে এবং নৈতিকতার অভিযোগ আনে, যারা বিশেষ স্বার্থের জন্য সাধারণ কল্যাণকে বিসর্জন দেয় এবং জনগণের আস্থাকে বিশ্বাসঘাতকতা করে।এর প্রায় সকল লক্ষ্য রিপাবলিকান। একটি আন্তর্জাতিক অপরাধ আদালতের জন্য সহযোগিতা: এই দলটি একটি আন্তর্জাতিক আদালতের কাছে আমেরিকান অপরাধ-বিচার পদ্ধতি অধস্তন করতে চায়। সাধারণ কারণ: এই সংস্থার লক্ষ্য হল প্রচারণা-অর্থ সংস্কার আনা, ফেয়ারনেস ডকট্রিনের মতো মিডিয়া সংস্কার অনুসরণ করা এবং সামাজিক-কল্যাণ এবং পরিবেশগত ব্যয় বাড়ানোর পক্ষে সামরিক বাজেট হ্রাস করা। সংবিধান প্রকল্প: এই সংস্থা সামরিক কমিশনের বৈধতা চ্যালেঞ্জ করতে চায়; শত্রু যোদ্ধাদের আটক শেষ করা; সন্ত্রাসীদের সরকারি নজরদারির নিন্দা করা; এবং রাষ্ট্রপতির নির্বাহী সুবিধা সীমিত করা। ওয়াইল্ডলাইফ অ্যাকশন ফান্ডের রক্ষাকারীরা: আলাস্কার জাতীয় বন্যপ্রাণী তেল অনুসন্ধানের বিরোধিতা করে।এটি লগিং, র্যাঞ্চিং, মাইনিং এবং এমনকি বিনোদনমূলক মোটরচালিত যানবাহনকে পরিবেশের জন্য ধ্বংসাত্মক কার্যকলাপ হিসাবে ব্যবহার করাকে নিন্দা করে। গণতন্ত্র জোট: এই স্ব-বর্ণিত উদার সংগঠন বামপন্থী দলগুলির জন্য তহবিল ক্লিয়ারিং হাউস বিকাশের জন্য ২০০ মিলিয়ন ডলার সংগ্রহ করার লক্ষ্য রাখে।সোরোস এই দলের প্রধান দাতা। ডেমোক্রাসি ২১: এই দলটি ২০০২ সালের দ্বিপক্ষীয় প্রচারণা সংস্কার আইনের একনিষ্ঠ সমর্থক, এছাড়াও এটি ম্যাককেইন-ফিঙ্গোল্ড অ্যাক্ট.ডেমোক্রাসি নাও নামে পরিচিত!: ডেমোক্রেসি নাউ!ডব্লিউবিআই রেডিও সংবাদ পরিচালক এমি গুডম্যান এবং চার অংশীদার ১৯৯৬ সালে মার্কিন কর্পোরেট-পৃষ্ঠপোষক মিডিয়াতে কদাচিৎ শোনা দৃষ্টিকোণগুলি সরবরাহ করার জন্য তৈরি করেছিলেন, উদাহরণস্বরূপ, র্যাডিকাল এবং বিদেশী সাংবাদিকদের দৃষ্টিভঙ্গি, বামপন্থী এবং শ্রম কর্মী এবং পুঁজিবাদের মতাদর্শিক শত্রু। ডেমোক্রেটিক জাস্টিস ফান্ড: ডিজেএফ প্যাট্রিয়ট অ্যাক্টের বিরোধিতা করে এবং যুক্তরাষ্ট্রে বিশেষত সন্ত্রাসী জাতি হিসাবে স্টেট ডিপার্টমেন্টের মনোনীত দেশ থেকে অভিবাসন নিয়ন্ত্রণ বা নিয়ন্ত্রণের সর্বাধিক প্রচেষ্টা।ডেমোক্রেটিক পার্টি: সোরোস তহবিল কার্যক্রম মূলত ডেমোক্রেটিক পার্টিকে তার ক্ষমতার ভিত্তি দৃঢ় করতে সাহায্য করার জন্য নিবেদিত।২০০৩ সালের নভেম্বর মাসে এক সাক্ষাৎকারে সোরোস বলেছিলেন যে, ২০০৪ সালে প্রেসিডেন্ট বুশকে পরাজিত করাই আমার জীবন ও মৃত্যুর মূল বিষয়।তিনি বুশকে পরাজিত করার জন্য ৭৫ মিলিয়ন মার্কিন ডলার সংগ্রহ করার অঙ্গীকার করেছিলেন এবং ব্যক্তিগতভাবে বুশ-বিরোধী সংস্থাগুলিকে সেই অর্থের এক তৃতীয়াংশ দান করেছিলেন।তিনি বলেন, বুশের অধীনস্থ আমেরিকা বিশ্বের জন্য একটি বিপদ এবং আমি আমার মুখ যেখানে আছে সেখানে আমার টাকা দিতে ইচ্ছুক।ডেমোস: এই সংস্থা ফেডারেল আর রাষ্ট্রীয় নীতি নির্ধারকদের কাছে আবেদন করেছে অর্থনৈতিক নিরাপত্তা আর বৈষম্য তুলে ধরার জন্য যা আজকে আমেরিকান সমাজের বৈশিষ্ট্য তুলে ধরে; সম্পদ, আয় আর রাজনৈতিক প্রভাবের মধ্যে ফাঁক কমানোর ধারণা তুলে ধরে; আর ধনীদের জন্য কর বাড়ানোকে সমর্থন করে। ড্রাম মেজর ইন্সটিটিউট: এই দল নিজেকে বর্ণনা করে নির্দলীয়, অলাভজনক চিন্তাবিদ হিসাবে যা এই ধারণা তৈরি করে যা প্রগতিশীল আন্দোলনকে উৎসাহিত করে, নীতি নির্ধারক আর মতামত নেতাদের রাজি করার চূড়ান্ত লক্ষ্য নিয়ে যে পদক্ষেপ নেয়া সামাজিক আর অর্থনৈতিক ন্যায় বিচার সম্পর্কে তাদের দৃষ্টিকে এগিয়ে নিয়ে যাবে।আর্থজাস্টিস: এই দলটি মার্কিন যুক্তরাষ্ট্রের ভূমি ও জলপথ কিভাবে ব্যবহার করা যেতে পারে তার উপর কঠোর বিধিনিষেধ আরোপ করতে চায়।এটি বেশিরভাগ খনি ও লগিং উদ্যোগ, বাণিজ্যিক মাছ ধরার ব্যবসা এবং অনুন্নত এলাকায় মোটরচালিত যানবাহন ব্যবহারের বিরোধিতা করে। অর্থনৈতিক নীতি ইনস্টিটিউট: এই সংস্থা বিশ্বাস করে যে সরকারকে অর্থনৈতিকভাবে দুর্বলদের রক্ষা, সমান সুযোগ নিশ্চিত এবং সমস্ত আমেরিকানদের কল্যাণের জন্য একটি সক্রিয় ভূমিকা পালন করতে হবে।ইলেকট্রনিক প্রাইভেসি ইনফরমেশন সেন্টার: এই সংগঠনটি মার্কিন প্যাট্রিওট আইনের কঠোর সমালোচক এবং আমেরিকান সিভিল লিবার্টিজ ইউনিয়নে যোগদান করেছে।এলা বেকার সেন্টার ফর হিউম্যান রাইটস: বিপ্লবী কমিউনিস্ট ভ্যান জোনসের সহ-প্রতিষ্ঠাতা এই দারিদ্র্য-বিরোধী সংগঠন দাবি করেছে যে, আমাদের শহরগুলোতে দশকের পর দশক ধরে মাত্রাতিরিক্ত, বর্ণবাদী পুলিশিং এবং অতি কারাদণ্ডের কারণে হতাশা এবং গৃহহীনতার সৃষ্টি হয়েছে।এমিলি এস লিস্ট: এই রাজনৈতিক নেটওয়ার্ক গণতান্ত্রিক মহিলা রাজনৈতিক প্রার্থীদের জন্য অর্থ সংগ্রহ করে যারা করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদা. এনার্জি অ্যাকশন কোয়ালিশনে অবাধ প্রবেশাধিকার সমর্থন করে: ২০০৪ সালে প্রতিষ্ঠিত, এই দলটি নিজেকে যুব নেতৃত্বাধীন ৫০ টি পরিবেশগত ও সামাজিক ন্যায়বিচার গোষ্ঠীর জোট হিসাবে বর্ণনা করে যারা যুব পরিষ্কার শক্তি এবং জলবায়ু আন্দোলন গড়ে তোলার জন্য একত্রে কাজ করছে।ইকুয়াল জাস্টিস ইউএসএ: এই দল দাবি করে যে আমেরিকা অপরাধ-বিচার ব্যবস্থা উল্লেখযোগ্য জাতি এবং শ্রেণীগত পক্ষপাতিত্বের দ্বারা ক্ষতিগ্রস্ত এবং এইভাবে বড় সংস্কারের প্রচার চায়।ফেয়ার ইমিগ্রেশন রিফর্ম মুভমেন্ট: এটি সেন্টার ফর কমিউনিটি চেঞ্জের উন্মুক্ত সীমান্ত বাহু। বিশ্বস্ত আমেরিকা: এই সংগঠনটি সম্পদের পুনর্বন্টন প্রচার করে, যুদ্ধবন্দীদের সাথে যুদ্ধের মাধ্যমে জিজ্ঞাসাবাদের প্রক্রিয়া উন্নত করা, বৈশ্বিক উষ্ণায়নের বিরুদ্ধে লড়াই করার জন্য নীতিমালা প্রণয়ন এবং সরকার পরিচালিত তাপ যত্ন ব্যবস্থা তৈরির প্রচার করে। নারীবাদী সংখ্যাগরিষ্ঠতা: মার্কিন যুক্তরাষ্ট্রকে অন্তর্নিহিত যৌনবাদী জাতি হিসাবে চিহ্নিত করা, এই দলটি পুরুষদের সাথে মহিলাদের আইনি, সামাজিক ও রাজনৈতিক সমতার অগ্রগতির বিরোধিতা করে এবং মার্কিন যুক্তরাষ্ট্রে নারীবাদী আন্দোলনের জন্য ভবিষ্যতের নেতৃত্বকে উত্সাহিত করার জন্য তরুণ নারীবাদীদের নিয়োগ এবং প্রশিক্ষণ দেয়।ফোর ফ্রিডম ফান্ড: এই সংগঠনটি একটি কন্ডুইট হিসাবে কাজ করার জন্য ডিজাইন করা হয়েছিল যার মাধ্যমে বড় ফাউন্ডেশনগুলি রাষ্ট্রীয়-ভিত্তিক উন্মুক্ত সীমান্ত সংস্থাগুলিকে আরও স্পষ্ট এবং দ্রুত তহবিল সরবরাহ করতে পারে। ক্যাম্পাসে ফ্রি এক্সচেঞ্জ: এই সংগঠনটি কেবল এক ব্যক্তির প্রচেষ্টার বিরোধিতা করার জন্য তৈরি করা হয়েছিল, ডেভিড হোরোইটজ এবং বিশ্ববিদ্যালয়গুলিকে একটি একাডেমিক বিল অফ রাইটস গ্রহণ করার জন্য তার প্রচারণা, পাশাপাশি হোরোইটজ এস ২০০৬ বই অধ্যাপকদের নিন্দা করার জন্য তৈরি করা হয়েছিল।এফইসি'র সদস্য সংগঠনগুলোর মধ্যে রয়েছে ক্যাম্পাস প্রোগ্রেস (সেন্টার ফর আমেরিকান প্রগ্রেসের একটি প্রকল্প); আমেরিকান এসোসিয়েশন অফ ইউনিভার্সিটি প্রফেসরস; আমেরিকান সিভিল লিবার্টিজ ইউনিয়ন; পিপল ফর আমেরিকান ওয়ে; মার্কিন যুক্তরাষ্ট্রের ছাত্র সংগঠন; সেন্টার ফর ক্যাম্পাস ফ্রি স্পিচ; আমেরিকান লাইব্রেরি অ্যাসোসিয়েশন; ফ্রি প্রেস; এবং ন্যাশনাল অ্যাসোসিয়েশন অফ স্টেট পাবলিক ইন্টারেস্ট রিসার্চ গ্রুপ। ফ্রি প্রেস: এই মিডিয়া সংস্কার সংস্থা আমেরিকার জন্য মিডিয়া ম্যাটারস, এয়ার আমেরিকা রেডিও, গ্লোবাল এক্সচেঞ্জ, কোড পিংক, ফেয়ারনেস এবং প্রতিবেদনের শুদ্ধতা, বিপ্লবী কমিউনিস্ট পার্টি, মাদার জোনস ম্যাগাজিন, এবং প্যাসিফিক রেডিওর মতো উল্লেখযোগ্য বামপন্থীদের সাথে ঘনিষ্ঠভাবে কাজ করেছে।ফান্ডিং এক্সচেঞ্জ: সামাজিক পরিবর্তনের বাহন হিসাবে জনসেবার ধারণার প্রতি নিবেদিত, এই সংগঠনটি বামপন্থী দাতাদের সাথে এবং সমমনা দল ও কর্মীদের সাথে ফাউন্ডেশন যারা তাদের নিজেদের প্রগতিশীল পরিবর্তন এবং সামাজিক ন্যায়বিচারের সংস্করণ আনতে নিবেদিত।এই অনুদানপ্রাপ্তদের অনেকেই অনুমান করেন যে আমেরিকান সমাজ বর্ণবাদ, বৈষম্য, শোষণ এবং অযোগ্যতায় পরিপূর্ণ এবং টেকসই শিক্ষা, সক্রিয়তা এবং সামাজিক আন্দোলনের মাধ্যমে তাদের সংস্কার করা প্রয়োজন। গামালিয়েল ফাউন্ডেশন: ষাটের দশকের প্রগতিবাদী সক্রিয় কর্মী সোল আলিনস্কির কৌশলের মডেল তৈরি করে এই দলটি বর্তমান মাতৃভূমি নিরাপত্তা ব্যবস্থা এবং অভিবাসন বিধিনিষেধের বিরুদ্ধে দৃঢ় অবস্থান নিয়েছে। গিশা: আন্দোলনের স্বাধীনতার আইনী সুরক্ষা কেন্দ্র: এই ইজরায়েল বিরোধী সংগঠন ফিলিস্তিনিদের আন্দোলনের স্বাধীনতার অধিকার অনুশীলনে সহায়তা করার চেষ্টা করছে।গ্লোবাল সেন্টার ফর দ্য রেসপন্সিবিলিটি টু প্রটেক্ট: এই গ্রুপ দাবি করে যে যখন একটি রাষ্ট্র তার সীমানার মধ্যে সংঘটিত গণহত্যা থেকে বেসামরিক নাগরিকদের রক্ষা করতে অক্ষম বা অনিচ্ছুক প্রমাণিত হয়, তখন সম্ভব হলে শান্তিপূর্ণভাবে হস্তক্ষেপ করা আন্তর্জাতিক সম্প্রদায়ের দায়িত্ব, তবে প্রয়োজনে সামরিক বাহিনীর সাথে। গ্লোবাল এক্সচেঞ্জ: ১৯৮৮ সালে ক্যাস্ট্রো-পন্থী র্যাডিকাল মিডিয়া বেঞ্জামিন দ্বারা প্রতিষ্ঠিত, এই দলটি আমেরিকাকে ধারাবাহিকভাবে বিদেশী নীতি, ব্যবসা অনুশীলন এবং গার্হস্থ্য জীবন নিন্দা করে।৯/১১ এর সন্ত্রাসী হামলার পর, গ্লোবাল এক্সচেঞ্জ আমেরিকানদের পরামর্শ দিয়েছে মধ্য প্রাচ্যের তেলের উপর আমাদের নির্ভরতা থেকে ইজরায়েলের প্রতি আমাদের পক্ষপাতিত্বমূলক নীতি পর্যন্ত আরব বিশ্বে যুক্তরাষ্ট্রের বিরুদ্ধে অসন্তোষের মূল কারণ পরীক্ষা করে দেখতে।গ্রান্টমেকারস উইদাউট বর্ডারস: জিডব্লিউবি বামপন্থী পরিবেশ, যুদ্ধ বিরোধী এবং নাগরিক অধিকার গোষ্ঠীর খুব সমর্থন করে।এটি সাধারণত পুঁজিবাদের বিরোধী, যা প্রধান রাজনৈতিক, অর্থনৈতিক এবং সামাজিক ব্যবস্থাগুলির মধ্যে একটি বলে মনে করা হয় যা একটি বড় সামাজিক ব্যাধির জন্ম দেয়।গ্রীন ফর অল: ফেডারেল জলবায়ু, শক্তি এবং অর্থনৈতিক নীতি উদ্যোগের জন্য লবি করার জন্য ভ্যান জোন্স এই গ্রুপ তৈরি করেছিলেন।হেলথ কেয়ার ফর আমেরিকা নাউ: এই গ্রুপ একটি একক পেয়ার মডেল সমর্থন করে যেখানে ফেডারেল সরকার সমগ্র মার্কিন স্বাস্থ্য ব্যবস্থা অর্থায়ন এবং পরিচালনার দায়িত্বে থাকবে।হিউম্যান রাইটস ক্যাম্পেইন: যুক্তরাষ্ট্রের বৃহত্তম সমকামী-সমকামী-ট্রান্সজেন্ডার লবিং গ্রুপ, এইচআরসি রাজনৈতিক প্রার্থী এবং আইন সমর্থন করে যা এলজিবিটি এজেন্ডাকে এগিয়ে নিয়ে যাবে।ঐতিহাসিকভাবে, এইচআরসি সর্বাধিক জোরালোভাবে এইচআইভি / এইডস সম্পর্কিত আইন, ঘৃণা অপরাধ আইন, সামরিক এস ডন টি এসকের বিলোপ, ডন টি টেল নীতি এবং সমকামী বিবাহের বৈধতাকে সমর্থন করেছে। মানবাধিকার প্রথম: এই দলটি উন্মুক্ত সীমানা এবং অবৈধ এলিয়েনদের অধিকার সমর্থন করে; অভিযোগ যে প্যাট্রিয়ট আইন মার্কিন নাগরিক স্বাধীনতা গুরুতরভাবে হ্রাস করে; সন্ত্রাসের সন্দেহভাজন জোসে প্যাডিলার পক্ষে অ্যামিকাস কিউরিয়া সংক্ষিপ্ত দায়ের করেছে; এবং গুয়ান্তানামো বে আটক সুবিধাগুলির সমালোচনা করে। হিউম্যান রাইটস ওয়াচ: এই দলটি মার্কিন যুক্তরাষ্ট্র এবং ইজরায়েলে তার সমালোচনার একটি অসমঞ্জস্য ভাগ নির্দেশ করে।এটি সকল ক্ষেত্রে মৃত্যুদণ্ডের বিরোধিতা করে এবং অবৈধ এলিয়েনদের জন্য উন্মুক্ত সীমান্ত এবং ক্ষমা সমর্থন করে।আমি লাম: ইজরায়েল বিরোধী এই এনজিও আরব মিডিয়ার উন্নয়ন আর ক্ষমতায়নের চেষ্টা করছে আর ফিলিস্তিনি বিষয় নিয়ে কথা বলছে।অভিবাসী প্রতিরক্ষা প্রকল্প: অবৈধ অভিবাসীদের কারণকে এগিয়ে নিয়ে যাওয়ার জন্য, আইডিপি অভিবাসন আইন ব্যাকআপ সমর্থন এবং নিউ ইয়র্ক প্রতিরক্ষা অ্যাটর্নি এবং অন্যান্য যারা অপরাধমূলক ন্যায়বিচার এবং অভিবাসন ব্যবস্থায় অভিবাসীদের প্রতিনিধিত্ব বা সহায়তা করে, পাশাপাশি অভিবাসীদেরও সহায়তা করে। অভিবাসী আইনী সম্পদ কেন্দ্র: এই দলটি মার্কিন যুক্তরাষ্ট্রে প্রায় ত্রিশ লক্ষ অবৈধ বিদেশীর জন্য ক্ষমা পেতে সহায়তা করেছে বলে দাবি করে, এবং ১৯৮০-এর দশকে অভয়ারণ্য আন্দোলনের অংশ ছিল যা মধ্য আমেরিকার ব্যর্থ কমিউনিস্ট রাজ্যগুলি থেকে শরণার্থীদের আশ্রয় দিতে চেয়েছিল। অভিবাসী শ্রমিক নাগরিকত্ব প্রকল্প: এই উন্মুক্ত-সীমানা সংস্থা মার্কিন ইমিগ্রেশন নেটওয়ার্ককে গণ অভিবাসনের পক্ষে সমর্থন করে: নিম্ন-আয়ের সংস্থাগুলির ন্যায়বিচার বৃদ্ধি এবং অভিবাসীদের অধিকার আদায়ের জন্য সহায়তা করার এই জোটটি তাদেরকে জোরদার করতে চায়।অভিবাসন নীতি কেন্দ্র: আইপিসি উন্মুক্ত সীমান্তের এক প্রবক্তা এবং তারা দাবী করছে যে আমেরিকায় অবৈধ অভিবাসীর বিশাল পরিমাণ প্রবেশ ঘটেছে যুক্তরাষ্ট্রের সরকারের নীতির কারণে, বিশেষ করে যখন ভেঙ্গে পড়া অভিবাসন ব্যবস্থা [ ] অবৈধ অভিবাসনকে প্রথম স্থানে নিয়ে যায়।স্বাধীন মিডিয়া সেন্টার: এই ইন্টারনেট ভিত্তিক, সংবাদ এবং ইভেন্ট বুলেটিন বোর্ড অনিবার্যভাবে বামপন্থী, পুঁজিবাদ বিরোধী দৃষ্টিভঙ্গি উপস্থাপন করে এবং বিশ্বায়ন-বিরোধী / আমেরিকা বিরোধী থিমগুলির জন্য একটি মুখপাত্র হিসাবে কাজ করে। স্বাধীন মিডিয়া ইনস্টিটিউট: আইএমআই এসপিএন প্রকল্প (কৌশলগত প্রেস ইনফরমেশন নেটওয়ার্ক) পরিচালনা করে, যা তাদের সামাজিক ন্যায়বিচার লক্ষ্য অর্জনে সহায়তা করার জন্য অ্যাক্সেসযোগ্য এবং সাশ্রয়ী কৌশলগত যোগাযোগ, প্রশিক্ষণ, নেটওয়ার্কিং সুযোগ এবং কংক্রিট সরঞ্জামগুলি সহ বামপন্থী সংগঠনগুলিকে সরবরাহ করে।ইনস্টিটিউট ফর আমেরিকাস ফিউচার: আইএএফ সামাজিক ঔষধ সমর্থন করে, শিক্ষার জন্য সরকারী তহবিল বৃদ্ধি করে এবং প্রগতিশীল সংখ্যাগরিষ্ঠের কণ্ঠস্বর যাতে শোনা যায় তা নিশ্চিত করার জন্য একটি অবকাঠামো তৈরি করে।ইনস্টিটিউট ফর নিউ ইকোনমিক থিঙ্কিং: একটি নতুন বিশ্বব্যাপী অর্থনৈতিক দৃষ্টান্ত তৈরি করার চেষ্টা করছে, এই সংস্থাটি অসংখ্য ব্যক্তি দ্বারা পরিচালিত যারা জাতীয় অর্থনীতিতে সরকারী হস্তক্ষেপকে সমর্থন করে এবং যারা পুঁজিবাদকে একটি ত্রুটিযুক্ত সিস্টেম হিসাবে দেখে। পলিসি স্টাডিজ ইনস্টিটিউট: এই চিন্তাবিদটি দীর্ঘকাল ধরে বিশ্বব্যাপী কমিউনিস্ট এবং আমেরিকান বিরোধী কারণগুলিকে সমর্থন করে আসছে।অনিয়ন্ত্রিত লোভের জন্য পুঁজিবাদকে একটি প্রজনন ক্ষেত্র হিসাবে দেখে, আইপিএস অনিয়ন্ত্রিত বাজার এবং ব্যক্তিস্বাতন্ত্র্যকে সংশোধন করতে চায়।জাতিসংঘের ধার্মিকতায় একটি প্রশ্নাতীত বিশ্বাসের কথা স্বীকার করে, এটি জাতিসংঘের নিয়ন্ত্রণে আমেরিকান বৈদেশিক নীতি নিয়ে আসার লক্ষ্যে কাজ করে। পাবলিক এককিউরেসি ইনস্টিটিউট: এই আমেরিকান-বিরোধী, পুঁজিবাদী-বিরোধী, ইজরায়েল-বিরোধী সংস্থা স্পনসর্ড অভিনেতা শন পেন এস ২০০২ সালে বাগদাদ সফর উদযাপন করেছিলেন।এটি ডেমোক্রেটিক কংগ্রেসম্যান নিক রাহাল এবং সাবেক ডেমোক্রেট সিনেটর জেমস আবুরেজক ইনস্টিটিউট ফর উইমেনস পলিসি রিসার্চ দ্বারা ইরাকে সফর স্পনসর করেছিল: এই গ্রুপ মার্কিন যুক্তরাষ্ট্রকে নারীর প্রতি বৈষম্যের সাথে একটি জাতি হিসেবে দেখে এবং এই কথিত অবস্থার দিকে দৃষ্টি আকর্ষণ করার জন্য গবেষণা প্রকাশ করে।এ ছাড়া, এটি করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদার অবাধ প্রবেশাধিকারকে সমর্থন করে, এই বলে যে নারী ও মেয়েদের অর্থনৈতিক মঙ্গলের জন্য গর্ভপাতে প্রবেশাধিকার অপরিহার্য।আন্তর্জাতিক ক্রাইসিস গ্রুপ: এই সংস্থার নেতৃস্থানীয় ব্যক্তিত্বদের মধ্যে একজন হলেন মিডইস্ট ডিরেক্টর রবার্ট ম্যালি, যিনি আরব-ইসরায়েল বিষয়ক বিশেষ সহকারী প্রেসিডেন্ট বিল ক্লিনটন ছিলেন।মিডইস্ট সংঘাত নিয়ে তার বিশ্লেষণ ফিলিস্তিনিপন্থী। জে স্ট্রিট: এই ইজরায়েল বিরোধী দল সাবধান করে দেয় যে হামাসের সন্ত্রাসী হামলা বন্ধের জন্য সামরিক পদক্ষেপ নেয়া ইজরায়েলের উচিত পাল্টা ফলপ্রসু হবে আর কেবলমাত্র এই অঞ্চলের ইহুদি ফান্ড ফর জাস্টিসের সংঘাত চক্রকে গভীর করবে: এই সংস্থা সরকারের হস্তক্ষেপ আর করদাতাদের অর্থায়নকে আলোকিত সামাজিক নীতির গুরুত্বপূর্ণ অংশ হিসাবে দেখে।এটি গার্হস্থ্য অর্থনৈতিক ও সামাজিক অবিচারের মূল কারণগুলির বিরুদ্ধে লড়াই করার জন্য যিহূদী দাতাদের কাছ থেকে স্বল্প-আয়ের সম্প্রদায়গুলিতে সম্পদ পুনর্বন্টনের চেষ্টা করে।জেএফজে এস হিসাব অনুযায়ী, মূল কারণগুলির মধ্যে প্রধান হল পুঁজিবাদের অন্তর্নিহিত নেতিবাচক উপজাতগুলি, বিশেষত বর্ণবাদ এবং চরম অর্থনৈতিক বৈষম্য।যৌথ বিজয় অভিযান ২০০৪: জর্জ সোরোস এবং হ্যারল্ড ইকস দ্বারা প্রতিষ্ঠিত, ২০০৪ সালের নির্বাচন চক্রের সময় এই দলটি ডেমোক্রেটদের জন্য একটি প্রধান তহবিল সংগ্রহের সংস্থা ছিল।এই দলটি ডেমক্রেটিক্সের পক্ষে কাজ করে। স্টেকে ন্যায়বিচার: এই জোটটি বিচারকদের নির্দলীয়, মেধা নির্বাচন নামে পরিচিত একটি প্রক্রিয়ায় নিযুক্ত করার আহ্বান জানায়, ভোটদানকারী জনগণের দ্বারা নির্বাচিত না হয়ে। ল্যাটিনো জাস্টিস পিআরএলডিএফ: এই সংস্থাটি দ্বিভাষিক শিক্ষাকে সমর্থন করে, ভোটিং জেলার জাতিগত যাযাবরকরণকে সমর্থন করে এবং অবৈধ এলিয়েনদের জন্য অধিকার প্রসারিত করে। আইনের অধীনে নাগরিক অধিকারের জন্য আইনজীবী কমিটি: এই দলটি আমেরিকাকে একটি অঘোষিত বর্ণবাদী জাতি হিসাবে দেখে; আদালত এই আইনের মাধ্যমে ইতিবাচক জাতি-ভিত্তিক ব্যবসায়ের সীমাবদ্ধতাকে সমর্থন করে।লিন স্টুয়ার্ট ডিফেন্স কমিটি: আইআরএস রেকর্ড নির্দেশ করে যে সোরোস এস ওপেন সোসাইটি ইনস্টিটিউট ২০০২ সালের সেপ্টেম্বর মাসে এই সংস্থাকে ২০,০০০ মার্কিন ডলার অনুদান প্রদান করে।স্টুয়ার্ট ছিলেন অপরাধী-প্রতিরক্ষা অ্যাটর্নি যিনি পরে তার মক্কেল অন্ধ শেখ ওমর আব্দেল রহমানকে তার ইসলামী গ্রুপের সাথে সম্পর্কিত সন্ত্রাসী কর্মকাণ্ডে সহায়তা করার জন্য দোষী সাব্যস্ত হন। ম্যাকসোম ওয়াচ: এই সংস্থাটি নিজেকে ইসরায়েলি নারীদের একটি আন্দোলন, ইসরায়েলি সমাজের সমস্ত ক্ষেত্রের শান্তি কর্মী, যারা ইসরায়েলি দখলদারিত্বের বিরোধিতা করে এবং তাদের দেশে অবাধে চলাচল করার ফিলিস্তিনি অধিকার অস্বীকার করে।মাদ্রেঃ এই আন্তর্জাতিক নারী সংগঠন আমেরিকাকে মানবাধিকার লংঘনকারী হিসেবে গণ্য করে।যেমন, এটি বিশ্বজুড়ে সহিংসতা, দারিদ্র্য এবং নিপীড়নের মুখোমুখি হওয়া নারী এবং পরিবারগুলির উপর মার্কিন নীতির বাস্তব জীবনের প্রভাব এবং মার্কিন নীতিগুলির বিকল্প দাবি করার জন্য যোগাযোগ [স্প্যানিশ] করার চেষ্টা করে।এছাড়াও এটি করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদার অবাধ প্রবেশাধিকারকে সমর্থন করে। ম্যালকম এক্স গ্রাসরুটস মুভমেন্ট: এই দলটি মার্কিন যুক্তরাষ্ট্রকে বর্ণবাদ এবং কালোদের বিরুদ্ধে বৈষম্যের সাথে পরিপূর্ণ একটি জাতি হিসাবে দেখে; দক্ষিণ-পূর্ব যুক্তরাষ্ট্রে একটি স্বাধীন কালো জাতি প্রতিষ্ঠা করতে চায়; এবং দাসত্বের জন্য ক্ষতিপূরণ দাবি করে। ম্যাসাচুসেটস অভিবাসী এবং শরণার্থী অ্যাডভোকেসি কোয়ালিশন: এই দলটি অবৈধ এলিয়েনদের জন্য নাগরিক অধিকার এবং স্বাধীনতা সম্প্রসারণের আহ্বান জানায়; শোক প্রকাশ করে যে আমেরিকাতে অবৈধ এলিয়েনরা সাধারণত শোষণের শিকার হয়; কলেজে পড়াশোনার জন্য পদ্ধতিগত-সহায়তা প্রোগ্রামকে সমর্থন করে; এবং প্যাট্রিয়টস এই আইনটিকে একটি অত্যন্ত রক্ষণশীল রাজনৈতিক গণমাধ্যম তহবিল হিসাবে চিহ্নিত করে, যার মুদ্রিত স্বাধীনতার জন্য খুব অসুবিধা সৃষ্টি করে।দলটি সোরোস-সমর্থিত সেন্টার ফর আমেরিকান প্রোগ্রেসের সাথে ঘনিষ্ঠভাবে কাজ করে এবং গণতন্ত্র জোট দ্বারা ব্যাপকভাবে অর্থায়ন করা হয়, যার মধ্যে সোরোস একজন প্রধান অর্থ যোগানদাতা। মার্সি কর্পস: আরব-ইসরায়েলি সংঘাতের মুখোমুখি হয়ে, মার্সি কর্পস ফিলিস্তিনি দারিদ্র্য এবং সরাসরি ইসরাইলের উপর দুর্ভোগের জন্য দায়ী। মেক্সিকান আমেরিকান লিগ্যাল ডিফেন্স অ্যান্ড এডুকেশন ফান্ড: এই দলটি উন্মুক্ত সীমানা, অবৈধ এলিয়েনদের জন্য কলেজে পড়ার অনুমতি দেয়, হিস্পানিকদের থাকার জন্য শিক্ষাগত মান হ্রাস করে এবং অপরাধীদের পক্ষে ভোট দেওয়ার অধিকার রাখে।মালডেফ এর মতে, ইংরেজীকে আমেরিকার সরকারী ভাষা করার সমর্থকরা বর্ণবাদ আর অভিবাসী বিরোধী মনোভাবের দ্বারা অনুপ্রাণিত, আর নিয়োগকর্তাদের বিরুদ্ধে নিষেধাজ্ঞা যারা অবৈধ শ্রমের উপরে নির্ভরশীল তারা বাদামী চামড়ার মানুষের বিরুদ্ধে বৈষম্যমূলক আচরণ করতে চায়।মেয়ার, সুজ্জি, ইংরেজ এবং ক্লেইন, পিসি: বিগ লেবারের এই প্রভাবশালী সমর্থকের নেতৃত্বে আছেন ডেমোক্রেটের সক্রিয় কর্মী হ্যারল্ড আইকস।মিডওয়েস্ট একাডেমী: এই সত্তা সরাসরি কাজ, লক্ষ্য, সংঘর্ষ এবং ভীতি প্রদর্শনের কৌশলগুলিতে মৌলবাদী কর্মীদের প্রশিক্ষণ দেয়। মাইগ্রেশন পলিসি ইনস্টিটিউট: এই দলটি মাঝারি পর্যায়ে স্থায়ী অভিবাসনের সাথে ধীরে অদৃশ্য সীমান্ত নিয়ন্ত্রণের সাথে উত্তর আমেরিকা তৈরি করতে চায়।সামরিক পরিবার কথা বলছে: এই দলটি যুক্তরাষ্ট্রের ইরাক আক্রমণকে আমেরিকান সাম্রাজ্যবাদ এবং তেলের লালসার সাথে তুলনা করেছে। মিসৌরিয়ানরা সংস্কার ও ক্ষমতায়নের জন্য সংগঠিত: এই দলটি এখন বিলুপ্ত, প্রো-সোশালিস্ট, কমিউনিটি সংস্থা একরন.মুভঅন.অর্গ এর পুনরায় ব্র্যান্ডেড মিসৌরি শাখা: এই ওয়েব-ভিত্তিক সংগঠন গণতান্ত্রিক রাজনৈতিক প্রার্থীদের তহবিল সংগ্রহ, বিজ্ঞাপন, এবং ভোট প্রদানের উদ্যোগের মাধ্যমে সমর্থন করে।ফাউন্ডেশন ফর উইমেন: এই দলটি মার্কিন সমাজের বিস্তৃত এবং স্থায়ী ত্রুটি: বর্ণবাদ, লিঙ্গ বৈষম্য, হোমোফোবিয়া এবং নাগরিক অধিকার ও স্বাধীনতা লংঘনের বিষয়ে এটি যা মনে করে তা নিয়ে দুঃখ প্রকাশ করেছে।এটি নারীদের জন্য ইতিবাচক পদক্ষেপ, করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদার অবাধ অ্যাক্সেস, অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমা এবং বড় সরকারগুলির উপর দৃষ্টি নিবদ্ধ করে। নারাল প্রো-চোইস আমেরিকা: এই দলটি করদাতা-অর্থায়িত গর্ভপাত-অন-দাবি সমর্থন করে এবং গর্ভপাত-বিরোধী ডেমোক্র্যাটদের নির্বাচিত করার জন্য কাজ করে। এনএএসিপি আইনী প্রতিরক্ষা এবং শিক্ষা তহবিল: এনএএসিপি কর্মসংস্থান এবং শিক্ষার জাতিগত পছন্দ এবং ভোটিং জেলার জাতিগত জিমন্যান্ডারিং সমর্থন করে।বর্ণ পছন্দগুলির জন্য তার সমর্থন জোর দিয়ে বিশ্বাস করা হয় যে মার্কিন যুক্তরাষ্ট্রে সাদা বর্ণবাদ একটি অপরিবর্তনীয়, মূলত অনিশ্চিত, ঘটনা। দ্য নেশন ইনস্টিটিউট: এই অলাভজনক সত্তা প্রগতিবাদী কর্মীদের জন্য বামপন্থী সম্মেলন, ফেলোশিপ, পুরষ্কার এবং সাংবাদিকতা ইন্টার্নশিপ স্পনসর করে। জাতীয় গর্ভপাত ফেডারেশন: এই গ্রুপ রাষ্ট্র বা ফেডারেল পর্যায়ে গর্ভপাতের উপর যে কোনও বিধিনিষেধের বিরোধিতা করে এবং বিশ্বের উন্নয়নশীল অঞ্চলে অবাধ গর্ভপাত প্রবর্তনের চ্যাম্পিয়ন। মৃত্যুদন্ড বাতিল করতে জাতীয় জোট: এই দলটি ১৯৭৬ সালে প্রতিষ্ঠিত হয়েছিল প্রথম সম্পূর্ণরূপে কর্মী জাতীয় সংস্থা হিসাবে একচেটিয়াভাবে মৃত্যুদন্ড বিলুপ্ত করার জন্য নিবেদিত।ন্যাশনাল কমিটি ফর রেসপন্সিভ ফিল্যানথ্রপি: এই দলটি মার্কিন যুক্তরাষ্ট্রকে এমন একটি জাতি হিসাবে বর্ণনা করে যা জনহিতৈষী সংস্থার অর্থায়নে নাটকীয় কাঠামোগত পরিবর্তনের প্রয়োজন।এটি ব্যাপকভাবে অনুদান প্রদানকারী এবং অনুদানপ্রাপ্তদের বামপন্থী এজেন্ডার সাথে প্রচার করে, তাদের রক্ষণশীল সহযোগীদের সমালোচনা করে। ভোটিং ইন্টিগ্রিটির জন্য জাতীয় কমিটি: এই দলটি নির্বাচনের অখণ্ডতা নিশ্চিত করার উপায় হিসাবে আমেরিকার নির্বাচনে যোগ্য ভোটারদের নাগরিকত্ব প্রমাণ এবং ছবি সনাক্তকরণ প্রয়োজনীয়তা প্রয়োগের বিরোধিতা করে।ন্যাশনাল কাউন্সিল ফর রিসার্চ অন ওমেন: এই গ্রুপ বড় সরকার, উচ্চ কর, সামরিক ব্যয় হ্রাস, সামাজিক কল্যাণ ব্যয় বৃদ্ধি, এবং করদাতাদের গর্ভপাত-অন-চাহিদার অনিয়ন্ত্রিত অধিকার সমর্থন করে। লা রাজা জাতীয় পরিষদ: এই গ্রুপ জাতিগত পছন্দ, দ্বিভাষিক শিক্ষা, কঠোর ঘৃণা-অপরাধ আইন, গণ অভিবাসন এবং অবৈধ এলিয়েনদের জন্য ক্ষমা দাবি করে। ন্যাশনাল কাউন্সিল অফ ওমেন এস অর্গানাইজেশনস: এই গ্রুপ মার্কিন যুক্তরাষ্ট্রকে নারী ও মহিলাদের বিরুদ্ধে অবিচারের সাথে একটি জাতি হিসাবে দেখে।এটি সামাজিক কল্যাণ কর্মসূচির জন্য উচ্চ স্তরের ব্যয় সমর্থন করে এবং সংখ্যালঘু এবং ব্যবসায় ও একাডেমিয়ায় নারীদের জন্য জাতি ও লিঙ্গ পছন্দ সমর্থন করে। জাতীয় অভিবাসন ফোরাম: বর্তমান অভিবাসন আইনগুলির প্রয়োগের বিরোধিতা করে, এই সংস্থাটি মার্কিন সরকারকে বর্তমানে মার্কিন যুক্তরাষ্ট্রে যে সমস্ত অবৈধ এলিয়েনদের কোন অপরাধমূলক রেকর্ড নেই তাদের আইনীকরণের জন্য এবং মার্কিন যুক্তরাষ্ট্রে অভিবাসন করতে ইচ্ছুকদের জন্য ভিসার সংখ্যা নাটকীয়ভাবে বৃদ্ধি করার আহ্বান জানিয়েছে।ফোরামটি বিশেষত অদক্ষ, নিম্ন-আয়ের শ্রমিকদের জন্য সীমান্ত উন্মুক্ত করতে প্রতিশ্রুতিবদ্ধ এবং তাদেরকে কল্যাণ ও সামাজিক পরিষেবা কার্যক্রমের জন্য উপযুক্ত করে তুলতে প্রতিশ্রুতিবদ্ধ। জাতীয় অভিবাসন আইন কেন্দ্র: এই দলটি অবৈধ এলিয়েনদের জন্য সরকার-তহবিলকৃত সামাজিক কল্যাণ কর্মসূচিতে অবাধ প্রবেশাধিকার পেতে চায়। জাতীয় আইনজীবী গিল্ড: এই দলটি উন্মুক্ত সীমানা প্রচার করে; আমেরিকা গোয়েন্দা-সংগ্রহকারী সংস্থাগুলিকে দুর্বল করার চেষ্টা করে; নাগরিক স্বাধীনতার উপর আক্রমণ হিসাবে প্যাট্রিয়ট অ্যাক্টকে নিন্দা করে; পুঁজিবাদকে একটি অহিংস অর্থনৈতিক ব্যবস্থা হিসাবে প্রত্যাখ্যান করে; দোষী সন্ত্রাসী এবং তাদের সহায়তাকারীদের প্রতিরক্ষা করতে ছুটে এসেছে; এবং সাধারণত মার্কিন যুক্তরাষ্ট্রের সমস্ত বিদেশী নীতির অবস্থানের বিরোধিতা করে, ঠিক যেমন এটি সোভিয়েত-জাতীয় লিঙ্গ বৈষম্য ওমেন সম্প্রদায়কে সমর্থন করার সময় করেছিল।এটি গর্ভাবস্থার যে কোনও পর্যায়ে এবং যে কোনও কারণে করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদা ভোগ করার জন্য নারীদের সর্বজনীন অধিকারের পক্ষেও পরামর্শ দেয়। জাতীয় অগ্রাধিকার প্রকল্প: এই গোষ্ঠী উচ্চতর কর এবং সামাজিক কল্যাণ কর্মসূচিতে বৃহত্তর ব্যয়ের মাধ্যমে সরকার-নিয়ন্ত্রিত সম্পদের পুনর্বণ্টন সমর্থন করে।এনপিপি সরকারকে জনশিক্ষা, সার্বজনীন স্বাস্থ্য বীমা, পরিবেশবাদী প্রকল্প এবং কল্যাণ কর্মসূচিতে তার সামরিক তহবিলের একটি উল্লেখযোগ্য অংশ পুনঃনির্দেশিত করার পরামর্শ দেয়। ন্যাশনাল পাবলিক রেডিও: ১৯৭০ সালে ৯০ টি পাবলিক রেডিও স্টেশনকে চার্টার সদস্য হিসাবে প্রতিষ্ঠিত করে, এনপিআর বর্তমানে সারা দেশে ৭৫০ টিরও বেশি মার্কিন রেডিও স্টেশনগুলির একটি শিথিল নেটওয়ার্ক, যার অনেকগুলি কলেজ এবং বিশ্ববিদ্যালয় ক্যাম্পাসের উপর ভিত্তি করে গঠিত।(উৎস)জাতীয় নিরাপত্তা আর্কাইভ তহবিল: এই দলটি আমেরিকান জাতীয় নিরাপত্তা এবং গোয়েন্দা এজেন্টদের সুরক্ষাকে আপস করে এমন একটি ডিগ্রিতে তথ্য স্বাধীনতা আইনের মাধ্যমে প্রাপ্ত ডিক্লায়েড নথি সংগ্রহ এবং প্রকাশ করে। জাতীয় মহিলা আইন কেন্দ্র: এই দলটি করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদা সমর্থন করে; রক্ষণশীল বিচার বিভাগীয় নিয়োগীদের বিরুদ্ধে লবিং; নিম্ন-আয়ের মায়েদের সহায়তা করার জন্য কল্যাণ ব্যয় বৃদ্ধি করে; এবং সরকারী কর্মসূচী যেমন মেডিকেড, খাদ্য স্ট্যাম্প, কল্যাণ, যত্ন যত্ন, স্বাস্থ্যসেবা, শিশু-সহায়তা প্রয়োগ এবং ছাত্র ঋণগুলির জন্য আরও তহবিল তৈরির উদ্দেশ্যে উচ্চতর কর প্রদান করে। নেচারাল রিসোর্সেস ডিফেন্স কাউন্সিল: মার্কিন যুক্তরাষ্ট্রের অন্যতম প্রভাবশালী পরিবেশগত লবিটিং গ্রুপ, জনগণের একটি পরিষদের সদস্য দাবি করে।নিউ আমেরিকা ফাউন্ডেশন: এই সংস্থা স্বাস্থ্য, পরিবেশবাদ, শক্তি নীতি, মিডইস্ট দ্বন্দ্ব, বিশ্বব্যাপী শাসন এবং আরও অনেক বিষয়ে জনমতকে প্রভাবিত করার জন্য নীতি কাগজপত্র, মিডিয়া নিবন্ধ, বই এবং শিক্ষামূলক ঘটনাগুলি ব্যবহার করে। নিউ ইজরায়েল তহবিল: এই সংস্থা এনজিওগুলিকে সহায়তা দেয় যা নিয়মিত মানবাধিকার লঙ্ঘন এবং ধর্মীয় নির্যাতনের অভিযোগ ইস্রায়েলকে অভিযুক্ত করে এমন প্রতিবেদন তৈরি করে। নিউজকর্পওয়াচ: আমেরিকার জন্য মিডিয়া ম্যাটারস প্রকল্পের একটি প্রকল্প, নিউজকর্পওয়াচ মিডিয়া ম্যাটারসকে ১ মিলিয়ন মার্কিন ডলার অনুদানের সহায়তায় প্রতিষ্ঠিত হয়েছিল। প্যাসিফিকা ফাউন্ডেশন: এই সত্তাটি প্যাসিফিক রেডিও পরিচালনা করে এবং তার জন্ম থেকে সমাজতান্ত্রিক-মার্কসবাদী বাগাড়ম্বরের ভিত্তিতে ধুয়ে দেয় এবং ৬০-যুদ্ধবিরোধী পুঁজিবাদ এবং আরও বামপন্থী সমিতিকে দেয়। এই সংস্থাটি মিডিয়া ম্যাটার্সের চেয়ে ৬০-শান্তি তহবিল দেয়।শান্তি উন্নয়ন তহবিল: পিডিএফ এস ক্যালকুলাসে মার্কিন যুক্তরাষ্ট্রের সামাজিক ও অর্থনৈতিক প্রতিষ্ঠানগুলোর ব্যাপক পরিবর্তন প্রয়োজন।সম্প্রতি পিডিএফ ব্যাখ্যা করছে, আমরা নব্য-উদারনীতিবাদ এবং পুঁজিবাদের বিশ্বায়নের নেতিবাচক প্রভাব, মার্কিন যুক্তরাষ্ট্রের শিল্পায়ন হ্রাস এবং ধনী ও দরিদ্র জনগণের মধ্যে মার্কিন পথের ক্রমবর্ধমান ব্যবধান প্রত্যক্ষ করেছি: এই দলটি প্যাট্রিয়ট অ্যাক্টের বিরোধিতা করে, সাধারণত সন্ত্রাস বিরোধী পদক্ষেপ এবং ধর্মীয় অধিকারের কথিত ক্রমবর্ধমান প্রভাবের বিরোধিতা করে।জনগণকে সংগঠিত করার মাধ্যমে সম্প্রদায় উন্নত করা: এই দলটি মানবাধিকার লঙ্ঘনের নিন্দা জানানোর জন্য আলিনস্কি-শৈলীর সাংগঠনিক কৌশলগুলি ব্যবহার করে। মানবাধিকারের জন্য চিকিৎসক: এই দলটি মানবাধিকার লঙ্ঘনের জন্য মার্কিন যুক্তরাষ্ট্র এবং ইসরাইলের সমালোচনায় বাছাই এবং ভারসাম্যহীনভাবে সমালোচনা করে। সামাজিক দায়বদ্ধতার জন্য চিকিৎসক: এটি একটি মার্কিন-সামরিক সংস্থা যা মৌলিক পরিবেশগত নীতিগুলিকেও আলিঙ্গন করে। পরিকল্পিত প্যারেন্টহুড: এই দলটি মার্কিন যুক্তরাষ্ট্রের বৃহত্তম গর্ভপাত সরবরাহকারী এবং করদাতা-অন-ডেমান্ডের সমর্থক। প্লাগশেয়ার তহবিল: এই পাবলিক অনুদান পিসি ফাউন্ডেশন আমেরিকাকে একটি অত্যন্ত সমালোচনামূলক অর্থনৈতিক উদ্যোগের বিরোধিতা করে, যা নিউ ইয়র্কের একটি নতুন জলবায়ু প্রকল্প তৈরিতে সহায়তা করে।সংগঠনটির প্রধান উপদেষ্টা বিপ্লবী কমিউনিস্ট ভ্যান জোন্স। প্রিজন মোরাটোরিয়াম প্রকল্প: এই উদ্যোগটি ১৯৯৫ সালে মার্কিন যুক্তরাষ্ট্রের সমস্ত কারাগার নির্মূল এবং সমস্ত বন্দীদের মুক্তির জন্য কাজ করার জন্য তৈরি করা হয়েছিল।বন্দীদশা কখনোই অপরাধ মোকাবেলা করার উপযুক্ত উপায় নয় এমন প্রতিজ্ঞা থেকে যুক্তি দিয়ে বলা হয়েছে, আমেরিকান সমাজ সহজাতভাবে সমস্ত অপরাধমূলক আচরণের মূল অযোগ্য বলে মনে করে। প্রগতিশীল পরিবর্তন প্রচারাভিযান কমিটি: এই সংস্থাটি সাহসী প্রগতিশীল প্রার্থীদের ফেডারেল অফিসে নির্বাচন করে এবং [তাদের] অর্থ সঞ্চয়, শ্রমকে আরও স্মার্ট করে এবং আরও বেশি করে জিততে সহায়তা করে।প্রগতিশীল রাজ্য নেটওয়ার্ক: পিএসএন মিশনটি ফরওয়ার্ড-চিন্তাশীল রাজ্য বিধানকারীদের সমন্বিত গবেষণা এবং কৌশলগত এডভোকেসি সরঞ্জাম সরবরাহ করে সমস্ত পঞ্চাশটি রাজ্যে প্রগতিশীল আইন পাস করা।প্রকল্প ভোট: এটি সোরোস-তহবিলকৃত একরনের ভোটার-মোবাইলাইজেশন বাহু।বছরের পর বছর ধরে একর্ন/প্রকল্প ভোট কার্যক্রম অনুসরণ করে আসছে।প্রো পাবলিকা: তদন্তমূলক সাংবাদিকতা ঝুঁকির মধ্যে রয়েছে দাবি করে, এই দলটি সরকার, ব্যবসা এবং অন্যান্য প্রতিষ্ঠানের ক্ষমতার অপব্যবহার এবং বিশ্বাসঘাতকতার কথা প্রকাশ করে [স্প্যানিশ ভাষায়] সংবাদ প্রকাশে এই লাক্ষানাটির প্রতিকার করার লক্ষ্যে অনুসন্ধানমূলক সাংবাদিকতার নৈতিক শক্তি ব্যবহার করে, যা অপরাধের স্থায়ী কেন্দ্রবিন্দুর মাধ্যমে সংস্কারের পক্ষে।প্রোটিয়াস ফান্ড: এই ফাউন্ডেশন বেশ কয়েকটি মৌলিক বামপন্থী সংস্থার প্রতি তার জনসেবা পরিচালনা করে। পাবলিক সিটিজেন ফাউন্ডেশন: পাবলিক সিটিজেন সিটিজেন কর্পোরেশনগুলির বিরুদ্ধে সরকারী হস্তক্ষেপ এবং মামলা মোকদ্দমা বৃদ্ধি করতে চায় এমন একটি অনুশীলনের উপর ভিত্তি করে যে আমেরিকান কর্পোরেশনগুলি, পুঁজিবাদী ব্যবস্থার মতো তারা অংশ, তারা সহজাতভাবে দুর্নীতির দিকে ঝুঁকে থাকে। পাবলিক জাস্টিস সেন্টার: আমেরিকাকে অবিচার ও বৈষম্যের সাথে একটি জাতি হিসাবে দেখে, এই সংস্থাটি আইন ও নীতি ওকালতিতে হস্তক্ষেপ করে অবহেলিতদের জন্য পদ্ধতিগত পরিবর্তন প্রচার করতে।রিবিল্ড অ্যান্ড রিনিউ আমেরিকা নাউ (এ.কে.এ.ইউনিটি ০৯): মুভঅন.অর্গ এর নেতৃত্বে আর দীর্ঘদিনের কর্মী হিথার বুথের তত্ত্বাবধানে, এই জোট গঠিত হয়েছিল প্রেসিডেন্ট ওবামাকে ২০১০ সালের জন্য ৩.৫ ট্রিলিয়ন ডলারের ঐতিহাসিক বাজেট পাসের সুবিধার্থে।রেস পাবলিকা: সারা বিশ্বের বিভিন্ন জায়গায় দূর-বামের এজেন্ডা এগিয়ে নেওয়ার চেষ্টা করে, আরপি ই-অ্যাডভোকেসি বা ওয়েব-ভিত্তিক আন্দোলন-ভবনে বিশেষজ্ঞ। স্টেট প্রজেক্টের সেক্রেটারি: এই প্রকল্পটি ২০০৬ সালের জুলাই মাসে ডেমোক্র্যাটদের নির্বাচিত সুইং বা যুদ্ধক্ষেত্রে সেক্রেটারি অফ স্টেটের অফিসে নির্বাচিত হতে সহায়তা করার জন্য নিবেদিত একটি স্বাধীন ৫২৭ সংস্থা হিসাবে শুরু হয়েছিল। প্রেরণ প্রকল্প: কারাগারে-সেন্সিং প্যাটার্নগুলি জাতিগতভাবে বৈষম্যমূলক, এই উদ্যোগটি অপরাধীদের পক্ষে ভোট দেওয়ার অধিকার সমর্থন করে। সামাজিক ন্যায়বিচার নেতৃত্ব: এই সংস্থাটি একটি নতুন সামাজিক-ন্যায়বিচার আন্দোলনের মাধ্যমে কথিত নির্দোষ আমেরিকাকে কেবল সমাজে রূপান্তরিত করতে চায়।শ্যাডো ডেমোক্রেটিক পার্টি: এটি জর্জ সোরোস এবং অন্যদের দ্বারা সংগঠিত অলাভজনক একটিভিস্ট গ্রুপগুলির একটি বিস্তৃত নেটওয়ার্ক যা সম্পদ অর্থ সংগ্রহ, ভোটের মাধ্যমে বেরিয়ে যাওয়া ড্রাইভ, প্রচারণা বিজ্ঞাপন এবং গণতান্ত্রিক প্রার্থীদের নির্বাচিত করার জন্য নীতি উদ্যোগ এবং বাম দিকে ডেমোক্রেটিক পার্টিকে গাইড করার জন্য সংগঠিত। সোজুরনার্স: এই ধর্মপ্রচারক খ্রিস্টান মন্ত্রিসভা মৌলিক বামপন্থী রাজনীতি প্রচার করে।১৯৮০-এর দশকে এটি মধ্য আমেরিকায় কমিউনিস্ট বিপ্লবকে সমর্থন করে এবং সোভিয়েতদের সম্পর্কে সবচেয়ে খারাপ অনুমান করার প্রবণতার জন্য মার্কিন নীতি নির্ধারকদের শাস্তি দেয়।আরো সম্প্রতি, সজরনার্স পরিবেশ আন্দোলনের কারণ তুলে ধরেছে, কল্যাণ সংস্কারের বিরোধিতা করেছে একটি অর্থ-উদ্দেশ্যপ্রণোদিত রিপাবলিকান এজেন্ডা হিসাবে, এবং ইতিবাচক পদক্ষেপের পক্ষ সমর্থন করেছে। দক্ষিণ দারিদ্র্য আইন কেন্দ্র: এই সংস্থা মার্কিন যুক্তরাষ্ট্রে ঘৃণা গোষ্ঠী বলে অভিহিত কার্যকলাপ পর্যবেক্ষণ করে।এটি আমেরিকান সংখ্যালঘুদের বিরুদ্ধে পরিচালিত সাদা বর্ণবাদের প্রাদুর্ভাবকে অতিরঞ্জিত করে। স্টেট ভয়েসেস: এই জোট ২২ টি রাজ্যের স্বাধীন স্থানীয় সক্রিয় কর্মীদের একটি বছরের ভিত্তিতে যৌথভাবে কাজ করতে সহায়তা করে, যাতে তাদের প্রচেষ্টার প্রভাব সর্বাধিক করতে পারে। ক্রান্তিকাল নিয়ে কথা বলা: নিউইয়র্কের নতুন নির্বাচিত গণতান্ত্রিক মেয়র বিল ডি ব্লাসিওর জন্য সিটি হলে রূপান্তরে সহায়তা করার জন্য ২০১৩ সালের নভেম্বরের গোড়ার দিকে এটি দুই সপ্তাহের একটি প্রকল্প শুরু হয়েছিল। অগ্রগতি চিন্তা করুন: এই ইন্টারনেট ব্লগ তার রক্ষণশীল লক্ষ্যগুলির বিপরীতে প্রতিদিন পিছনে ফিরে যায় এবং দ্রুত যোগাযোগ, আইনী পদক্ষেপ, তৃণমূল এবং অ্যাডভোকেসি এবং বিশ্বব্যাপী অন্যান্য প্রগতিশীল নেতাদের সাথে অংশীদারিত্ব সংগঠিত করার মাধ্যমে প্রগতিশীল ধারণাগুলিকে নীতিতে রূপান্তর করার চেষ্টা করে।থান্ডার রোড গ্রুপ: এই রাজনৈতিক পরামর্শ, যার সৃষ্টিতে সোরোসের একটি হাত ছিল, মিডিয়া ফান্ড, আমেরিকা একত্র হচ্ছে এবং আমেরিকা ভোটস এর জন্য সমন্বয় কৌশল।টাইডস ফাউন্ডেশন এবং টাইডস সেন্টার: টাইডস মৌলিক বাম মার্কিন যুক্তরাষ্ট্রের একটি প্রধান তহবিল।পাবলিক ইন্টারেস্ট রিসার্চ গ্রুপ: এটি ছাত্র গোষ্ঠীর একটি ছাতা সংগঠন যা বামপন্থী এজেন্ডা সমর্থন করে। সার্বজনীন স্বাস্থ্যসেবা অ্যাকশন নেটওয়ার্ক: এই সংস্থা কেন্দ্রীয় সরকার দ্বারা নিয়ন্ত্রিত একক-পেয়ার স্বাস্থ্য সেবা ব্যবস্থাকে সমর্থন করে। আরবান ইনস্টিটিউট: এই গবেষণা সংস্থা সামাজিক ঔষধ, ফেডারেল কল্যাণ আমলাতন্ত্রের সম্প্রসারণ এবং উচ্চ আয়ের-মালিকদের জন্য কর বৃদ্ধিকে সমর্থন করে। ইউএসএকশন এডুকেশন ফান্ড: ইউএসএকশন তার অগ্রাধিকারগুলির তালিকা করে যেমন: সঠিক পক্ষের এজেন্ডার বিরুদ্ধে লড়াই করা; তৃণমূল রাজনৈতিক ক্ষমতা গড়ে তোলা; সকলের জন্য সামাজিক, জাতিগত ও অর্থনৈতিক ন্যায়বিচার শিক্ষিত করা; করদাতাদের অর্থায়নে সামাজিক ঔষধের একটি সিস্টেমকে সমর্থন করা; মিলিয়নিয়ার এবং কর্পোরেশনগুলির জন্য বেপরোয়া কর কর্তনকে পুনরুজ্জীবিত করা যা তাদের নির্বাচিত পরিবেশগত বিষয়গুলির ন্যায্য ও প্রগতিশীল সরকারের পক্ষে কাজ করে; নির্বাচিত পরিবেশগত বিষয়গুলির জন্য তাদের কর্মপরিবেশগত কণ্ঠস্বরকে সমর্থন করে।ভোটো ল্যাটিনো: এই দলটি ল্যাটিন-আমেরিকানদের নিবন্ধিত ভোটার এবং রাজনৈতিক কর্মী হওয়ার জন্য একত্রিত করতে চায়। আমরা আমেরিকা জোট: এই জোট আমেরিকান রাজনৈতিক প্রক্রিয়ায় অভিবাসীদের দ্বারা নাগরিক অংশগ্রহণ বৃদ্ধিকে উৎসাহিত করে। ওয়ার্কিং ফ্যামিলিস পার্টি: সমাজতান্ত্রিক নতুন পার্টির বিকাশ, ডাব্লুএফপি বাম দিকে ডেমোক্রেটিক পার্টিকে চাপ দিতে সহায়তা করার চেষ্টা করে। নির্যাতনের বিরুদ্ধে ওয়ার্ল্ড অর্গানাইজেশন: এই জোট এমন দলগুলির সাথে ঘনিষ্ঠভাবে কাজ করে যারা ফিলিস্তিনি সন্ত্রাসবাদের বিরুদ্ধে ইসরায়েলি নিরাপত্তা ব্যবস্থাকে নিন্দা করে। ওয়াইডব্লিউসিএ ওয়ার্ল্ড অফিস, সুইজারল্যান্ড: ওয়াইডব্লিউসিএ সংযম শিক্ষার বিরোধিতা করে; করদাতা-অর্থায়িত গর্ভপাত-অন-ডেমান্ডের সার্বজনীন প্রবেশাধিকার সমর্থন করে; এবং স্কুল ভাউচারের বিরোধিতা করে।জর্জ সোরোস নেটওয়ার্কের মাধ্যমিক বা পরোক্ষ অধিভুক্তি সরাসরি জর্জ সোরোস এবং তার ওপেন সোসাইটি ইনস্টিটিউট (ওএসআই) দ্বারা অর্থায়ন করা সংস্থা ছাড়াও সোরোস নেটওয়ার্কের অসংখ্য মাধ্যমিক বা পরোক্ষ অনুমোদিত রয়েছে।এর মধ্যে আছে সেইসব সংস্থা যা সোরোস আর ওএসআই থেকে সরাসরি অর্থ পায় না, কিন্তু যা এক বা একাধিক সংস্থার দ্বারা অর্থায়ন করা হয়।- ড. রিচ সুইয়ার জর্জ সোরোসের সাথে সংশ্লিষ্ট সকল গৌণ গ্রুপের তালিকার জন্য, এখানে যান\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in final_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "Di5Ii3japzTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', final_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNLWYZP-oKns",
        "outputId": "ea5cdd66-f152-4897-e47b-03b4b26852e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শোকজগত ১৭ সেপ্টেম্বর বাংলাদেশ কৃষি বিশ্ববিদ্যালয়ে (বাকৃবি) উপাচার্যের কার্যালয়ে হট্টগোলের ঘটনায় দুইজনকে সাময়িক বরখাস্ত ও ছয় জনকে শোকজ করেছে বিশ্ববিদ্যালয় প্রশাসন। বুধবার বিশ্ববিদ্যালয় বাকৃবি রেজিস্ট্রার সাইফুল ইসলাম স্বাক্ষরিত এক নোটিশে আগামী ৭ দিনের মধ্যে উপযুক্ত উত্তর দেয়ার নির্দেশ দেয়া হয়েছে। এদিকে এ ঘটনায় আন্দোলনের সঙ্গে একাত্বতা প্রকাশ না করায় হামলার শিকার হয়ে কারিগরি কর্মচারী পরিষদের সভাপতি ও সাধারণ সম্পাদক হাসপাতালে ভর্তি হয়েছেন। সাময়িক বরখাস্তরা হলেন- শিক্ষা বিষয়ক শাখার কর্মচারী ও ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন ও কর্মকর্তা পরিষদের যুগ্ম সম্পাদক জিয়াউর রহমান টিটু। এছাড়া বিশ্ববিদ্যালয় সম্প্রসারণ কেন্দ্রের সহকারী পরিচালক মোহাম্মদ আবুল বাসার আমজাদ, ডেপুটি লাইব্রেরিয়ান মো.খাইরুল আলম নান্নু, মো.আবদুল বাতেন, ক্রীড়া প্রশিক্ষণ বিভাগের মোহাম্মদ মোস্তাইন কবীর সোহেল, সংস্থাপন শাখার সহকারী রেজিস্ট্রার মোহাম্মদ আশিকুল আলম বাচ্চু ও খামার ব্যবস্থাপনা শাখার অ্যাডিশনাল রেজিস্ট্রার ড. মো. হেলাল উদ্দীনকে কারণ দর্শানোর নোটিশ দেয় প্রশাসন।  নোটিশে উল্লেখ করা হয়, গত সোমবার দুপুরে সোয়া ১২টার দিকে উপাচার্যের অনুমতি ছাড়াই হঠাৎ করে উপাচার্যের কার্যালয়ে প্রবেশ করে ছাত্র বিষয়ক উপদেষ্টা, প্রক্টর, ডিন কাউন্সিলের আহ্বায়ক, রেজিস্ট্রার ও সাংবাদিকদের সামনে উপাচার্য ও উপ-উপাচার্যকে লক্ষ্য করে আঙ্গুল উচিয়ে কটুক্তি করে এবং অশালীন শারীরিক অঙ্গভঙ্গি করে। এতে করে বিশ্ববিদ্যালয়ের উচ্চ পর্যায়ের প্রাশাসনিক কার্যক্রম ব্যাহত হয় এবং উপাচার্যের সঙ্গে দুর্ব্যবহার করে যা বিশ্ববিদ্যালয়েল চাকরি সংবিধির সুস্পষ্ট লঙ্ঘন ও গুরুতর অপরাধ। এদিকে প্রশাসনের কারণ দর্শানোর নোটিশ পাওয়ার পর অফিসার পরিষদের নেতারা মিছিল নিয়ে হিসাব সংরক্ষণ শাখা, প্রকৌশল শাখা, পরিকল্পনা ও উন্নয়ন শাখায় তালা ঝুঁলিয়ে দেয়। তবে প্রশাসন ভবনে পুলিশ মোতায়ন থাকায় তালা দিতে ব্যর্থ হয়। কর্মকর্তাদের সঙ্গে একাত্বতা প্রকাশ করে কর্মচারীরাও ক্যাম্পাসে মিছিল করে। এসময় তারা প্রশাসনের বিরুদ্ধে বিভিন্ন ধরনে শ্লোগান দিতে থাকে।  এদিকে কারিগরি কর্মচারী পরিষদের পক্ষ থেকে আন্দোলনে সঙ্গে একাত্বতা প্রকাশ না করায় হামলা করে ৩য় ও চতুর্থ শ্রেণির কর্মচারীরা। এবিষয়ে কারিগরি কর্মচারী পরিষদের সভাপতি মো. আবদুল মোতালেব বলেন, আমরা চার দফা দাবিতে ঐক্যবদ্ধ হয়েছিলাম। গত ১৭ সেপ্টেম্বর আমাদের রেখেই ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন কর্মকর্তাদের সঙ্গে ভিসি সচিবালয়ে ঢুকে ভিসির সঙ্গে বেয়াদবি করে। পরবর্তীতে তাকে বিশ্ববিদ্যালয় থেকে শোকজ করলে আমাকে ও আমার সংগঠনের সকলকে তাদের সঙ্গে আন্দোলনে যেতে বলে। যোগ না দিলে পরে ৩য় ও ৪র্থ শ্রেণি মিলে আমাদের সংগঠনে হামলা করে, চেয়ার ভাঙে। এ ঘটনায় আমি ও আমার সংগঠনের সাধারণ সম্পাদক সুলতান আহমেদ আহত হয়ে বর্তমানে ময়মনসিংহ হাসপাতালে ভর্তি আছি। মো. শাহীন সরদার/আরএ/আরআইপি\n",
            "Token IDs: tensor([    2, 27217,  6605,     1,  3805,   464, 19391, 10863, 12240,    16,\n",
            "          275,  5550,  6429, 19608,   431,  2791,  4309,  1086,  5046,     1,\n",
            "           12,  3805,   464,   893,    13, 19942,     1, 27217, 30374,     1,\n",
            "        10863,   772,     1, 12240,   219,     1,  5550,  6429,   412,  1333,\n",
            "            1,  4280,   205,  3488,     1,  3805,   464,   893, 18669, 10488,\n",
            "         1514, 17198,   788, 11184,   410,  2649,   276,  2180,  1021,  6791,\n",
            "         1650,     1,  2265,     1,     1,   205,  3060,   217,     1,  4735,\n",
            "         1031,  1981,  1533,   905,  1482,   795,     1,  5108,  3404,     1,\n",
            "        13330,  7826,  4140,  2403,   219,  1728,  2421,  2717,  2814,     1,\n",
            "          205,     1, 12240,   825,  3169,    17,  2490,     1,  7723,  7826,\n",
            "          219,     1,  6785,  1728,  2421,  1074,    18, 27095,  2131,   219,\n",
            "         2444,  4140,  7306,  2421,     1,  1814,  1594,  1156,   205,     1,\n",
            "            1, 15308,  6419,  4538,  3293,  3391,  4645,  6213, 17593,    16,\n",
            "        10571,     1,  1074,    18,  3814,  5245,  3199,  4251, 28209,    16,\n",
            "         1074,    18,  2907,  2374,   818,    16,     1,  5433,  3209,  3391,\n",
            "         5994,  1663, 13719,  9997,    16,  3145,  2117,  7723,  4538, 18669,\n",
            "         3391, 18521,   808,  3199, 17627,   219, 13891,  6557,  7723,  5529,\n",
            "         4008,   780, 18669,   233,    18,  1074,    18, 15808, 12743,   772,\n",
            "         1155,  2798,  1568, 11184,     1,  4280,   205, 11184,   410,  2528,\n",
            "          913,     1,    16,  1192,  3374,  3828,     1, 12859,  1097, 19942,\n",
            "         4484,     1,  1821,   792, 19942,     1,  3096,   792,  1592,     1,\n",
            "         7343,    16, 26108,    16, 12498, 13042,     1,    16, 18669,   219,\n",
            "         5884,  1418,  7721,   219,   973,    17,  7721,   772,  2686,   792,\n",
            "        11060,     1, 28053,  1308,   792,   903, 26444,  5645,  4057, 11522,\n",
            "          792,   205,  2049,   792,     1,  2353,     1,  1443, 11206,   783,\n",
            "         4916, 15387,     1,   903, 19942,  1031,  7158, 20058,   792,   866,\n",
            "            1,  3236,  5013, 10079, 11470, 12265,   219,  6639,  2558,   205,\n",
            "         3060,  5596,  1155,  2798,  1568, 11184,     1,   804,  4071,  4140,\n",
            "         5323,  4781,     1,  4256,  7945,  6412,    16,  9378,  6412,    16,\n",
            "         3417,   219,     1,     1,  7907,     1,     1,   205,  1079,  4280,\n",
            "         8932,  1275,     1,     1,  7907,  1251,  3710,     1,   205,  7810,\n",
            "         1031,  1981,  1533,   905,  1482,   792, 18533,   463, 10528,  4781,\n",
            "          792,   205,     1,  1170,  5596,  1673,  1431, 10354,   410, 18506,\n",
            "         1251,  1117,   205,  3060, 13330,  7826,  4140,  2447,   842,  7443,\n",
            "         1031,  1981,  1533,   905,  1482,   795,     1,  3794,   792,     1,\n",
            "          219,  5683,  6785, 18533,   205,     1, 13330,  7826,  4140,  2403,\n",
            "         1074,    18,  2907, 30141,  1071,    16,  1062,  1315,  6838,  5907,\n",
            "        11785,     1,   205,  1192,  2791,  4309,  1029, 10023,     1,  6785,\n",
            "         1728,  2421,  1074,    18, 27095,  2131,  7810,  1031, 28393,     1,\n",
            "         2881, 28393,   411,  1031,     1,   792,   205,  6256,  1339,     1,\n",
            "          842,  6429,   412,  1978,  1258,   219,   878,  5247,  9458,  1060,\n",
            "         1031,  7443,  1413,   896,   205,  1524,   795,  3004,  1231,     1,\n",
            "          219, 21088, 11141,  2979,  1029, 31074,  3794,   792,    16,     1,\n",
            "        16712,   205,   217,     1,   857,   219,   878,  5247,  1728,  2421,\n",
            "         7846,  3232,  3207,     1,  3134,     1,  2717,  2814,  2548,   205,\n",
            "         1074,    18, 15992, 14599,    19,   815,   440,    19,   815, 18142,\n",
            "            3,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0oUn0Olq_Or",
        "outputId": "dbb55b91-0365-4fce-e049-db59330b64c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8,513 training samples\n",
            "1,503 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "0QLU1GDVrPqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"csebuetnlp/banglabert\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "646f187e221c4a249c06b35a68dcc33b",
            "08fa1a9181684b64af9b47b88d190b64",
            "62ace4f252ba41b6bf12e3b7598bb494",
            "e7c6b8352e2a49b59d0537445f85c7c3",
            "ab845949d13f429a8f6e7d0b5735b671",
            "15a65a529a9d4867b33bb69963ba5ecb",
            "11ec58c654f74ad3a291705589014053",
            "d2c6eb12c8d7455d9b2627ae0bcd356b",
            "3aabc6364ddb4077a39de2089cbe75b1",
            "71280175a5894acc9f5343df2ee7fb3c",
            "bfadb332b2de486a8e0c97ddc99605d7"
          ]
        },
        "id": "Q1TqBQ9Rr-Pt",
        "outputId": "9feef988-1068-43f5-af4a-7b1ed061adfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/config.json\n",
            "You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"ElectraForPreTraining\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/443M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "646f187e221c4a249c06b35a68dcc33b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--csebuetnlp--banglabert/snapshots/9ce791f330578f50da6bc52b54205166fb5d1c8c/pytorch_model.bin\n",
            "Some weights of the model checkpoint at csebuetnlp/banglabert were not used when initializing BertForSequenceClassification: ['electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'discriminator_predictions.dense.bias', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.embeddings.position_ids', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.3.attention.output.dense.weight', 'discriminator_predictions.dense_prediction.weight', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'discriminator_predictions.dense.weight', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.10.attention.output.dense.bias', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.6.intermediate.dense.bias', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'discriminator_predictions.dense_prediction.bias', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.10.attention.self.value.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at csebuetnlp/banglabert and are newly initialized: ['encoder.layer.5.attention.self.value.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.2.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.5.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.weight', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.8.output.dense.weight', 'encoder.layer.6.output.LayerNorm.bias', 'pooler.dense.weight', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.9.output.dense.weight', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.4.output.dense.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.0.output.dense.weight', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.5.output.dense.bias', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.10.output.dense.weight', 'encoder.layer.4.output.LayerNorm.bias', 'pooler.dense.bias', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.8.output.dense.bias', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.0.attention.output.LayerNorm.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.11.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.4.output.dense.bias', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.10.attention.self.query.bias', 'embeddings.LayerNorm.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'classifier.weight', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.0.attention.self.key.weight', 'classifier.bias', 'encoder.layer.4.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.1.output.dense.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.3.output.dense.bias', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.11.output.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "id": "DYFhvbHWsgG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "eNweRhQCsl00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0RmMrCAs5wL",
        "outputId": "360593f1-23f4-45d8-f08b-896fb09be2f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:03.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:02.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:02.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:01.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:00.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:00.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:59.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:58.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:57.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:57.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:56.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:56.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:55.\n",
            "\n",
            "  Average training loss: 0.24\n",
            "  Training epcoh took: 0:13:13\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.95\n",
            "  Validation Loss: 0.18\n",
            "  Validation took: 0:00:50\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    533.    Elapsed: 0:01:59.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:58.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:57.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:57.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:56.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:55.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:55.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:54.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:53.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:52.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:52.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:51.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:13:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.96\n",
            "  Validation Loss: 0.17\n",
            "  Validation took: 0:00:50\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    533.    Elapsed: 0:01:59.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:58.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:57.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:56.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:56.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:55.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:54.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:54.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:53.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:53.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:52.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:51.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:13:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:00:51\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    533.    Elapsed: 0:01:59.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:58.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:57.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:57.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:56.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:56.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:55.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:54.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:53.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:53.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:52.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:51.\n",
            "\n",
            "  Average training loss: 0.06\n",
            "  Training epcoh took: 0:13:09\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:00:51\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:56:03 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TM_fnfn : tahsin mayeesha finetune+finetune (first fine tuned with regular train, then model summarized train data)\n",
        "model.save_pretrained('/content/drive/MyDrive/saved_models/csebuetbb/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuZSUSwvyb-Y",
        "outputId": "adbc11d6-75a3-4e50-a2da-e4943261ad8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/saved_models/csebuetbb/config.json\n",
            "Model weights saved in /content/drive/MyDrive/saved_models/csebuetbb/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load data for 2nd fine tune"
      ],
      "metadata": {
        "id": "OXxZ4EBq78PZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading models\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/saved_models/csebuetbb/\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "loaded_model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEJPWWQkSjQV",
        "outputId": "4a030130-2c66-4e02-d676-6457f70930e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/saved_models/csebuetbb/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"csebuetnlp/banglabert\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/saved_models/csebuetbb/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/saved_models/csebuetbb/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#path2 contains modelsum_train\n",
        "final_df = pd.read_csv(path2)"
      ],
      "metadata": {
        "id": "slFEmH3T720N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MODEL TRAINING 2 (modesum train data)"
      ],
      "metadata": {
        "id": "N7B1q5Vy7hcS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in final_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "omqXOkBa7hci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', final_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ac5a9f6-a75f-469c-cf38-ca68f39d3e66",
        "id": "RyUFqJpz7hcj"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  বাংলাদেশের কৃষি বিশ্ববিদ্যালয়ে উপাচার্যের কার্যালয়ে হট্টগোলের ঘটনায় দুইজনকে সাময়িক বরখাস্ত ও ছয় জনকে শোকজ করেছে বিশ্ববিদ্যালয় প্রশাসন। বাকৃবিতে হামলাকারীদের কারণ দর্শানোর নোটিশ দেয়া হয়েছে গত ১৭ সেপ্টেম্বরের দুপুরে। এ ঘটনাকে কেন্দ্র করে   Kuniকেল কোর্টের নির্দেশ অনুযায়ী আগামী ৭ দিনের মধ্যে উত্তর দেয়ার পরামর্শ দিয়েছেন বিশ্ববিদ্যালয়ের শিক্ষার্থীরা।. এর সঙ্গে BBC 코리아 .. ( ) - এই নিয়ে , বিবিসি । (সংবাদিকদের ধারণা : 'আন্তর্জাতিক নকল প্রকাশ বন্ধ করে দেয় প্রধান পক্ষ সরকার।'  এ বিভক্তি সবসময়ই হলেও, এখনো এ বিষয়ে আবারো আলোচনা চলছে। তবে এবারের আন্দোলনে এমন তিনজনকে গ্রেপ্তার করা হচ্ছে নতুন করে দুইজন বিশ্ববিদ্যালয় শিক্ষক এবং শিক্ষকদের বিরুদ্ধে বিভিন্ন ক্ষেত্রে আন্দোলন শুরু হওয়ার পর এখন পর্যন্ত সাক্ষীর সংখ্যা ছাড়াও এসব ব্যবস্থা গ্রহণ করতে চাইছে ছাত্র অধিকার সংগঠনগুলোর একটি বড় অংশের সাথে সামাজিক যোগাযোগ মাধ্যম ভিত্তিক সূত্রগুলোয় দেখা গেছে, যেখানে এ ধরণের বিতর্ক চরমে পৌঁছানো হয়েছে একাধিক অভিযোগের কথা রয়েছে এখানকার বিশ্ববিদ্যালয় কর্তৃপক্ষ।\n",
            "Token IDs: tensor([    2,  1631,  5046,  5300, 19942,  6698, 27217, 30374,  3142, 10863,\n",
            "          772,  7683, 12240,   219,  2665,  5550,  6429,   412,  1333,  3107,\n",
            "         4280,   205,  3805,   464, 19391, 29300,  1155,  2798,  1568, 11184,\n",
            "         2096,   975,  1192,  2791, 23352,  3828,   205,   217, 15244,  1947,\n",
            "          792,    47,  3325,   455,  2325,  9847,  2265,  2728,  2649,   276,\n",
            "         2180,  1021,  1650,  4272,  3686,  2236,  2769,  7057,   205,    18,\n",
            "          919,  1031,    38,   473,   484,     1,    18,    18,    12,    13,\n",
            "           17,   830,   888,    16,  9140,   205,    12,  2287,   783,   833,\n",
            "         2949,    30,    11,  2760,  9580,  1482,  1169,   792,  1386,  1415,\n",
            "         2447,  1150,   205,    11,   217, 26226, 15485,  2045,    16,  2127,\n",
            "          217,  1876,  8014,  2613,  2322,   205,  1079,  6089,  7443,  1119,\n",
            "        16010,  3441,   913,  1140,  1299,   792, 10863,  3107,  2625,   903,\n",
            "         8181,  1673,  1431,  1875,  3229,  1116,  1730,   804,  1004,  1358,\n",
            "        27983,  2300,  4569,  1613,  1718,  2423,   924,  5656,  1592,  2533,\n",
            "        31956,   990,  1109,  8217,  1042,  3022,  2661,  7079, 11104,  2708,\n",
            "        14228,  1189,  1232,    16,  2192,   217,  6097,  5120, 26200, 22511,\n",
            "          975,  4199,  8460,   917,  1401,  6840,  3107,  3049,   205,     3,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90daa39f-d8c5-462d-a7ae-c94367aa26ce",
        "id": "BZVrpwzh7hck"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8,513 training samples\n",
            "1,503 validation samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "9XGNi9S97hck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = loaded_model\n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"Tahsin-Mayeesha/bangla-fake-news-mbert\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "#                     # You can increase this for multi-class tasks.   \n",
        "#     output_attentions = False, # Whether the model returns attentions weights.\n",
        "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# )\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb6d5eb4-39e5-4a2f-edf9-6ec940e94551",
        "id": "P5qE-wZd7hcl"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ],
      "metadata": {
        "id": "fzVp6fL27hcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ],
      "metadata": {
        "id": "73ZGCd4U7hcm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c20478b-98c3-4597-e252-887ecd49ba45",
        "id": "CdF2QQ4u7hcn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:00:59.\n",
            "  Batch    80  of    533.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:55.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:53.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:52.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:50.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:48.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:47.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:45.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:43.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:41.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:39.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:38.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:12:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:50\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    533.    Elapsed: 0:01:57.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:55.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:53.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:51.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:49.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:47.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:46.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:44.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:42.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:40.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:39.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:37.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:12:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:50\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    533.    Elapsed: 0:01:56.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:54.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:53.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:51.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:49.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:47.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:45.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:43.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:41.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:39.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:38.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:36.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:12:53\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.10\n",
            "  Validation took: 0:00:50\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:00:58.\n",
            "  Batch    80  of    533.    Elapsed: 0:01:56.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:54.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:53.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:51.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:49.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:47.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:45.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:43.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:41.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:40.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:38.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:36.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:12:54\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:50\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:54:56 (h:mm:ss)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TM_fnfn : tahsin mayeesha finetune+finetune (first fine tuned with regular train, then model summarized train data)\n",
        "model.save_pretrained('/content/drive/MyDrive/saved_models/csebuetbb_fnfn/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d278f6fe-4320-4c3e-ccfb-a5aeb9e0d6c5",
        "id": "30E0E4h67hcp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/saved_models/csebuetbb_fnfn/config.json\n",
            "Model weights saved in /content/drive/MyDrive/saved_models/csebuetbb_fnfn/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#load model from saved\n"
      ],
      "metadata": {
        "id": "m1y2mQdbwGRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#loading models\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/saved_models/csebuetbb_fnfn/\",\n",
        "    num_labels = 2\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "loaded_model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4058e847-da40-4656-c9b9-5e49fb82993e",
        "id": "BUMXkhrU7hcq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/saved_models/csebuetbb_fnfn/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/saved_models/csebuetbb/\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"embedding_size\": 768,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"summary_activation\": \"gelu\",\n",
            "  \"summary_last_dropout\": 0.1,\n",
            "  \"summary_type\": \"first\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32000\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/saved_models/csebuetbb_fnfn/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/saved_models/csebuetbb_fnfn/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(32000, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing with test_df(regular)\n"
      ],
      "metadata": {
        "id": "ycrqMjV1z9ei"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5958fcd9-15b5-4f14-db12-4b1c95cccc69",
        "id": "UiW-7TD8z9ez"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "775c4c9f-391b-41a8-df97-16e95105f181",
        "id": "e5xOg7x_z9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e7794224-23c9-4566-a832-331769237e27\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e7794224-23c9-4566-a832-331769237e27')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e7794224-23c9-4566-a832-331769237e27 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e7794224-23c9-4566-a832-331769237e27');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "YwmV1eRzz9e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c0adf44-e0f7-488e-9bc1-e1f7c92d236d",
        "id": "68hgybTvz9e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  অধ্যাপক গোলাম আযম যে ইস্কুলের মাষ্টার, আমি সে ইস্কুলের চানাচুরওলা: কাদের সিদ্দিকী | দৈনিক মতিকণ্ঠনিজস্ব মতিবেদকচলমান মানবতাবিরোধী অপরাধের বিচার নিয়ে তীব্র ক্ষোভ প্রকাশ করে মুক্তিযুদ্ধকালে কাদেরিয়া বাহিনীর প্রধান বঙ্গবীর আবদুল কাদের সিদ্দিকী বীর উত্তম বলেছেন, এ দেশে কোনো মানবতাবিরোধী অপরাধী নেই। যে দুইজন মানবতাবিরোধী অপরাধী ছিলো, তাদের দেশছাড়া করা হয়েছে। তাদের একজন শহীদ প্রেসিডেন্ট মুক্তিযোদ্ধা জিয়াউর রহমান বীর উত্তমের সন্তান তারেক জিয়া এখন লন্ডনে ফুর্তি করছে। অপরজন বেগম খালেদা জিয়ার অপর সন্তান আরাফাত কোকো বেংককে গেংবেং করছে। দেশ তাই মানবতাবিরোধী অপরাধীমুক্ত।আজ এক সংবাদ সম্মেলনে আবদুল কাদের সিদ্দিকী এ কথা বলেন।তিনি আবেগঘন গলায় বলেন, অধ্যাপক গোলাম আযম একজন অধ্যাপক। তিনি অধ্যাপনা করতেন। মুক্তিযুদ্ধ চলাকালে তিনি টিক্কা খানের শিশুপুত্র খালিদ খানকে আমপারা অধ্যাপনা করতে টিক্কা খানের বাসভবনে যেতেন। অথচ বাকশালীরা গুজব রটিয়েছে তিনি মানবতাবিরোধী অপরাধে লিপ্ত ছিলেন। টিক্কার ছেলেকে আরবী শেখান কেন মানবতাবিরোধী অপরাধ হবে?কাদের সিদ্দিকী বলেন, অনেকেই বলে টিক্কার সাথে অধ্যাপক গোলাম আযমের অবৈধ যৌন সম্পর্ক আছে। তারা ভুল বলে। এ কথা মোটেও সত্য নয়। টিক্কা খান অনেক জোরাজুরি করলেও অধ্যাপক গোলাম আযম কখনও টিক্কার সাথে যৌন সম্পর্কে লিপ্ত হননি। তিনি তখনও পাক ছিলেন, এখনও পাক আছেন।অধ্যাপক গোলাম আযমের কাছে অস্ত্র জমা দিচ্ছেন কাদের সিদ্দিকীআবেগঘন গলায় তিনি বলেন, মুক্তিযুদ্ধের পর ভারতীয় সেনাবাহিনী আমাকে অস্ত্র সমর্পনের আদেশ দিয়েছিল। আমি তাদের বলেছিলাম, তুমাদের আমি চুদি না। এরপর বাংলাদেশ সেনাবাহিনী আমাকে অস্ত্র সমর্পনের আদেশ দিয়েছিল। আমি তাদের বলেছিলাম, তুমাদেরও আমি চুদি না। এরপর ১৯৭৮ সালে অধ্যাপক গোলাম আযম দেশে ফিরে আমাকে অস্ত্র সমর্পনের আদেশ দেন। আমি তখন বলেছিলাম, হুজুর আমি আপনাকেই শুধু চুদি। আপনারা জানেন, আমি অধ্যাপক গোলাম আযমের কদম মুবারকে আমার থ্রি নট থ্রি রাইফেলটি জমা দিয়েছিলাম। কাদের সিদ্দিকী দৃপ্ত কণ্ঠে বলেন, “অস্ত্র জমা দিয়েছি, ট্রেনিং জমা দেই নাই। অধ্যাপক গোলাম আযমের ডাকে দরকার হলে আবার আরেকটি মুক্তিযুদ্ধে ঝাপিয়ে পড়ব। পাক সার জমিন সাদ বাদ।”\n",
            "Token IDs: tensor([    2,  3840,  5862, 22899,   831, 31056,   411, 24713,    16,   857,\n",
            "          809, 31056,   411, 30993,  6457, 16036,    30,  5018, 13117,    96,\n",
            "         4897,  6342,  8506,   853,   412,  2118,  6342,  1820,   432,  3270,\n",
            "         1005, 15708,  8183,  1902,   888,  3879,  6488,  1482,   792,  3830,\n",
            "         1887,  5018,   951,  3854,  1415,  2584,  6145,  2907,  5018, 13117,\n",
            "         4070,  7638,  2150,    16,   217,  1772,  1078, 15708,  9890,  1052,\n",
            "          205,   831, 10863, 15708,  9890,  2109,    16,  1060,  1041,  2485,\n",
            "          913,   975,   205,  1060,  1313,  3791,  3108,  6623,  9808,  1814,\n",
            "         4070,  7638,   764,  2636,  8773,  3726,  1004, 10522, 27153,  1409,\n",
            "          205,  2253,   923,  4307,  4970,  6757,  2253,  2636, 20158, 10178,\n",
            "          413,   985,  2309,   772,  1038,   434,   778,   434,  1409,   205,\n",
            "         1041,  1070, 15708,  9890,  6991,   205,   997,   788,  2287,  4811,\n",
            "         2907,  5018, 13117,   217,   917,  1071,   205,   954,  4865, 14076,\n",
            "         3029,  1071,    16,  3840,  5862, 22899,  1313,  3840,   205,   954,\n",
            "         3625,   848,  3398,   205,  3830, 14026,   954, 27152,  6048,  2302,\n",
            "        10121, 16481, 15619,   785,  2035,   415,  3625,   848,   924, 27152,\n",
            "         6048, 20261, 11610,   205,  2506, 28129,  1465, 11202, 27957,  3075,\n",
            "          954, 15708, 10928, 10537,  1438,   205, 27152,   411,  5341, 18926,\n",
            "        14288,   418,  1107, 15708,  2558,   918,    35,  5018, 13117,  1071,\n",
            "           16,  3120,   896, 27152,   411,  1042,  3840,  5862, 22899,   764,\n",
            "         5083,  5021,  2377,   972,   205,  1170,  1771,   896,   205,   217,\n",
            "          917,  8434,  1441,  1087,   205, 27152,  1803,  1011,  2741,   812,\n",
            "         2029,  4428,  3840,  5862, 22899,  2973, 27152,   411,  1042,  5021,\n",
            "         2064, 10537, 10650,   205,   954,  5468,  1371,  1438,    16,  2493,\n",
            "         1371,  2274,   205,  3840,  5862, 22899,   764,  1068,  2948,  3280,\n",
            "         5492,  5018, 13117,   527,  3524, 14076,  3029,   954,  1071,    16,\n",
            "         5539,   804,  2572,  6571,  1258,  2948, 10019,   843,   863,  4233,\n",
            "         4022,   205,   857,  1060,  6925,    16,  6719,   856,   857, 14434,\n",
            "          944,   795,   205,  1973,  1086,  6571,  1258,  2948, 10019,   843,\n",
            "          863,  4233,  4022,   205,   857,  1060,  6925,    16,  6719,   856,\n",
            "          463,   857, 14434,   944,   795,   205,  1973, 18407,  1460,  3840,\n",
            "         5862, 22899,  1772,  1557,  1258,  2948, 10019,   843,   863,  4233,\n",
            "         1629,   205,   857,  1095,  6925,    16, 10453,   857, 31849,  1289,\n",
            "        14434,   944,   205,  3316,  3386,    16,   857,  3840,  5862, 22899,\n",
            "          764, 14392, 27247,   410,   878, 11537, 11844, 11537, 11434,   806,\n",
            "         3280,  8794,   205,  5018, 13117, 27806,  7171,  1071,    16,     1,\n",
            "         2948,  3280,  4488,    16, 10203,  3280,  4989,  1538,   205,  3840,\n",
            "         5862, 22899,   764,  4995,  2119,  1163,  1148,  4690, 10143, 23197,\n",
            "        19908,   205,  1371,  1397, 28519,  4147,  2355,   205,     1,     3,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgxoBxXDz9e1"
      },
      "source": [
        "We can see some of the results by the model here. Our model trains on half of the dataset and achieves around 0.80 in overall f1. Its likely that the model is trained longer it will achieve better performance. I might retrain it later on full data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "f4I0lcQmz9e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "QQlh9EFOz9e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "k_VLqVCNz9e2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#model = loaded_model\n",
        "loaded_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        outputs = loaded_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        _, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d8b14f3-d3d6-4dbe-d04b-e8fcdd8dbefd",
        "id": "1UaYkEw6z9e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.84\n",
            "  Test Loss: 1.07\n",
            "  Test took: 0:00:40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25c1f40a-da35-472e-aa09-d2594589e39c",
        "id": "y-5uNy9wz9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.71      0.82       600\n",
            "           1       0.77      0.96      0.86       600\n",
            "\n",
            "    accuracy                           0.84      1200\n",
            "   macro avg       0.86      0.84      0.84      1200\n",
            "weighted avg       0.86      0.84      0.84      1200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Testing with modelsum_test(summarized)\n"
      ],
      "metadata": {
        "id": "w9qmSLwBtG_1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path4 = '/content/drive/MyDrive/datasets/modelsum_test.csv'\n",
        "test_df = pd.read_csv(path4)"
      ],
      "metadata": {
        "id": "lnEQAJ67tR_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cad41be-1d87-4268-c31c-fef35393622a",
        "id": "wjakwioetG_3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a4ac9d2-083f-4d3c-b50e-70d04c36ab0b",
        "id": "WX7Lt9NhtG_5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "2fbe6de0-6dba-411a-d079-046e032dc6f7",
        "id": "yDdorCIHtG_6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  বাংলাদেশের জনপ্রিয় কথাসাহিত্যিক মোস্তফা কামাল...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3a2dbc9f-b206-4598-9be4-01e258453cf6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>বাংলাদেশের জনপ্রিয় কথাসাহিত্যিক মোস্তফা কামাল...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3a2dbc9f-b206-4598-9be4-01e258453cf6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3a2dbc9f-b206-4598-9be4-01e258453cf6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3a2dbc9f-b206-4598-9be4-01e258453cf6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ],
      "metadata": {
        "id": "xb-aFgRitG_7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07aecd1f-f764-4b62-ab45-331cd7ff55e2",
        "id": "KNUjhpu7tG_8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  বাংলাদেশে মানবতাবিরোধী অপরাধের বিচার নিয়ে তীব্র ক্ষোভ প্রকাশ করেছেন দৈনিক মতিকণ্ঠ। মুক্তিযুদ্ধের সময় বিএনপির চেয়ারপার্সন আবদুল কাদের সিদ্দিকী এবং তাঁর পরিবারের সদস্যরা তাকে গ্রেপ্তার ছাড়ার জন্য সরকার ব্যবস্থা গ্রহণ করেছে.  ,  BBC নিউজ এর পক্ষ থেকে এ বিষয়ে তৈরি কোন তথ্য বের হচ্ছে না - যার মধ্যে এক  Kuni ( ( ) ? ' বিবিসি ’ র সঙ্গে এখনও এই দেশে মানসিকতার বিচারে যুক্ত নেই .. এ সব ক্ষেত্রেই তারা গত কাল ঢাকায় জন্ম হল । এমন কী ভাবেন জাতিসংঘের একজন সাবেক প্রধানমন্ত্রী জিয়া খানকে গুলি করেন অধ্যাপক গোলাম আযমের বিরুদ্ধে যে অভিযোগ উঠেছে, সেই অভিজ্ঞতার কথা বললেও বিবিসির সংবাদ মাধ্যমে এসব খবর পাওয়া গেছে ইস্কুলের মাষ্টার, যিনি অবৈধভাবে টিক্কার সাথে যৌন সম্পর্কে লিপ্ত ছিলেন, তাদের দেশছাড়া তিনি এখনো বন্ধ করা হয়নি ; কিন্তু পাকিস্তানী নাগরিকদের কাছে এত মানুষের মত লোকজন এখানে আবারো যুদ্ধাপরাধীদের মৃত্যুর ঘটনা তো ঠিকই ছিলো, যে তিনজনের সামাজিক যোগাযোগ\n",
            "Token IDs: tensor([    2,  2712, 15708,  8183,  1902,   888,  3879,  6488,  1482,  1403,\n",
            "         4897,  6342,  8506,   205,  5539,   998,  3243, 10452, 19558,  2907,\n",
            "         5018, 13117,   903,  1096,  2602,  5688,  1339,  3441, 10595,   900,\n",
            "         1150,  1718,  2423,  1333,    18,    16,    38,   473,   484,  4411,\n",
            "          919,  2447,   842,   217,  1876,  1621,   886,  1859,  1296,  1140,\n",
            "          795,    17,  1843,  1021,   788,    47,  3325,   455,    12,    12,\n",
            "           13,    35,    11,  9140,     1,   247,  1031,  2493,   830,  1772,\n",
            "        19018, 10833,  1833,  1052,    18,    18,   217,   889,  9017,  1170,\n",
            "         1192,  1340,  3655,  1823,  1267,   205,  1119,  1165, 11731,  8192,\n",
            "         1313,  3109,  2696,  3726, 15619,  3131,  1050,  3840,  5862, 22899,\n",
            "          764,  1673,   831,  1660,  3274,    16,   983, 11251,   917, 10216,\n",
            "        19098,  2287,  1744,  1613,  1691,  1580,  1232, 31056,   411, 24713,\n",
            "           16,  3862, 15690, 27152,   411,  1042,  5021,  2064, 10537,  1438,\n",
            "           16,  1060,  1041,  2485,   954,  2127,  1169,   913,  1702,    31,\n",
            "          925,  8693,  9832,  1068,  1284,  1449,  1287,  3468,  1424,  8014,\n",
            "        11662,  3163,  1714,   846,  4492,  2109,    16,   831, 12770,  3022,\n",
            "         2661,     3,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyp994tntG_9"
      },
      "source": [
        "We can see some of the results by the model here. Our model trains on half of the dataset and achieves around 0.80 in overall f1. Its likely that the model is trained longer it will achieve better performance. I might retrain it later on full data."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ],
      "metadata": {
        "id": "ww40748CtG_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ],
      "metadata": {
        "id": "kQ5ly3hhtG_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "wwgOoNYYtG_-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#model = loaded_model\n",
        "loaded_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        outputs = loaded_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        _, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27e41244-e699-4784-fbe6-a553fc409f63",
        "id": "JWk58-BNtG__"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.74\n",
            "  Test Loss: 1.78\n",
            "  Test took: 0:00:40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d03e409-3184-428e-f80a-7015d9c11922",
        "id": "HkMU8ESktHAA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.62      0.70       600\n",
            "           1       0.69      0.86      0.77       600\n",
            "\n",
            "    accuracy                           0.74      1200\n",
            "   macro avg       0.75      0.74      0.73      1200\n",
            "weighted avg       0.75      0.74      0.73      1200\n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "QloXfBVVjlZh",
        "EhQIDJ6il66B",
        "XpmaLJWyNB2U"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e3bc2f42755e43b8addd126db7ac8573": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0968be02156441c98ccf60e028e7b6eb",
              "IPY_MODEL_65a363ffc8da4af2936e6074d8c99918",
              "IPY_MODEL_085f736599194a9a947ce31301482253"
            ],
            "layout": "IPY_MODEL_027d9b1021af4b33bf394fb4ccdc5aad"
          }
        },
        "0968be02156441c98ccf60e028e7b6eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94b5e2e0692f4ba881891cefcb846a4d",
            "placeholder": "​",
            "style": "IPY_MODEL_d0d778b77906414a833617e28959bf4a",
            "value": "Downloading: 100%"
          }
        },
        "65a363ffc8da4af2936e6074d8c99918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8fa4d2861eb42319af1883e9c347b6d",
            "max": 119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e65b59a9389d4adabb8a5caad0e9a9f0",
            "value": 119
          }
        },
        "085f736599194a9a947ce31301482253": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a2db8cb2415741328a77da14ffc16884",
            "placeholder": "​",
            "style": "IPY_MODEL_c2ae663cfd8841ad935e35e9b8a9c360",
            "value": " 119/119 [00:00&lt;00:00, 3.84kB/s]"
          }
        },
        "027d9b1021af4b33bf394fb4ccdc5aad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94b5e2e0692f4ba881891cefcb846a4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d0d778b77906414a833617e28959bf4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8fa4d2861eb42319af1883e9c347b6d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e65b59a9389d4adabb8a5caad0e9a9f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a2db8cb2415741328a77da14ffc16884": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2ae663cfd8841ad935e35e9b8a9c360": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51a2514a62bb4dba8a5c0b7c540f0bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6034aac1e738498fb47a81209e8188a8",
              "IPY_MODEL_d35216bcbc4f45fe8b2a640af685b5d8",
              "IPY_MODEL_4754ffbeaaa94223aba3a4d184cd8114"
            ],
            "layout": "IPY_MODEL_ddad42fb0e5641b1a9061412327e19ee"
          }
        },
        "6034aac1e738498fb47a81209e8188a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71287fb2ead540e3bb63760c1af5364f",
            "placeholder": "​",
            "style": "IPY_MODEL_79f428ec0a154105a0b78c71506e1246",
            "value": "Downloading: 100%"
          }
        },
        "d35216bcbc4f45fe8b2a640af685b5d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc9876037eef4bf2b2a9808587d9b922",
            "max": 586,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f1bd4a479ce46608ea7c91e4a7b3932",
            "value": 586
          }
        },
        "4754ffbeaaa94223aba3a4d184cd8114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd20d71fe0ff416ca25178daf56a2f91",
            "placeholder": "​",
            "style": "IPY_MODEL_bad96de964164378ab9e6009a1c47765",
            "value": " 586/586 [00:00&lt;00:00, 32.9kB/s]"
          }
        },
        "ddad42fb0e5641b1a9061412327e19ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71287fb2ead540e3bb63760c1af5364f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f428ec0a154105a0b78c71506e1246": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc9876037eef4bf2b2a9808587d9b922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f1bd4a479ce46608ea7c91e4a7b3932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fd20d71fe0ff416ca25178daf56a2f91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bad96de964164378ab9e6009a1c47765": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82b876a871f94638b39c249019cf0b42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8484962a482a4e65ba992d048b743957",
              "IPY_MODEL_59c6fc4013bf43abac6bd660fa99bd5c",
              "IPY_MODEL_cd04ad4207344931b299085ac2b97010"
            ],
            "layout": "IPY_MODEL_5a7d3903965a4514a76dbd67c11c7dea"
          }
        },
        "8484962a482a4e65ba992d048b743957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f55487bb3fed4a46b601a2b3be838968",
            "placeholder": "​",
            "style": "IPY_MODEL_99a975912d584c71bce1d8b13cca9f52",
            "value": "Downloading: 100%"
          }
        },
        "59c6fc4013bf43abac6bd660fa99bd5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f1f1937a3f34ace8f892e89a6e64e05",
            "max": 528316,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea8763a67dcd42f8a10a54d8e1066417",
            "value": 528316
          }
        },
        "cd04ad4207344931b299085ac2b97010": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f5918c008e4f4e4091e6e6482a977814",
            "placeholder": "​",
            "style": "IPY_MODEL_355d879e18d24e9ab90a60c51ea59d62",
            "value": " 528k/528k [00:00&lt;00:00, 1.66MB/s]"
          }
        },
        "5a7d3903965a4514a76dbd67c11c7dea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f55487bb3fed4a46b601a2b3be838968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99a975912d584c71bce1d8b13cca9f52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f1f1937a3f34ace8f892e89a6e64e05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea8763a67dcd42f8a10a54d8e1066417": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f5918c008e4f4e4091e6e6482a977814": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "355d879e18d24e9ab90a60c51ea59d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e0cb278e85af450fa4a294a07a2d12c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d3e237441683473ab5f94f94ee0147a8",
              "IPY_MODEL_d5b86415119e489a8e8576e4e6034f32",
              "IPY_MODEL_55c8379f1b4147d69dc6eca7bc1b8462"
            ],
            "layout": "IPY_MODEL_9d1b155f53df4b9db376f578a021dd26"
          }
        },
        "d3e237441683473ab5f94f94ee0147a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_478da4110a15429e97141cb65c735131",
            "placeholder": "​",
            "style": "IPY_MODEL_49411b4d82df440b9176df393e02b440",
            "value": "Downloading: 100%"
          }
        },
        "d5b86415119e489a8e8576e4e6034f32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a986a0216044e41923ce7cc8853c8d5",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_512f5bf7fdcc4853a5e6f5ef1fd2a0e1",
            "value": 112
          }
        },
        "55c8379f1b4147d69dc6eca7bc1b8462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d05c1d207594c24840a5aaa931cb544",
            "placeholder": "​",
            "style": "IPY_MODEL_31b5f253cff442748bdb559a542276c0",
            "value": " 112/112 [00:00&lt;00:00, 6.22kB/s]"
          }
        },
        "9d1b155f53df4b9db376f578a021dd26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "478da4110a15429e97141cb65c735131": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49411b4d82df440b9176df393e02b440": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a986a0216044e41923ce7cc8853c8d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "512f5bf7fdcc4853a5e6f5ef1fd2a0e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4d05c1d207594c24840a5aaa931cb544": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31b5f253cff442748bdb559a542276c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "646f187e221c4a249c06b35a68dcc33b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08fa1a9181684b64af9b47b88d190b64",
              "IPY_MODEL_62ace4f252ba41b6bf12e3b7598bb494",
              "IPY_MODEL_e7c6b8352e2a49b59d0537445f85c7c3"
            ],
            "layout": "IPY_MODEL_ab845949d13f429a8f6e7d0b5735b671"
          }
        },
        "08fa1a9181684b64af9b47b88d190b64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_15a65a529a9d4867b33bb69963ba5ecb",
            "placeholder": "​",
            "style": "IPY_MODEL_11ec58c654f74ad3a291705589014053",
            "value": "Downloading: 100%"
          }
        },
        "62ace4f252ba41b6bf12e3b7598bb494": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d2c6eb12c8d7455d9b2627ae0bcd356b",
            "max": 442560329,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3aabc6364ddb4077a39de2089cbe75b1",
            "value": 442560329
          }
        },
        "e7c6b8352e2a49b59d0537445f85c7c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71280175a5894acc9f5343df2ee7fb3c",
            "placeholder": "​",
            "style": "IPY_MODEL_bfadb332b2de486a8e0c97ddc99605d7",
            "value": " 443M/443M [00:06&lt;00:00, 73.6MB/s]"
          }
        },
        "ab845949d13f429a8f6e7d0b5735b671": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15a65a529a9d4867b33bb69963ba5ecb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11ec58c654f74ad3a291705589014053": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d2c6eb12c8d7455d9b2627ae0bcd356b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3aabc6364ddb4077a39de2089cbe75b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "71280175a5894acc9f5343df2ee7fb3c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfadb332b2de486a8e0c97ddc99605d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}