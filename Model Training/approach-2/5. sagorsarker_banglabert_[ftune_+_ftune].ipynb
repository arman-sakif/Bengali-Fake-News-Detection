{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVbzepNk5h-X"
      },
      "source": [
        "##Pips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOq7B_40lDK9",
        "outputId": "32701d2b-ecaa-45f4-ba49-0b3a39669faa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLXleXuvNmOV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Ni-8Uqswow",
        "outputId": "dd3dce60-a7b1-4b6a-ef54-83b7be5ceb28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaUFAGkoOjw9"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeHFP-aKe8yS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEtV-2-RNpO5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQJ_1ZHyvhne"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spCh2Lun43Td"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "#note: importing something 2nd time does not cause any performance loss \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeSKEGgL6RaO"
      },
      "source": [
        "##Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKsvtoZ-6QuU"
      },
      "outputs": [],
      "source": [
        "path1 = '/content/drive/MyDrive/datasets/train.csv'\n",
        "path2 = '/content/drive/MyDrive/datasets/modelsum_train.csv'\n",
        "path3 = '/content/drive/MyDrive/datasets/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5EqTc526gg2"
      },
      "outputs": [],
      "source": [
        "final_df = pd.read_csv(path1)\n",
        "test_df = pd.read_csv(path3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycik9pTI6m26",
        "outputId": "1c1ccc88-8968-4c9d-ded5-fcf3129ff595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10016, 2), (1200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "final_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw2nWrN06ufX",
        "outputId": "6a483d63-b7f6-46c4-9e0b-0addcdbfe88b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5008\n",
              "0    5008\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#this is necessary because model won't run if there are NAN values. Though Training set is clean, this is for double check\n",
        "final_df = final_df.dropna() \n",
        "final_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ8u5GuJ6qiD",
        "outputId": "5bbb73a2-b5ce-4bbb-c486-fa601e611a89"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5008\n",
              "0    5008\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "final_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae5rhzVm6ySx",
        "outputId": "613beb1a-650e-479f-feb5-e97b7d67070f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      1  হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শো...\n",
              "1      1  মালয়েশিয়ায় কর্মী পাঠানোর ব্যবস্থা নেয়ার সুপারি...\n",
              "2      1  প্রেমের প্রস্তাবে রাজি না হওয়ায় স্কুলছাত্রীকে ...\n",
              "3      1  মেডিয়েশনই মামলাজট নিরসনের পথ : বিচারপতি আহমেদ ...\n",
              "4      1  টকশোতে বক্তব্য দিতে গিয়ে জাপা নেতার মৃত্যুমাদা..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3d582653-ea21-4cf1-a2cd-919aeff76ec8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শো...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>মালয়েশিয়ায় কর্মী পাঠানোর ব্যবস্থা নেয়ার সুপারি...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>প্রেমের প্রস্তাবে রাজি না হওয়ায় স্কুলছাত্রীকে ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>মেডিয়েশনই মামলাজট নিরসনের পথ : বিচারপতি আহমেদ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>টকশোতে বক্তব্য দিতে গিয়ে জাপা নেতার মৃত্যুমাদা...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d582653-ea21-4cf1-a2cd-919aeff76ec8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d582653-ea21-4cf1-a2cd-919aeff76ec8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d582653-ea21-4cf1-a2cd-919aeff76ec8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "final_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e8eKa460zXB"
      },
      "source": [
        "#prerequisites for model train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "e71ce1a8c11a4dbd9d04dec7cc0b839f",
            "1c3d9f91817949fab42e7b31caf6e1fc",
            "ed247d64a20649ff97fa16a3c10b12a9",
            "52c81f6e1ae4469bab4543c967e41d07",
            "40c9e1ebbbc549c89a933b0e1db22243",
            "4d324b2353524e01a6d95daa297e3997",
            "e77d100ccc75411d9c134b24c573c1d9",
            "7d9152a954644180a976432303cf4882",
            "116bf0cd6605422692b5f19e992eae72",
            "97665fb6c9d242a99c2f55897958ea1f",
            "43998f6084a94bccb1273091429a2513",
            "a8462402fb6f4d089bf03448a009de92",
            "d87c189509cf4e9f88b9c98ee5406911",
            "6e8b57dbe1174601833ce23696bd7894",
            "fbee4d0d018a4fd0b6c94b12dc34dd25",
            "9b762e3c8dc446189e9c5e3df84679cd",
            "84e3edea666147ee8bc94a4ee13845e2",
            "df27bcd352d64e8fad166d67b5e9f943",
            "fc2c136474404801868f606efb71477b",
            "b2e36512eb35492aa75137b305ddcafc",
            "d473c6b496ed450bac926920b51fe545",
            "548b2c9c752d4b7fab5300f2bab94bfe"
          ]
        },
        "id": "3f-UgLMel4fl",
        "outputId": "acab277c-3f67-4ff4-c67c-6f7ed886b6cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Could not locate the tokenizer configuration file, will try to use the model config instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/491 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e71ce1a8c11a4dbd9d04dec7cc0b839f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sagorsarker--bangla-bert-base/snapshots/315fa6f024884c29b34a3909a016decc2b068222/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"sagorsarker/bangla-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 102025\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.24M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8462402fb6f4d089bf03448a009de92"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--sagorsarker--bangla-bert-base/snapshots/315fa6f024884c29b34a3909a016decc2b068222/vocab.txt\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at None\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sagorsarker--bangla-bert-base/snapshots/315fa6f024884c29b34a3909a016decc2b068222/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"sagorsarker/bangla-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 102025\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sagorsarker--bangla-bert-base/snapshots/315fa6f024884c29b34a3909a016decc2b068222/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"sagorsarker/bangla-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 102025\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# from transformers import BertTokenizer, AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('sagorsarker/bangla-bert-base')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOaNQVs81VkV"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm6bcFR7syJH"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "# import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhQIDJ6il66B"
      },
      "source": [
        "#MODEL TRAINING 1 (train data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjHYMxNtmCsS",
        "outputId": "66169776-7e63-44bb-e4ab-82aa39a33d76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max sentence length:  13411\n",
            "sentence:  আমেরিকা বিরোধী জর্জ সরস ট্রাম্পের বিরুদ্ধে এনএফএল দিয়ে অস্ত্র আটক করেছেআমরা এইমাত্র এনএফএলকে সমর্থন না করার আরেকটি কারণ আবিষ্কার করলাম যে ব্যক্তিটি সবচেয়ে এন্টি-আমেরিকান, যাকে আমরা জানি সে এখন ন্যাশনাল ফুটবল লীগ প্লেয়ারস অ্যাসোসিয়েশন (এনএফএলপিএ)-এর সাথে যুক্ত। এনএফএলপিএ সম্প্রতি আর্থিক ভাবে এমন এক সত্যকে সমর্থন করেছে যে দূর-বাম সংগঠনের তালিকা তৈরি করেছে, প্লানড প্যারেন্টহুড থেকে শুরু করে অবৈধ অভিবাসীদের বিতাড়নের প্রতিবাদে সংগঠন, যাদের মধ্যে অনেকের ঘটনা রয়েছে।এই ধরনের একজন ব্যক্তি ওপেন সোসাইটি ফাউন্ডেশন ছাড়া আর কেউ নন, যার প্রধান কোটিপতি জর্জ সোরস.২য় ভোট পেয়েছেন এনএফএলপিএ সোরোস সেন্টার ফর কমিউনিটি চেঞ্জ এ্যাকশন নামক প্রতিষ্ঠানের সামাজিক ন্যায়বিচার শাখাকে আর্থিক সহায়তা প্রদান করছে। ওয়াশিংটন ফ্রি বিকন-এর মতে এই প্রতিষ্ঠানটি নভেম্বরের আগে এবং পরে প্রেসিডেন্ট ডোনাল্ড ট্রাম্প এবং রিপাবলিকানদের বিরুদ্ধে সরাসরি ব্যবস্থা গ্রহণ করেছে।এনএফএলপিএ কমপক্ষে ২০১৩ সালের দিকে ডেটিং করে বেশ কয়েকটি সুদূরপ্রসারী এবং বিরোধী-ট্রাম্প কারণ দান করছে। মার্কিন যুক্তরাষ্ট্রে সর্বাধিক মৌলিক এবং দূর-বাম কারণগুলির কয়েকটি তহবিলের একটি দীর্ঘ ইতিহাস রয়েছে। তিনি ২০১২ সালের ওয়াল স্ট্রিট দখল প্রতিবাদকে সমর্থন করেছেন বলে জানা যায়, ন্যাশনাল রিসোর্স ডিফেন্স কাউন্সিল, একটি ট্রাম বিরোধী পরিবেশবাদী সংগঠন, পরিকল্পিত প্যারেন্টহুড সহ গর্ভপাত-পন্থী আন্দোলন এবং অসংখ্য অ্যান্টি-ট্রাম্প প্রতিরোধের কারণও রয়েছে। সোরোস ওয়াশিংটনের উইমেনস মার্চের মূল অংশীদারদের অন্তত ৫৬ টি তহবিল দিয়েছে, যা ট্রাম্পের উদ্বোধনের পরের দিন ঘটেছিল। আরেকটি মাঠপর্যায়ের স্বত:স্ফূর্ত অভিযানের জন্য তহবিল গঠন করা হয়েছে, এবং এটি আরও স্বতঃস্ফূর্তভাবে পরিচালিত হবে।এই ১৮৭টি সংস্থা সরাসরি জর্জ সোরোসের অর্থায়নে পরিচালিত এই তালিকার কয়েকটি নাম আপনাকে হতবাক করবে গর্ভপাত গ্রুপ, উন্মুক্ত সীমান্ত, অভিবাসী গ্রুপ, গ্রুপ, গ্রুপকে আমরা যেভাবে ভোট দিই, বৈশ্বিক স্বাস্থ্যসেবা, জলবায়ু পরিবর্তন, ক্যাথলিক, সমাজতান্ত্রিক এবং কমিউনিস্টদের পরিবর্তন করতে।সোরোসের আসলে একটা দল রয়েছে, যাদের লক্ষ্য হল ধনী যিহুদিদের কাছ থেকে টাকাপয়সা নিয়ে কম লোকেদের কাছে তা দেওয়া।গতকাল প্রকাশিত একটি ভিডিওতে জর্জ সোরোস (একজন ইহুদি) স্বীকার করেছেন যে তিনি দ্বিতীয় বিশ্বযুদ্ধের সময় ইহুদিদের কাছ থেকে সম্পত্তি বাজেয়াপ্ত করতে সাহায্য করেছেন, এই ধারণা যে সোরোস এমন একটি দলকে অর্থায়ন করছে তা আসলে অত আশ্চর্যজনক নয়। তারা সবাই এখানে।১৮৭ টি দল আমেরিকাকে ধ্বংস করতে ব্যবহৃত হচ্ছে, ধন্যবান কোটিপতি জর্জ সোরোস।এখানে সেই সব দল যারা ট্রাম্পের নির্বাচনকে আমেরিকা দখলের অজুহাত হিসেবে ব্যবহার করছে: জর্জ সোরোস এবং তার যৌথবাদী সক্রিয়তা নিয়ে অনেক নিবন্ধ লেখা হয়েছে।সোরোস একজন ব্যবসায়ী, বিনিয়োগকারী, জনহিতৈষী এবং লেখক যিনি ইহুদি-হাঙ্গেরিয়ান বংশোদ্ভূত এবং দ্বৈত নাগরিকত্বের অধিকারী।তিনি সোরোস ফান্ড ম্যানেজমেন্টের চেয়ারম্যান।আবিষ্কার নেটওয়ার্কস সোরোস এবং তার ওপেন সোসাইটি ইনস্টিটিউটের অর্থায়নে পরিচালিত সংস্থাগুলির একটি বিস্তৃত তালিকা প্রকাশ করেছে। এই দলগুলির মধ্যে কয়েকটি সক্রিয়ভাবে রাষ্ট্রপতি ডোনাল্ড ট্রাম্পের বিরোধিতা করেছে এবং তার সমাবেশে দেখা সাম্প্রতিক সহিংসতা ও বিশৃঙ্খলার স্তরের অংশ হতে পারে।অনেক গোষ্ঠীই সমর্থন করে: উন্মুক্ত সীমানা, রাজক্ষমা, অবৈধ ভোটের অধিকার প্রদান, মুসলিম অভিবাসন এবং সামাজিক ন্যায়বিচার। সাম্প্রতিক বছরগুলিতে জর্জ সোরোস এবং তাঁর ওপেন সোসাইটি ইনস্টিটিউট (ওএসআই) থেকে সরাসরি তহবিল এবং সহায়তা পেয়েছে এমন সংস্থাগুলি নিম্নরূপ:(ডিসকভারদ্যনেটওয়ার্কস.অর্গ এর গ্রুপ বিভাগে প্রতিটির সমন্বিত প্রোফাইল পাওয়া যায়): অ্যাডভান্সমেন্ট প্রকল্প: এই সংস্থা বাম বিশ্বের মতামত এবং মূল্যগুলি বিস্তৃতভাবে একটি অত্যাধুনিক যোগাযোগ বিভাগের মাধ্যমে যতটা সম্ভব ছড়িয়ে দেওয়ার সময় রঙের সম্প্রদায়গুলিকে রাজনৈতিকভাবে সমন্বয়মূলক ইউনিটগুলিতে সংগঠিত করার জন্য কাজ করে। এয়ার আমেরিকা রেডিও: এখন বিলুপ্ত, এটি একটি স্ব-চিহ্নিত উদার রেডিও নেটওয়ার্ক ছিল। আমাদের সবাই বা না: এই সংস্থা ভোটিং আইনগুলি পরিবর্তন করতে চায় যা প্রাক্তন-বন্দী, চরমপন্থীদের এবং এমনকি বর্তমান কারাবন্দীদের রাজনৈতিক নির্বাচনে তাদের ব্যালটগুলি নিক্ষেপ করতে অনুমতি দেওয়ার জন্য রাষ্ট্র থেকে রাজ্যে পরিবর্তিত হয়। ন্যায়বিচার গ্রুপ হিসাবে পরিচিত: প্রজাতন্ত্রের এই সক্রিয়তার জন্য ধারাবাহিকভাবে একটি ফেডারেল বিচারক হিসাবে পরিচিত।আমেরিকা একত্রিত হচ্ছে: সোরোস এই গ্রুপ তৈরিতে একটি প্রধান ভূমিকা পালন করেছে, যার উদ্দেশ্য ছিল গণতন্ত্রপন্থী ভোটার-মোবাইলাইজেশন প্রোগ্রামগুলির সমন্বয় এবং সংগঠিত করা। আমেরিকা ভোটস: সোরোসও এই গ্রুপ তৈরিতে একটি প্রধান ভূমিকা পালন করেছে, যার ভোটের প্রচারণা সম্ভাব্য গণতান্ত্রিক ভোটারদের লক্ষ্য করে। আমেরিকা এস ভয়েস: এই উন্মুক্ত বর্ডার গ্রুপ বিস্তৃত অভিবাসন সংস্কার প্রচার করতে চায় যার মধ্যে অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমার পক্ষে একটি শক্তিশালী এজেন্ডা রয়েছে। আমেরিকান বার অ্যাসোসিয়েশন কমিশন অন ইমিগ্রেশন পলিসি: এই সংস্থা নিয়োগকর্তা এবং শিক্ষা, স্বাস্থ্যসেবা বা অভিবাসন অবস্থা যাচাই করার জন্য অন্যান্য সামাজিক পরিষেবা প্রদানকারী ব্যক্তিদের আইনের বিরোধিতা করে।আমেরিকান ব্রিজ ২১শ শতাব্দী: এই সুপার প্যাক গণতান্ত্রিক রাজনৈতিক প্রার্থীদের তাদের রিপাবলিকান শত্রুদের পরাজিত করতে সাহায্য করার জন্য ডিজাইন করা বিরোধী গবেষণা পরিচালনা করে। আমেরিকান সিভিল লিবার্টিস ইউনিয়ন: এই দলটি মার্কিন সরকারের ৯/১১ পরবর্তী সমস্ত জাতীয় নিরাপত্তা ব্যবস্থার বিরোধিতা করে।এটি উন্মুক্ত সীমান্ত সমর্থন করে, সন্দেহভাজন সন্ত্রাসী এবং তাদের সহায়তাকারীদের প্রতিরক্ষায় দ্রুত এগিয়ে এসেছে এবং প্রাক্তন নিউ লেফট সন্ত্রাসী বার্নার্ডিন ডর্নকে এর উপদেষ্টা বোর্ডের জন্য নিযুক্ত করেছে। আমেরিকান সংবিধান সোসাইটি ফর ল এন্ড পলিসি: এই ওয়াশিংটন, ডিসি-ভিত্তিক চিন্তাবিদরা তরুণ আইন শিক্ষার্থীদের নিয়োগ, দীক্ষা এবং সংগঠিত করে ক্ষমতার অবস্থান অর্জনে সাহায্য করে বাম দিকে আমেরিকান আইনশাস্ত্রকে স্থানান্তরিত করার চেষ্টা করে।এটি বামপন্থী ডেমোক্রেটদের একটি উৎপীড়ক মঞ্চও সরবরাহ করে যা তাদের রাজনৈতিক প্রতিপক্ষের নিন্দা করে। আমেরিকান ফ্যামিলি ভয়েস: এই দলটি রিপাবলিকানদের বিরুদ্ধে অন্যায়ের অভিযোগ আনে এমন মিডিয়া প্রচারণা তৈরি এবং সমন্বয় সাধন করে। আমেরিকান ফেডারেশন অফ টিচারস: ১৯৯৭ সালে দীর্ঘদিনের এএফটি প্রেসিডেন্ট আলবার্ট শ্যাঙ্কার মারা যাওয়ার পরে, তিনি সান্ড্রা ফেল্ডম্যানের স্থলাভিষিক্ত হন, যিনি ধীরে ধীরে ইউনিয়নটিকে নতুন শ্রম আন্দোলনের সবচেয়ে শক্তিশালী বামপন্থী উপাদানগুলির সাথে সংযুক্ত করেন।২০০৪ সালে ফেল্ডম্যানের মৃত্যুর পর, এডওয়ার্ড ম্যাকএলরয় তার স্থলাভিষিক্ত হন এবং ২০০৮ সালে র্যান্ডি ওয়েঙ্গার্টেন তার স্থলাভিষিক্ত হন।আমেরিকান ফ্রেন্ডস সার্ভিস কমিটি: এই দলটি যুক্তরাষ্ট্রকে সারা বিশ্বের মানুষের দুঃখকষ্টের প্রধান কারণ হিসেবে দেখে থাকে।যেমন, এটা আমেরিকাকে একতরফা নিরস্ত্রীকরণ, আমেরিকান সীমানা বিলোপ, অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমা, মৃত্যুদণ্ড বিলোপ এবং প্যাট্রিয়ট অ্যাক্ট বাতিলের পক্ষে। আমেরিকান ইমিগ্রেশন কাউন্সিল: এই অলাভজনক সংস্থা উন্মুক্ত সীমান্ত লবির বিশিষ্ট সদস্য।এটি আমেরিকান ইমিগ্রেশন ল ফাউন্ডেশনে বসবাসকারী অবৈধ এলিয়েনদের অধিকার এবং ক্ষমা প্রসারিত করে: এই দলটি অবৈধ এলিয়েনদের জন্য ক্ষমাকে সমর্থন করে, যার পক্ষে এটি মার্কিন সরকারের বিরুদ্ধে মামলা করে। আমেরিকান ইন্ডিপেন্ডেন্ট নিউজ নেটওয়ার্ক: এই সংস্থাটি প্রগতিশীল পরিবর্তনের পক্ষে সমর্থনকারী প্রভাব সাংবাদিকতা প্রচার করে।আমেরিকান ইনস্টিটিউট ফর সোসাল জাস্টিস: এআইএসজে এর লক্ষ্য হচ্ছে দক্ষ সম্প্রদায়ের সংগঠক তৈরি করা যারা শহুরে পরিষেবা, মাদক নিষেধাজ্ঞা, অপরাধ প্রতিরোধ, গৃহায়ণ, পাবলিক সেক্টরের কাজ, স্বাস্থ্যসেবা এবং পাবলিক স্কুলগুলিতে বর্ধিত সরকারী ব্যয় বৃদ্ধির জন্য বিক্ষোভ করে দরিদ্র সম্প্রদায়কে রূপান্তরিত করতে পারে। আমেরিকান লাইব্রেরি অ্যাসোসিয়েশন: এই দলটি সন্ত্রাসের বিরুদ্ধে বুশ প্রশাসনের যুদ্ধ এর একটি স্পষ্টবাদী সমালোচক, মার্কিন প্যাট্রিয়ট অ্যাক্টের ধারা ২১৫, যা লাইব্রেরি ব্যবহারকারীদের সাংবিধানিক অধিকার এবং গোপনীয়তা অধিকারের বর্তমান বিপদ বলে অভিহিত করে।দ্য আমেরিকান প্রসপেক্ট, ইনক: এই কর্পোরেশন তরুণ বামপন্থী সাংবাদিকদের প্রশিক্ষণ দেয় এবং বামপন্থী নেতাদের জন্য কৌশল সভার আয়োজন করে।অ্যামনেস্টি ইন্টারন্যাশনাল: এই সংস্থা যুক্তরাষ্ট্র আর ইজরায়েলে মানবাধিকার লঙ্ঘনের জন্য তাদের সমালোচনার একটা অসামঞ্জস্য ভাগ ঠিক করে। ফলিত গবেষণা কেন্দ্র: আমেরিকাকে এমন একটা জাতি হিসাবে দেখা যেখানে কাঠামোগত বর্ণবাদ সমাজের কাঠামোর মধ্যে গভীরভাবে প্রোথিত, আরসি চেষ্টা করে একটা ন্যায় আর সমান সমাজ গড়ে তুলতে আমাদের সব থেকে শক্তিশালী প্রতিষ্ঠান থেকে সুনির্দিষ্ট পরিবর্তন দাবি করে।আরব আমেরিকান ইনস্টিটিউট ফাউন্ডেশন: আরব আমেরিকান ইনস্টিটিউট ৯/১১ পরবর্তী সময়ে আরব আমেরিকানদের বিরুদ্ধে পরিচালিত ব্যাপক নাগরিক স্বাধীনতা লঙ্ঘনের নিন্দা করে এবং ইস্রায়েলকে ফিলিস্তিনি জনগণের নৃশংস নিপীড়নকারী হিসাবে চিহ্নিত করে। অ্যাসপেন ইনস্টিটিউট: এই সংস্থা মৌলিক পরিবেশবাদ প্রচার করে এবং আমেরিকাকে এমন একটি জাতি হিসাবে দেখে যা গভীর আসনের কাঠামোগত বর্ণবাদ দ্বারা জর্জরিত।অ্যাসোসিয়েশন অফ কমিউনিটি অরগানাইজেশন ফর রিফর্ম নাউ: এই দলটি বামপন্থী ডেমোক্রেটদের পক্ষে ভোটার আন্দোলন পরিচালনা করে।এই উদ্যোগগুলো প্রতারণা এবং দুর্নীতির দ্বারা কুখ্যাতভাবে ক্ষতিগ্রস্ত হয়েছে। ব্যালট ইনিশিয়েটিভ স্ট্র্যাটেজি সেন্টার: এই সংস্থা একটি জাতীয় প্রগতিশীল কৌশলকে এগিয়ে নিয়ে যাওয়ার চেষ্টা করছে ভোটের মাধ্যমে রাষ্ট্র-স্তরের আইনী প্রস্তাবগুলি যা একটি পিটিশন (উদ্যোগ) প্রক্রিয়ার মাধ্যমে সফলভাবে পাস হয় এবং তারপর জনগণের দ্বারা ভোট দেওয়া হয়। বিল অফ রাইটস ডিফেন্স কমিটি: এই দলটি সক্রিয় কর্মীদের জন্য একটি বিস্তারিত ব্লুপ্রিন্ট সরবরাহ করে যারা তাদের স্থানীয় শহর, শহর এবং এমনকি কলেজ ক্যাম্পাসগুলিকে তাদের দেশপ্রেম আইনের বিরোধিতা প্রকাশ্যে ঘোষণা করতে এবং নিজেদের নাগরিক স্বাধীনতা নিরাপদ অঞ্চল হিসাবে চিহ্নিত করতে আগ্রহী।সংগঠনটি সন্ত্রাসবাদের জন্য বস্তুগত সহায়তা প্রদানের জন্য ২০০৫ সালে দোষী সাব্যস্ত হওয়া মৌলবাদী অ্যাটর্নি লিন স্টুয়ার্টের প্রতিরক্ষায়ও এসেছিল। ব্ল্যাক অ্যালায়েন্স ফর জাস্ট ইমিগ্রেশন: এই সংস্থা কালো জাতিগত পরিচয়ের উপর কেন্দ্রীভূত সামাজিক ও অর্থনৈতিক ন্যায়বিচারের জন্য একটি ঐক্যবদ্ধ আন্দোলন তৈরি করতে চায়। ব্লুপ্রিন্ট নর্থ ক্যারোলিনা: এই দলটি উত্তর ক্যারোলিনায় রাষ্ট্রীয় নীতি প্রভাবিত করতে চায় যাতে রাজ্যের বাসিন্দারা আরও প্রগতিশীল নীতিগুলি যেমন স্বাস্থ্যসেবা, উচ্চতর মজুরি, আরও সাশ্রয়ী মূল্যের হাউজিং, নিরাপদ, পরিষ্কার পরিবেশ এবং প্রজনন স্বাস্থ্যসেবা অ্যাক্সেস থেকে উপকৃত হয়।ব্রেনান সেন্টার ফর জাস্টিস: এই চিন্তাবিদ ট্যাঙ্ক/আইনী একটিভিস্ট গ্রুপ পাণ্ডিত্যপূর্ণ গবেষণা তৈরি করে, প্রচার মাধ্যমের প্রচারণা বৃদ্ধি করে, এমিকাসের সংক্ষিপ্ত নথি প্রকাশ করে, সক্রিয় কর্মীদের জন্য বোনো সমর্থন প্রদান করে এবং মৌলিক পরিবর্তনের জন্য পরীক্ষামূলক মামলা দায়ের করে।ব্রুকিংস ইনস্টিটিউশন: এই সংগঠনটি বিভিন্ন আন্তর্জাতিকতাবাদী এবং রাষ্ট্র-পৃষ্ঠপোষক প্রোগ্রামগুলির সাথে জড়িত, যার মধ্যে একটি জাতিসংঘ-শাসিত বিশ্ব সরকার প্রতিষ্ঠার জন্য উত্সাহী।ব্রুকিংস ফেলোগণ ব্যবসা ও ব্যাংকিং-এর উপর বৈশ্বিক সহযোগিতা, কিয়োটো প্রটোকলের সম্প্রসারণ এবং শিশুদের জন্য জাতীয়কৃত স্বাস্থ্য বীমার আহবান জানিয়েছেন।নয় জন ব্রুকিংস অর্থনীতিবিদ ২০০৩ সালে প্রেসিডেন্ট বুশের বিরুদ্ধে একটি পিটিশনে স্বাক্ষর করেছেন। আমেরিকার ভবিষ্যৎ এর জন্য ক্যাম্পেইন: এই দলটি কর বৃদ্ধি, সামাজিক ঔষধ, এবং সামাজিক কল্যাণ কর্মসূচির নাটকীয় সম্প্রসারণ সমর্থন করে। উন্নততর স্বাস্থ্যসেবার জন্য ক্যাম্পেইন: এই সংস্থাটি একক প্রদায়ক, সরকার পরিচালিত, সার্বজনীন স্বাস্থ্যসেবা ব্যবস্থাকে সমর্থন করে।ক্যাম্পেইন ফর ইয়থ জাস্টিস: এই সংগঠন দাবি করে যে, কিশোর-কিশোরীদের প্রাপ্তবয়স্ক অপরাধ-বিচার ব্যবস্থায় স্থানান্তরিত করা, অপরাধ-প্রতিরোধের উচ্চ হারের দিকে পরিচালিত করে, কারারুদ্ধ করে রাখে এবং অপ্রয়োজনীয় ঝুঁকিতে আটক রাখে, তাদের প্রতিরোধের মূল্য খুব কম এবং জনগণের নিরাপত্তা বৃদ্ধি করে না।ক্যাম্পাস প্রোগ্রেস: সোরোস-ব্যাংকরোলড সেন্টার ফর আমেরিকান প্রগ্রেসের একটি প্রকল্প, এই দলটি কলেজ এবং বিশ্ববিদ্যালয় ক্যাম্পাসগুলিতে প্রগতিশীল কণ্ঠস্বরকে শক্তিশালী করার চেষ্টা করে, ক্যাম্পাসে ডানপন্থী দলগুলোর ক্রমবর্ধমান প্রভাব মোকাবেলা করে এবং নতুন প্রজন্মের প্রগতিশীল নেতাদের ক্ষমতায়ন করে।কাসা ডি ম্যারিল্যান্ড: এই সংস্থাটি মার্কিন যুক্তরাষ্ট্রে বর্তমানে বসবাসরত অবৈধ এলিয়েনদের ক্ষমা সহ প্রসারিত অধিকারগুলির প্রচার করা নীতিগুলির পক্ষে ভোট দেওয়ার জন্য বিধায়কদের তীব্রভাবে লবি করে। ক্যাটালিস্ট: এটি একটি লাভজনক রাজনৈতিক পরামর্শ যা প্রগতিশীল সংস্থাগুলিকে সাহায্য করতে চায়, প্রতিটি ভোট-বয়স আমেরিকানের একটি শক্তিশালী জাতীয় ভোটার ডাটাবেস নির্মাণ এবং পরিচালনা করে নাগরিক অংশগ্রহণ এবং নির্বাচনী সাফল্যের পরিমাপযোগ্য বৃদ্ধি উপলব্ধি করতে।ক্যাথলিক ফর চয়েজ: এই নামমাত্র ক্যাথলিক সংস্থা মহিলাদের গর্ভপাত-অন-চাহিদার অধিকার সমর্থন করে। অ্যালায়েন্স ফর দ্য কমন গুড: এই রাজনৈতিক অলাভজনক গ্রুপ বামপন্থী প্রার্থী, কারণ এবং আইন প্রণয়নের জন্য ক্যাথলিক সম্প্রদায়ের কাছ থেকে সমর্থন আদায়ের জন্য নিবেদিত। আমেরিকান অগ্রগতির জন্য কেন্দ্র: এই বামপন্থী চিন্তাবিদের নেতৃত্বে প্রাক্তন ক্লিনটন চিফ অফ স্টাফ জন পোডেস্টা, হিলারি ক্লিনটনের সাথে ঘনিষ্ঠভাবে কাজ করেন এবং অসংখ্য প্রাক্তন ক্লিনটন প্রশাসন কর্মী নিয়োগ করেন।এটি একটি প্রগতিশীল আমেরিকা সম্পর্কে একটি দীর্ঘমেয়াদী ধারণা গড়ে তুলতে এবং নতুন প্রগতিশীল ধারণা ও নীতি প্রস্তাব তৈরির জন্য একটি ফোরাম তৈরি করতে প্রতিশ্রুতিবদ্ধ।সেন্টার ফর কমিউনিটি চেঞ্জ: এই দলটি বামপন্থী রাজনৈতিক ইস্যু প্রচারণার নেতৃত্ব দেওয়ার জন্য কর্মীদের নিয়োগ এবং প্রশিক্ষণ দেয়।দারিদ্রের সাথে সম্পর্কিত প্রধান জাতীয় বিষয়গুলির প্রতি দৃষ্টি আকর্ষণ করে সামাজিক কল্যাণ কর্মসূচির জন্য বর্ধিত তহবিল গঠন করে, কেন্দ্রটি প্রখ্যাত মৌলবাদী সংগঠক শৌল আলিনস্কির শেখানো কৌশলগুলির উপর তার প্রশিক্ষণ কর্মসূচির ভিত্তি করে। সাংবিধানিক অধিকারের জন্য কেন্দ্র: এই ক্যাস্ট্রোপন্থী সংগঠনটি উন্মুক্ত সীমান্ত লবির মূল সদস্য, মার্কিন সরকারের ৯/১১ পরবর্তী সমস্ত সন্ত্রাসবাদ বিরোধী পদক্ষেপের বিরোধিতা করেছে এবং অভিযোগ করেছে যে আমেরিকান অবিচার আন্তর্জাতিক সন্ত্রাসবাদের কাজকে প্ররোচিত করে। অর্থনৈতিক ও নীতি গবেষণা কেন্দ্র: এই দলটি কল্যাণ সংস্কারের বিরোধিতা করে, জীবিত মজুরি আইন সমর্থন করে, কর কর্তন প্রত্যাখ্যান করে এবং ধারাবাহিকভাবে সমাজতান্ত্রিক শাসকদের কৃতিত্বগুলিকে প্রশংসা করে, বিশেষত ভেনিজুয়েলা। সমস্ত উত্পাদনশীল মিশন, মহিলাদের জন্য নিরাপদ গর্ভপাতের নিশ্চয়তা দেয়।সংস্থাটি নিম্ন-আয়ের মহিলাদের জন্য করদাতা-অর্থায়িত গর্ভপাত (মেডিকেডের মাধ্যমে) অ্যাক্সেসের দাবি করে রাজ্য ও ফেডারেল মামলা দায়ের করেছে। দায়ী ঋণ কেন্দ্রের: এই সংস্থাটি সাব-প্রাইম বন্ধক সংকটের একটি প্রধান খেলোয়াড় ছিল।ফিল কারপেন (আমেরিকানদের প্রোস্পারিটি নীতির ভাইস প্রেসিডেন্ট) এর মতে, সিআরএল বাতিল করে দিয়েছে আর ব্যাংকগুলোকে হয়রানি করেছে অযোগ্য ঋণগ্রহীতাদের খারাপ ঋণ দিতে।এছাড়াও, সিআরএল বাজেট এবং নীতি অগ্রাধিকারের উপর ফ্যানি মে সেন্টারকে উচ্চ ঝুঁকির ঋণের শর্ত হিসাবে কাজ করতে সক্ষম করে এমন একটি চুক্তি নিয়ে আলোচনা করেছে: কর কর্তন সাধারণত ধনীদের সহায়তা করে এমন প্রাঙ্গণ থেকে যুক্তি দিয়ে, এই সংস্থাটি নিম্ন আয়ের লোকদের জন্য সামাজিক কল্যাণ কর্মসূচির উপর বৃহত্তর কর ব্যয়কে সমর্থন করে। উইসকনসিন স্ট্র্যাটেজি (সিওএস) কেন্দ্র: যাদের আয় গড়ের উপরে তাদের উপর আরোপিত উচ্চতর করের মাধ্যমে সম্পদকে পুনর্বণ্টনের লক্ষ্যে, কাওস যুক্তি দেখায় যে এটি গুরুত্বপূর্ণ যে রাষ্ট্রীয় সরকার কর্পোরেশন এবং ধনী সহ সমাজের সমস্ত অংশ থেকে ন্যায্য অবদান সংগ্রহ করতে সক্ষম হবে।চেঞ্জ আমেরিকা নাউ: ২০০৬ সালের ডিসেম্বর মাসে গঠিত চেঞ্জ আমেরিকা নাউ নিজেকে একটি স্বাধীন রাজনৈতিক সংস্থা হিসাবে বর্ণনা করেছে যা রিপাবলিকান কংগ্রেসের ব্যর্থ নীতি সম্পর্কে নাগরিকদের শিক্ষিত করার জন্য তৈরি করা হয়েছিল এবং একটি গণতান্ত্রিক এজেন্ডা দ্বারা প্রদত্ত প্রতিশ্রুতির সাথে ব্যর্থতার রেকর্ডের বিপরীতে।ওয়াশিংটনে দায়িত্ব ও নৈতিকতার জন্য নাগরিক: এই দলটি সরকারি কর্মকর্তাদের বিরুদ্ধে মামলা দায়ের করে এবং নৈতিকতার অভিযোগ আনে, যারা বিশেষ স্বার্থের জন্য সাধারণ কল্যাণকে বিসর্জন দেয় এবং জনগণের আস্থাকে বিশ্বাসঘাতকতা করে।এর প্রায় সকল লক্ষ্য রিপাবলিকান। একটি আন্তর্জাতিক অপরাধ আদালতের জন্য সহযোগিতা: এই দলটি একটি আন্তর্জাতিক আদালতের কাছে আমেরিকান অপরাধ-বিচার পদ্ধতি অধস্তন করতে চায়। সাধারণ কারণ: এই সংস্থার লক্ষ্য হল প্রচারণা-অর্থ সংস্কার আনা, ফেয়ারনেস ডকট্রিনের মতো মিডিয়া সংস্কার অনুসরণ করা এবং সামাজিক-কল্যাণ এবং পরিবেশগত ব্যয় বাড়ানোর পক্ষে সামরিক বাজেট হ্রাস করা। সংবিধান প্রকল্প: এই সংস্থা সামরিক কমিশনের বৈধতা চ্যালেঞ্জ করতে চায়; শত্রু যোদ্ধাদের আটক শেষ করা; সন্ত্রাসীদের সরকারি নজরদারির নিন্দা করা; এবং রাষ্ট্রপতির নির্বাহী সুবিধা সীমিত করা। ওয়াইল্ডলাইফ অ্যাকশন ফান্ডের রক্ষাকারীরা: আলাস্কার জাতীয় বন্যপ্রাণী তেল অনুসন্ধানের বিরোধিতা করে।এটি লগিং, র্যাঞ্চিং, মাইনিং এবং এমনকি বিনোদনমূলক মোটরচালিত যানবাহনকে পরিবেশের জন্য ধ্বংসাত্মক কার্যকলাপ হিসাবে ব্যবহার করাকে নিন্দা করে। গণতন্ত্র জোট: এই স্ব-বর্ণিত উদার সংগঠন বামপন্থী দলগুলির জন্য তহবিল ক্লিয়ারিং হাউস বিকাশের জন্য ২০০ মিলিয়ন ডলার সংগ্রহ করার লক্ষ্য রাখে।সোরোস এই দলের প্রধান দাতা। ডেমোক্রাসি ২১: এই দলটি ২০০২ সালের দ্বিপক্ষীয় প্রচারণা সংস্কার আইনের একনিষ্ঠ সমর্থক, এছাড়াও এটি ম্যাককেইন-ফিঙ্গোল্ড অ্যাক্ট.ডেমোক্রাসি নাও নামে পরিচিত!: ডেমোক্রেসি নাউ!ডব্লিউবিআই রেডিও সংবাদ পরিচালক এমি গুডম্যান এবং চার অংশীদার ১৯৯৬ সালে মার্কিন কর্পোরেট-পৃষ্ঠপোষক মিডিয়াতে কদাচিৎ শোনা দৃষ্টিকোণগুলি সরবরাহ করার জন্য তৈরি করেছিলেন, উদাহরণস্বরূপ, র্যাডিকাল এবং বিদেশী সাংবাদিকদের দৃষ্টিভঙ্গি, বামপন্থী এবং শ্রম কর্মী এবং পুঁজিবাদের মতাদর্শিক শত্রু। ডেমোক্রেটিক জাস্টিস ফান্ড: ডিজেএফ প্যাট্রিয়ট অ্যাক্টের বিরোধিতা করে এবং যুক্তরাষ্ট্রে বিশেষত সন্ত্রাসী জাতি হিসাবে স্টেট ডিপার্টমেন্টের মনোনীত দেশ থেকে অভিবাসন নিয়ন্ত্রণ বা নিয়ন্ত্রণের সর্বাধিক প্রচেষ্টা।ডেমোক্রেটিক পার্টি: সোরোস তহবিল কার্যক্রম মূলত ডেমোক্রেটিক পার্টিকে তার ক্ষমতার ভিত্তি দৃঢ় করতে সাহায্য করার জন্য নিবেদিত।২০০৩ সালের নভেম্বর মাসে এক সাক্ষাৎকারে সোরোস বলেছিলেন যে, ২০০৪ সালে প্রেসিডেন্ট বুশকে পরাজিত করাই আমার জীবন ও মৃত্যুর মূল বিষয়।তিনি বুশকে পরাজিত করার জন্য ৭৫ মিলিয়ন মার্কিন ডলার সংগ্রহ করার অঙ্গীকার করেছিলেন এবং ব্যক্তিগতভাবে বুশ-বিরোধী সংস্থাগুলিকে সেই অর্থের এক তৃতীয়াংশ দান করেছিলেন।তিনি বলেন, বুশের অধীনস্থ আমেরিকা বিশ্বের জন্য একটি বিপদ এবং আমি আমার মুখ যেখানে আছে সেখানে আমার টাকা দিতে ইচ্ছুক।ডেমোস: এই সংস্থা ফেডারেল আর রাষ্ট্রীয় নীতি নির্ধারকদের কাছে আবেদন করেছে অর্থনৈতিক নিরাপত্তা আর বৈষম্য তুলে ধরার জন্য যা আজকে আমেরিকান সমাজের বৈশিষ্ট্য তুলে ধরে; সম্পদ, আয় আর রাজনৈতিক প্রভাবের মধ্যে ফাঁক কমানোর ধারণা তুলে ধরে; আর ধনীদের জন্য কর বাড়ানোকে সমর্থন করে। ড্রাম মেজর ইন্সটিটিউট: এই দল নিজেকে বর্ণনা করে নির্দলীয়, অলাভজনক চিন্তাবিদ হিসাবে যা এই ধারণা তৈরি করে যা প্রগতিশীল আন্দোলনকে উৎসাহিত করে, নীতি নির্ধারক আর মতামত নেতাদের রাজি করার চূড়ান্ত লক্ষ্য নিয়ে যে পদক্ষেপ নেয়া সামাজিক আর অর্থনৈতিক ন্যায় বিচার সম্পর্কে তাদের দৃষ্টিকে এগিয়ে নিয়ে যাবে।আর্থজাস্টিস: এই দলটি মার্কিন যুক্তরাষ্ট্রের ভূমি ও জলপথ কিভাবে ব্যবহার করা যেতে পারে তার উপর কঠোর বিধিনিষেধ আরোপ করতে চায়।এটি বেশিরভাগ খনি ও লগিং উদ্যোগ, বাণিজ্যিক মাছ ধরার ব্যবসা এবং অনুন্নত এলাকায় মোটরচালিত যানবাহন ব্যবহারের বিরোধিতা করে। অর্থনৈতিক নীতি ইনস্টিটিউট: এই সংস্থা বিশ্বাস করে যে সরকারকে অর্থনৈতিকভাবে দুর্বলদের রক্ষা, সমান সুযোগ নিশ্চিত এবং সমস্ত আমেরিকানদের কল্যাণের জন্য একটি সক্রিয় ভূমিকা পালন করতে হবে।ইলেকট্রনিক প্রাইভেসি ইনফরমেশন সেন্টার: এই সংগঠনটি মার্কিন প্যাট্রিওট আইনের কঠোর সমালোচক এবং আমেরিকান সিভিল লিবার্টিজ ইউনিয়নে যোগদান করেছে।এলা বেকার সেন্টার ফর হিউম্যান রাইটস: বিপ্লবী কমিউনিস্ট ভ্যান জোনসের সহ-প্রতিষ্ঠাতা এই দারিদ্র্য-বিরোধী সংগঠন দাবি করেছে যে, আমাদের শহরগুলোতে দশকের পর দশক ধরে মাত্রাতিরিক্ত, বর্ণবাদী পুলিশিং এবং অতি কারাদণ্ডের কারণে হতাশা এবং গৃহহীনতার সৃষ্টি হয়েছে।এমিলি এস লিস্ট: এই রাজনৈতিক নেটওয়ার্ক গণতান্ত্রিক মহিলা রাজনৈতিক প্রার্থীদের জন্য অর্থ সংগ্রহ করে যারা করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদা. এনার্জি অ্যাকশন কোয়ালিশনে অবাধ প্রবেশাধিকার সমর্থন করে: ২০০৪ সালে প্রতিষ্ঠিত, এই দলটি নিজেকে যুব নেতৃত্বাধীন ৫০ টি পরিবেশগত ও সামাজিক ন্যায়বিচার গোষ্ঠীর জোট হিসাবে বর্ণনা করে যারা যুব পরিষ্কার শক্তি এবং জলবায়ু আন্দোলন গড়ে তোলার জন্য একত্রে কাজ করছে।ইকুয়াল জাস্টিস ইউএসএ: এই দল দাবি করে যে আমেরিকা অপরাধ-বিচার ব্যবস্থা উল্লেখযোগ্য জাতি এবং শ্রেণীগত পক্ষপাতিত্বের দ্বারা ক্ষতিগ্রস্ত এবং এইভাবে বড় সংস্কারের প্রচার চায়।ফেয়ার ইমিগ্রেশন রিফর্ম মুভমেন্ট: এটি সেন্টার ফর কমিউনিটি চেঞ্জের উন্মুক্ত সীমান্ত বাহু। বিশ্বস্ত আমেরিকা: এই সংগঠনটি সম্পদের পুনর্বন্টন প্রচার করে, যুদ্ধবন্দীদের সাথে যুদ্ধের মাধ্যমে জিজ্ঞাসাবাদের প্রক্রিয়া উন্নত করা, বৈশ্বিক উষ্ণায়নের বিরুদ্ধে লড়াই করার জন্য নীতিমালা প্রণয়ন এবং সরকার পরিচালিত তাপ যত্ন ব্যবস্থা তৈরির প্রচার করে। নারীবাদী সংখ্যাগরিষ্ঠতা: মার্কিন যুক্তরাষ্ট্রকে অন্তর্নিহিত যৌনবাদী জাতি হিসাবে চিহ্নিত করা, এই দলটি পুরুষদের সাথে মহিলাদের আইনি, সামাজিক ও রাজনৈতিক সমতার অগ্রগতির বিরোধিতা করে এবং মার্কিন যুক্তরাষ্ট্রে নারীবাদী আন্দোলনের জন্য ভবিষ্যতের নেতৃত্বকে উত্সাহিত করার জন্য তরুণ নারীবাদীদের নিয়োগ এবং প্রশিক্ষণ দেয়।ফোর ফ্রিডম ফান্ড: এই সংগঠনটি একটি কন্ডুইট হিসাবে কাজ করার জন্য ডিজাইন করা হয়েছিল যার মাধ্যমে বড় ফাউন্ডেশনগুলি রাষ্ট্রীয়-ভিত্তিক উন্মুক্ত সীমান্ত সংস্থাগুলিকে আরও স্পষ্ট এবং দ্রুত তহবিল সরবরাহ করতে পারে। ক্যাম্পাসে ফ্রি এক্সচেঞ্জ: এই সংগঠনটি কেবল এক ব্যক্তির প্রচেষ্টার বিরোধিতা করার জন্য তৈরি করা হয়েছিল, ডেভিড হোরোইটজ এবং বিশ্ববিদ্যালয়গুলিকে একটি একাডেমিক বিল অফ রাইটস গ্রহণ করার জন্য তার প্রচারণা, পাশাপাশি হোরোইটজ এস ২০০৬ বই অধ্যাপকদের নিন্দা করার জন্য তৈরি করা হয়েছিল।এফইসি'র সদস্য সংগঠনগুলোর মধ্যে রয়েছে ক্যাম্পাস প্রোগ্রেস (সেন্টার ফর আমেরিকান প্রগ্রেসের একটি প্রকল্প); আমেরিকান এসোসিয়েশন অফ ইউনিভার্সিটি প্রফেসরস; আমেরিকান সিভিল লিবার্টিজ ইউনিয়ন; পিপল ফর আমেরিকান ওয়ে; মার্কিন যুক্তরাষ্ট্রের ছাত্র সংগঠন; সেন্টার ফর ক্যাম্পাস ফ্রি স্পিচ; আমেরিকান লাইব্রেরি অ্যাসোসিয়েশন; ফ্রি প্রেস; এবং ন্যাশনাল অ্যাসোসিয়েশন অফ স্টেট পাবলিক ইন্টারেস্ট রিসার্চ গ্রুপ। ফ্রি প্রেস: এই মিডিয়া সংস্কার সংস্থা আমেরিকার জন্য মিডিয়া ম্যাটারস, এয়ার আমেরিকা রেডিও, গ্লোবাল এক্সচেঞ্জ, কোড পিংক, ফেয়ারনেস এবং প্রতিবেদনের শুদ্ধতা, বিপ্লবী কমিউনিস্ট পার্টি, মাদার জোনস ম্যাগাজিন, এবং প্যাসিফিক রেডিওর মতো উল্লেখযোগ্য বামপন্থীদের সাথে ঘনিষ্ঠভাবে কাজ করেছে।ফান্ডিং এক্সচেঞ্জ: সামাজিক পরিবর্তনের বাহন হিসাবে জনসেবার ধারণার প্রতি নিবেদিত, এই সংগঠনটি বামপন্থী দাতাদের সাথে এবং সমমনা দল ও কর্মীদের সাথে ফাউন্ডেশন যারা তাদের নিজেদের প্রগতিশীল পরিবর্তন এবং সামাজিক ন্যায়বিচারের সংস্করণ আনতে নিবেদিত।এই অনুদানপ্রাপ্তদের অনেকেই অনুমান করেন যে আমেরিকান সমাজ বর্ণবাদ, বৈষম্য, শোষণ এবং অযোগ্যতায় পরিপূর্ণ এবং টেকসই শিক্ষা, সক্রিয়তা এবং সামাজিক আন্দোলনের মাধ্যমে তাদের সংস্কার করা প্রয়োজন। গামালিয়েল ফাউন্ডেশন: ষাটের দশকের প্রগতিবাদী সক্রিয় কর্মী সোল আলিনস্কির কৌশলের মডেল তৈরি করে এই দলটি বর্তমান মাতৃভূমি নিরাপত্তা ব্যবস্থা এবং অভিবাসন বিধিনিষেধের বিরুদ্ধে দৃঢ় অবস্থান নিয়েছে। গিশা: আন্দোলনের স্বাধীনতার আইনী সুরক্ষা কেন্দ্র: এই ইজরায়েল বিরোধী সংগঠন ফিলিস্তিনিদের আন্দোলনের স্বাধীনতার অধিকার অনুশীলনে সহায়তা করার চেষ্টা করছে।গ্লোবাল সেন্টার ফর দ্য রেসপন্সিবিলিটি টু প্রটেক্ট: এই গ্রুপ দাবি করে যে যখন একটি রাষ্ট্র তার সীমানার মধ্যে সংঘটিত গণহত্যা থেকে বেসামরিক নাগরিকদের রক্ষা করতে অক্ষম বা অনিচ্ছুক প্রমাণিত হয়, তখন সম্ভব হলে শান্তিপূর্ণভাবে হস্তক্ষেপ করা আন্তর্জাতিক সম্প্রদায়ের দায়িত্ব, তবে প্রয়োজনে সামরিক বাহিনীর সাথে। গ্লোবাল এক্সচেঞ্জ: ১৯৮৮ সালে ক্যাস্ট্রো-পন্থী র্যাডিকাল মিডিয়া বেঞ্জামিন দ্বারা প্রতিষ্ঠিত, এই দলটি আমেরিকাকে ধারাবাহিকভাবে বিদেশী নীতি, ব্যবসা অনুশীলন এবং গার্হস্থ্য জীবন নিন্দা করে।৯/১১ এর সন্ত্রাসী হামলার পর, গ্লোবাল এক্সচেঞ্জ আমেরিকানদের পরামর্শ দিয়েছে মধ্য প্রাচ্যের তেলের উপর আমাদের নির্ভরতা থেকে ইজরায়েলের প্রতি আমাদের পক্ষপাতিত্বমূলক নীতি পর্যন্ত আরব বিশ্বে যুক্তরাষ্ট্রের বিরুদ্ধে অসন্তোষের মূল কারণ পরীক্ষা করে দেখতে।গ্রান্টমেকারস উইদাউট বর্ডারস: জিডব্লিউবি বামপন্থী পরিবেশ, যুদ্ধ বিরোধী এবং নাগরিক অধিকার গোষ্ঠীর খুব সমর্থন করে।এটি সাধারণত পুঁজিবাদের বিরোধী, যা প্রধান রাজনৈতিক, অর্থনৈতিক এবং সামাজিক ব্যবস্থাগুলির মধ্যে একটি বলে মনে করা হয় যা একটি বড় সামাজিক ব্যাধির জন্ম দেয়।গ্রীন ফর অল: ফেডারেল জলবায়ু, শক্তি এবং অর্থনৈতিক নীতি উদ্যোগের জন্য লবি করার জন্য ভ্যান জোন্স এই গ্রুপ তৈরি করেছিলেন।হেলথ কেয়ার ফর আমেরিকা নাউ: এই গ্রুপ একটি একক পেয়ার মডেল সমর্থন করে যেখানে ফেডারেল সরকার সমগ্র মার্কিন স্বাস্থ্য ব্যবস্থা অর্থায়ন এবং পরিচালনার দায়িত্বে থাকবে।হিউম্যান রাইটস ক্যাম্পেইন: যুক্তরাষ্ট্রের বৃহত্তম সমকামী-সমকামী-ট্রান্সজেন্ডার লবিং গ্রুপ, এইচআরসি রাজনৈতিক প্রার্থী এবং আইন সমর্থন করে যা এলজিবিটি এজেন্ডাকে এগিয়ে নিয়ে যাবে।ঐতিহাসিকভাবে, এইচআরসি সর্বাধিক জোরালোভাবে এইচআইভি / এইডস সম্পর্কিত আইন, ঘৃণা অপরাধ আইন, সামরিক এস ডন টি এসকের বিলোপ, ডন টি টেল নীতি এবং সমকামী বিবাহের বৈধতাকে সমর্থন করেছে। মানবাধিকার প্রথম: এই দলটি উন্মুক্ত সীমানা এবং অবৈধ এলিয়েনদের অধিকার সমর্থন করে; অভিযোগ যে প্যাট্রিয়ট আইন মার্কিন নাগরিক স্বাধীনতা গুরুতরভাবে হ্রাস করে; সন্ত্রাসের সন্দেহভাজন জোসে প্যাডিলার পক্ষে অ্যামিকাস কিউরিয়া সংক্ষিপ্ত দায়ের করেছে; এবং গুয়ান্তানামো বে আটক সুবিধাগুলির সমালোচনা করে। হিউম্যান রাইটস ওয়াচ: এই দলটি মার্কিন যুক্তরাষ্ট্র এবং ইজরায়েলে তার সমালোচনার একটি অসমঞ্জস্য ভাগ নির্দেশ করে।এটি সকল ক্ষেত্রে মৃত্যুদণ্ডের বিরোধিতা করে এবং অবৈধ এলিয়েনদের জন্য উন্মুক্ত সীমান্ত এবং ক্ষমা সমর্থন করে।আমি লাম: ইজরায়েল বিরোধী এই এনজিও আরব মিডিয়ার উন্নয়ন আর ক্ষমতায়নের চেষ্টা করছে আর ফিলিস্তিনি বিষয় নিয়ে কথা বলছে।অভিবাসী প্রতিরক্ষা প্রকল্প: অবৈধ অভিবাসীদের কারণকে এগিয়ে নিয়ে যাওয়ার জন্য, আইডিপি অভিবাসন আইন ব্যাকআপ সমর্থন এবং নিউ ইয়র্ক প্রতিরক্ষা অ্যাটর্নি এবং অন্যান্য যারা অপরাধমূলক ন্যায়বিচার এবং অভিবাসন ব্যবস্থায় অভিবাসীদের প্রতিনিধিত্ব বা সহায়তা করে, পাশাপাশি অভিবাসীদেরও সহায়তা করে। অভিবাসী আইনী সম্পদ কেন্দ্র: এই দলটি মার্কিন যুক্তরাষ্ট্রে প্রায় ত্রিশ লক্ষ অবৈধ বিদেশীর জন্য ক্ষমা পেতে সহায়তা করেছে বলে দাবি করে, এবং ১৯৮০-এর দশকে অভয়ারণ্য আন্দোলনের অংশ ছিল যা মধ্য আমেরিকার ব্যর্থ কমিউনিস্ট রাজ্যগুলি থেকে শরণার্থীদের আশ্রয় দিতে চেয়েছিল। অভিবাসী শ্রমিক নাগরিকত্ব প্রকল্প: এই উন্মুক্ত-সীমানা সংস্থা মার্কিন ইমিগ্রেশন নেটওয়ার্ককে গণ অভিবাসনের পক্ষে সমর্থন করে: নিম্ন-আয়ের সংস্থাগুলির ন্যায়বিচার বৃদ্ধি এবং অভিবাসীদের অধিকার আদায়ের জন্য সহায়তা করার এই জোটটি তাদেরকে জোরদার করতে চায়।অভিবাসন নীতি কেন্দ্র: আইপিসি উন্মুক্ত সীমান্তের এক প্রবক্তা এবং তারা দাবী করছে যে আমেরিকায় অবৈধ অভিবাসীর বিশাল পরিমাণ প্রবেশ ঘটেছে যুক্তরাষ্ট্রের সরকারের নীতির কারণে, বিশেষ করে যখন ভেঙ্গে পড়া অভিবাসন ব্যবস্থা [ ] অবৈধ অভিবাসনকে প্রথম স্থানে নিয়ে যায়।স্বাধীন মিডিয়া সেন্টার: এই ইন্টারনেট ভিত্তিক, সংবাদ এবং ইভেন্ট বুলেটিন বোর্ড অনিবার্যভাবে বামপন্থী, পুঁজিবাদ বিরোধী দৃষ্টিভঙ্গি উপস্থাপন করে এবং বিশ্বায়ন-বিরোধী / আমেরিকা বিরোধী থিমগুলির জন্য একটি মুখপাত্র হিসাবে কাজ করে। স্বাধীন মিডিয়া ইনস্টিটিউট: আইএমআই এসপিএন প্রকল্প (কৌশলগত প্রেস ইনফরমেশন নেটওয়ার্ক) পরিচালনা করে, যা তাদের সামাজিক ন্যায়বিচার লক্ষ্য অর্জনে সহায়তা করার জন্য অ্যাক্সেসযোগ্য এবং সাশ্রয়ী কৌশলগত যোগাযোগ, প্রশিক্ষণ, নেটওয়ার্কিং সুযোগ এবং কংক্রিট সরঞ্জামগুলি সহ বামপন্থী সংগঠনগুলিকে সরবরাহ করে।ইনস্টিটিউট ফর আমেরিকাস ফিউচার: আইএএফ সামাজিক ঔষধ সমর্থন করে, শিক্ষার জন্য সরকারী তহবিল বৃদ্ধি করে এবং প্রগতিশীল সংখ্যাগরিষ্ঠের কণ্ঠস্বর যাতে শোনা যায় তা নিশ্চিত করার জন্য একটি অবকাঠামো তৈরি করে।ইনস্টিটিউট ফর নিউ ইকোনমিক থিঙ্কিং: একটি নতুন বিশ্বব্যাপী অর্থনৈতিক দৃষ্টান্ত তৈরি করার চেষ্টা করছে, এই সংস্থাটি অসংখ্য ব্যক্তি দ্বারা পরিচালিত যারা জাতীয় অর্থনীতিতে সরকারী হস্তক্ষেপকে সমর্থন করে এবং যারা পুঁজিবাদকে একটি ত্রুটিযুক্ত সিস্টেম হিসাবে দেখে। পলিসি স্টাডিজ ইনস্টিটিউট: এই চিন্তাবিদটি দীর্ঘকাল ধরে বিশ্বব্যাপী কমিউনিস্ট এবং আমেরিকান বিরোধী কারণগুলিকে সমর্থন করে আসছে।অনিয়ন্ত্রিত লোভের জন্য পুঁজিবাদকে একটি প্রজনন ক্ষেত্র হিসাবে দেখে, আইপিএস অনিয়ন্ত্রিত বাজার এবং ব্যক্তিস্বাতন্ত্র্যকে সংশোধন করতে চায়।জাতিসংঘের ধার্মিকতায় একটি প্রশ্নাতীত বিশ্বাসের কথা স্বীকার করে, এটি জাতিসংঘের নিয়ন্ত্রণে আমেরিকান বৈদেশিক নীতি নিয়ে আসার লক্ষ্যে কাজ করে। পাবলিক এককিউরেসি ইনস্টিটিউট: এই আমেরিকান-বিরোধী, পুঁজিবাদী-বিরোধী, ইজরায়েল-বিরোধী সংস্থা স্পনসর্ড অভিনেতা শন পেন এস ২০০২ সালে বাগদাদ সফর উদযাপন করেছিলেন।এটি ডেমোক্রেটিক কংগ্রেসম্যান নিক রাহাল এবং সাবেক ডেমোক্রেট সিনেটর জেমস আবুরেজক ইনস্টিটিউট ফর উইমেনস পলিসি রিসার্চ দ্বারা ইরাকে সফর স্পনসর করেছিল: এই গ্রুপ মার্কিন যুক্তরাষ্ট্রকে নারীর প্রতি বৈষম্যের সাথে একটি জাতি হিসেবে দেখে এবং এই কথিত অবস্থার দিকে দৃষ্টি আকর্ষণ করার জন্য গবেষণা প্রকাশ করে।এ ছাড়া, এটি করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদার অবাধ প্রবেশাধিকারকে সমর্থন করে, এই বলে যে নারী ও মেয়েদের অর্থনৈতিক মঙ্গলের জন্য গর্ভপাতে প্রবেশাধিকার অপরিহার্য।আন্তর্জাতিক ক্রাইসিস গ্রুপ: এই সংস্থার নেতৃস্থানীয় ব্যক্তিত্বদের মধ্যে একজন হলেন মিডইস্ট ডিরেক্টর রবার্ট ম্যালি, যিনি আরব-ইসরায়েল বিষয়ক বিশেষ সহকারী প্রেসিডেন্ট বিল ক্লিনটন ছিলেন।মিডইস্ট সংঘাত নিয়ে তার বিশ্লেষণ ফিলিস্তিনিপন্থী। জে স্ট্রিট: এই ইজরায়েল বিরোধী দল সাবধান করে দেয় যে হামাসের সন্ত্রাসী হামলা বন্ধের জন্য সামরিক পদক্ষেপ নেয়া ইজরায়েলের উচিত পাল্টা ফলপ্রসু হবে আর কেবলমাত্র এই অঞ্চলের ইহুদি ফান্ড ফর জাস্টিসের সংঘাত চক্রকে গভীর করবে: এই সংস্থা সরকারের হস্তক্ষেপ আর করদাতাদের অর্থায়নকে আলোকিত সামাজিক নীতির গুরুত্বপূর্ণ অংশ হিসাবে দেখে।এটি গার্হস্থ্য অর্থনৈতিক ও সামাজিক অবিচারের মূল কারণগুলির বিরুদ্ধে লড়াই করার জন্য যিহূদী দাতাদের কাছ থেকে স্বল্প-আয়ের সম্প্রদায়গুলিতে সম্পদ পুনর্বন্টনের চেষ্টা করে।জেএফজে এস হিসাব অনুযায়ী, মূল কারণগুলির মধ্যে প্রধান হল পুঁজিবাদের অন্তর্নিহিত নেতিবাচক উপজাতগুলি, বিশেষত বর্ণবাদ এবং চরম অর্থনৈতিক বৈষম্য।যৌথ বিজয় অভিযান ২০০৪: জর্জ সোরোস এবং হ্যারল্ড ইকস দ্বারা প্রতিষ্ঠিত, ২০০৪ সালের নির্বাচন চক্রের সময় এই দলটি ডেমোক্রেটদের জন্য একটি প্রধান তহবিল সংগ্রহের সংস্থা ছিল।এই দলটি ডেমক্রেটিক্সের পক্ষে কাজ করে। স্টেকে ন্যায়বিচার: এই জোটটি বিচারকদের নির্দলীয়, মেধা নির্বাচন নামে পরিচিত একটি প্রক্রিয়ায় নিযুক্ত করার আহ্বান জানায়, ভোটদানকারী জনগণের দ্বারা নির্বাচিত না হয়ে। ল্যাটিনো জাস্টিস পিআরএলডিএফ: এই সংস্থাটি দ্বিভাষিক শিক্ষাকে সমর্থন করে, ভোটিং জেলার জাতিগত যাযাবরকরণকে সমর্থন করে এবং অবৈধ এলিয়েনদের জন্য অধিকার প্রসারিত করে। আইনের অধীনে নাগরিক অধিকারের জন্য আইনজীবী কমিটি: এই দলটি আমেরিকাকে একটি অঘোষিত বর্ণবাদী জাতি হিসাবে দেখে; আদালত এই আইনের মাধ্যমে ইতিবাচক জাতি-ভিত্তিক ব্যবসায়ের সীমাবদ্ধতাকে সমর্থন করে।লিন স্টুয়ার্ট ডিফেন্স কমিটি: আইআরএস রেকর্ড নির্দেশ করে যে সোরোস এস ওপেন সোসাইটি ইনস্টিটিউট ২০০২ সালের সেপ্টেম্বর মাসে এই সংস্থাকে ২০,০০০ মার্কিন ডলার অনুদান প্রদান করে।স্টুয়ার্ট ছিলেন অপরাধী-প্রতিরক্ষা অ্যাটর্নি যিনি পরে তার মক্কেল অন্ধ শেখ ওমর আব্দেল রহমানকে তার ইসলামী গ্রুপের সাথে সম্পর্কিত সন্ত্রাসী কর্মকাণ্ডে সহায়তা করার জন্য দোষী সাব্যস্ত হন। ম্যাকসোম ওয়াচ: এই সংস্থাটি নিজেকে ইসরায়েলি নারীদের একটি আন্দোলন, ইসরায়েলি সমাজের সমস্ত ক্ষেত্রের শান্তি কর্মী, যারা ইসরায়েলি দখলদারিত্বের বিরোধিতা করে এবং তাদের দেশে অবাধে চলাচল করার ফিলিস্তিনি অধিকার অস্বীকার করে।মাদ্রেঃ এই আন্তর্জাতিক নারী সংগঠন আমেরিকাকে মানবাধিকার লংঘনকারী হিসেবে গণ্য করে।যেমন, এটি বিশ্বজুড়ে সহিংসতা, দারিদ্র্য এবং নিপীড়নের মুখোমুখি হওয়া নারী এবং পরিবারগুলির উপর মার্কিন নীতির বাস্তব জীবনের প্রভাব এবং মার্কিন নীতিগুলির বিকল্প দাবি করার জন্য যোগাযোগ [স্প্যানিশ] করার চেষ্টা করে।এছাড়াও এটি করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদার অবাধ প্রবেশাধিকারকে সমর্থন করে। ম্যালকম এক্স গ্রাসরুটস মুভমেন্ট: এই দলটি মার্কিন যুক্তরাষ্ট্রকে বর্ণবাদ এবং কালোদের বিরুদ্ধে বৈষম্যের সাথে পরিপূর্ণ একটি জাতি হিসাবে দেখে; দক্ষিণ-পূর্ব যুক্তরাষ্ট্রে একটি স্বাধীন কালো জাতি প্রতিষ্ঠা করতে চায়; এবং দাসত্বের জন্য ক্ষতিপূরণ দাবি করে। ম্যাসাচুসেটস অভিবাসী এবং শরণার্থী অ্যাডভোকেসি কোয়ালিশন: এই দলটি অবৈধ এলিয়েনদের জন্য নাগরিক অধিকার এবং স্বাধীনতা সম্প্রসারণের আহ্বান জানায়; শোক প্রকাশ করে যে আমেরিকাতে অবৈধ এলিয়েনরা সাধারণত শোষণের শিকার হয়; কলেজে পড়াশোনার জন্য পদ্ধতিগত-সহায়তা প্রোগ্রামকে সমর্থন করে; এবং প্যাট্রিয়টস এই আইনটিকে একটি অত্যন্ত রক্ষণশীল রাজনৈতিক গণমাধ্যম তহবিল হিসাবে চিহ্নিত করে, যার মুদ্রিত স্বাধীনতার জন্য খুব অসুবিধা সৃষ্টি করে।দলটি সোরোস-সমর্থিত সেন্টার ফর আমেরিকান প্রোগ্রেসের সাথে ঘনিষ্ঠভাবে কাজ করে এবং গণতন্ত্র জোট দ্বারা ব্যাপকভাবে অর্থায়ন করা হয়, যার মধ্যে সোরোস একজন প্রধান অর্থ যোগানদাতা। মার্সি কর্পস: আরব-ইসরায়েলি সংঘাতের মুখোমুখি হয়ে, মার্সি কর্পস ফিলিস্তিনি দারিদ্র্য এবং সরাসরি ইসরাইলের উপর দুর্ভোগের জন্য দায়ী। মেক্সিকান আমেরিকান লিগ্যাল ডিফেন্স অ্যান্ড এডুকেশন ফান্ড: এই দলটি উন্মুক্ত সীমানা, অবৈধ এলিয়েনদের জন্য কলেজে পড়ার অনুমতি দেয়, হিস্পানিকদের থাকার জন্য শিক্ষাগত মান হ্রাস করে এবং অপরাধীদের পক্ষে ভোট দেওয়ার অধিকার রাখে।মালডেফ এর মতে, ইংরেজীকে আমেরিকার সরকারী ভাষা করার সমর্থকরা বর্ণবাদ আর অভিবাসী বিরোধী মনোভাবের দ্বারা অনুপ্রাণিত, আর নিয়োগকর্তাদের বিরুদ্ধে নিষেধাজ্ঞা যারা অবৈধ শ্রমের উপরে নির্ভরশীল তারা বাদামী চামড়ার মানুষের বিরুদ্ধে বৈষম্যমূলক আচরণ করতে চায়।মেয়ার, সুজ্জি, ইংরেজ এবং ক্লেইন, পিসি: বিগ লেবারের এই প্রভাবশালী সমর্থকের নেতৃত্বে আছেন ডেমোক্রেটের সক্রিয় কর্মী হ্যারল্ড আইকস।মিডওয়েস্ট একাডেমী: এই সত্তা সরাসরি কাজ, লক্ষ্য, সংঘর্ষ এবং ভীতি প্রদর্শনের কৌশলগুলিতে মৌলবাদী কর্মীদের প্রশিক্ষণ দেয়। মাইগ্রেশন পলিসি ইনস্টিটিউট: এই দলটি মাঝারি পর্যায়ে স্থায়ী অভিবাসনের সাথে ধীরে অদৃশ্য সীমান্ত নিয়ন্ত্রণের সাথে উত্তর আমেরিকা তৈরি করতে চায়।সামরিক পরিবার কথা বলছে: এই দলটি যুক্তরাষ্ট্রের ইরাক আক্রমণকে আমেরিকান সাম্রাজ্যবাদ এবং তেলের লালসার সাথে তুলনা করেছে। মিসৌরিয়ানরা সংস্কার ও ক্ষমতায়নের জন্য সংগঠিত: এই দলটি এখন বিলুপ্ত, প্রো-সোশালিস্ট, কমিউনিটি সংস্থা একরন.মুভঅন.অর্গ এর পুনরায় ব্র্যান্ডেড মিসৌরি শাখা: এই ওয়েব-ভিত্তিক সংগঠন গণতান্ত্রিক রাজনৈতিক প্রার্থীদের তহবিল সংগ্রহ, বিজ্ঞাপন, এবং ভোট প্রদানের উদ্যোগের মাধ্যমে সমর্থন করে।ফাউন্ডেশন ফর উইমেন: এই দলটি মার্কিন সমাজের বিস্তৃত এবং স্থায়ী ত্রুটি: বর্ণবাদ, লিঙ্গ বৈষম্য, হোমোফোবিয়া এবং নাগরিক অধিকার ও স্বাধীনতা লংঘনের বিষয়ে এটি যা মনে করে তা নিয়ে দুঃখ প্রকাশ করেছে।এটি নারীদের জন্য ইতিবাচক পদক্ষেপ, করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদার অবাধ অ্যাক্সেস, অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমা এবং বড় সরকারগুলির উপর দৃষ্টি নিবদ্ধ করে। নারাল প্রো-চোইস আমেরিকা: এই দলটি করদাতা-অর্থায়িত গর্ভপাত-অন-দাবি সমর্থন করে এবং গর্ভপাত-বিরোধী ডেমোক্র্যাটদের নির্বাচিত করার জন্য কাজ করে। এনএএসিপি আইনী প্রতিরক্ষা এবং শিক্ষা তহবিল: এনএএসিপি কর্মসংস্থান এবং শিক্ষার জাতিগত পছন্দ এবং ভোটিং জেলার জাতিগত জিমন্যান্ডারিং সমর্থন করে।বর্ণ পছন্দগুলির জন্য তার সমর্থন জোর দিয়ে বিশ্বাস করা হয় যে মার্কিন যুক্তরাষ্ট্রে সাদা বর্ণবাদ একটি অপরিবর্তনীয়, মূলত অনিশ্চিত, ঘটনা। দ্য নেশন ইনস্টিটিউট: এই অলাভজনক সত্তা প্রগতিবাদী কর্মীদের জন্য বামপন্থী সম্মেলন, ফেলোশিপ, পুরষ্কার এবং সাংবাদিকতা ইন্টার্নশিপ স্পনসর করে। জাতীয় গর্ভপাত ফেডারেশন: এই গ্রুপ রাষ্ট্র বা ফেডারেল পর্যায়ে গর্ভপাতের উপর যে কোনও বিধিনিষেধের বিরোধিতা করে এবং বিশ্বের উন্নয়নশীল অঞ্চলে অবাধ গর্ভপাত প্রবর্তনের চ্যাম্পিয়ন। মৃত্যুদন্ড বাতিল করতে জাতীয় জোট: এই দলটি ১৯৭৬ সালে প্রতিষ্ঠিত হয়েছিল প্রথম সম্পূর্ণরূপে কর্মী জাতীয় সংস্থা হিসাবে একচেটিয়াভাবে মৃত্যুদন্ড বিলুপ্ত করার জন্য নিবেদিত।ন্যাশনাল কমিটি ফর রেসপন্সিভ ফিল্যানথ্রপি: এই দলটি মার্কিন যুক্তরাষ্ট্রকে এমন একটি জাতি হিসাবে বর্ণনা করে যা জনহিতৈষী সংস্থার অর্থায়নে নাটকীয় কাঠামোগত পরিবর্তনের প্রয়োজন।এটি ব্যাপকভাবে অনুদান প্রদানকারী এবং অনুদানপ্রাপ্তদের বামপন্থী এজেন্ডার সাথে প্রচার করে, তাদের রক্ষণশীল সহযোগীদের সমালোচনা করে। ভোটিং ইন্টিগ্রিটির জন্য জাতীয় কমিটি: এই দলটি নির্বাচনের অখণ্ডতা নিশ্চিত করার উপায় হিসাবে আমেরিকার নির্বাচনে যোগ্য ভোটারদের নাগরিকত্ব প্রমাণ এবং ছবি সনাক্তকরণ প্রয়োজনীয়তা প্রয়োগের বিরোধিতা করে।ন্যাশনাল কাউন্সিল ফর রিসার্চ অন ওমেন: এই গ্রুপ বড় সরকার, উচ্চ কর, সামরিক ব্যয় হ্রাস, সামাজিক কল্যাণ ব্যয় বৃদ্ধি, এবং করদাতাদের গর্ভপাত-অন-চাহিদার অনিয়ন্ত্রিত অধিকার সমর্থন করে। লা রাজা জাতীয় পরিষদ: এই গ্রুপ জাতিগত পছন্দ, দ্বিভাষিক শিক্ষা, কঠোর ঘৃণা-অপরাধ আইন, গণ অভিবাসন এবং অবৈধ এলিয়েনদের জন্য ক্ষমা দাবি করে। ন্যাশনাল কাউন্সিল অফ ওমেন এস অর্গানাইজেশনস: এই গ্রুপ মার্কিন যুক্তরাষ্ট্রকে নারী ও মহিলাদের বিরুদ্ধে অবিচারের সাথে একটি জাতি হিসাবে দেখে।এটি সামাজিক কল্যাণ কর্মসূচির জন্য উচ্চ স্তরের ব্যয় সমর্থন করে এবং সংখ্যালঘু এবং ব্যবসায় ও একাডেমিয়ায় নারীদের জন্য জাতি ও লিঙ্গ পছন্দ সমর্থন করে। জাতীয় অভিবাসন ফোরাম: বর্তমান অভিবাসন আইনগুলির প্রয়োগের বিরোধিতা করে, এই সংস্থাটি মার্কিন সরকারকে বর্তমানে মার্কিন যুক্তরাষ্ট্রে যে সমস্ত অবৈধ এলিয়েনদের কোন অপরাধমূলক রেকর্ড নেই তাদের আইনীকরণের জন্য এবং মার্কিন যুক্তরাষ্ট্রে অভিবাসন করতে ইচ্ছুকদের জন্য ভিসার সংখ্যা নাটকীয়ভাবে বৃদ্ধি করার আহ্বান জানিয়েছে।ফোরামটি বিশেষত অদক্ষ, নিম্ন-আয়ের শ্রমিকদের জন্য সীমান্ত উন্মুক্ত করতে প্রতিশ্রুতিবদ্ধ এবং তাদেরকে কল্যাণ ও সামাজিক পরিষেবা কার্যক্রমের জন্য উপযুক্ত করে তুলতে প্রতিশ্রুতিবদ্ধ। জাতীয় অভিবাসন আইন কেন্দ্র: এই দলটি অবৈধ এলিয়েনদের জন্য সরকার-তহবিলকৃত সামাজিক কল্যাণ কর্মসূচিতে অবাধ প্রবেশাধিকার পেতে চায়। জাতীয় আইনজীবী গিল্ড: এই দলটি উন্মুক্ত সীমানা প্রচার করে; আমেরিকা গোয়েন্দা-সংগ্রহকারী সংস্থাগুলিকে দুর্বল করার চেষ্টা করে; নাগরিক স্বাধীনতার উপর আক্রমণ হিসাবে প্যাট্রিয়ট অ্যাক্টকে নিন্দা করে; পুঁজিবাদকে একটি অহিংস অর্থনৈতিক ব্যবস্থা হিসাবে প্রত্যাখ্যান করে; দোষী সন্ত্রাসী এবং তাদের সহায়তাকারীদের প্রতিরক্ষা করতে ছুটে এসেছে; এবং সাধারণত মার্কিন যুক্তরাষ্ট্রের সমস্ত বিদেশী নীতির অবস্থানের বিরোধিতা করে, ঠিক যেমন এটি সোভিয়েত-জাতীয় লিঙ্গ বৈষম্য ওমেন সম্প্রদায়কে সমর্থন করার সময় করেছিল।এটি গর্ভাবস্থার যে কোনও পর্যায়ে এবং যে কোনও কারণে করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদা ভোগ করার জন্য নারীদের সর্বজনীন অধিকারের পক্ষেও পরামর্শ দেয়। জাতীয় অগ্রাধিকার প্রকল্প: এই গোষ্ঠী উচ্চতর কর এবং সামাজিক কল্যাণ কর্মসূচিতে বৃহত্তর ব্যয়ের মাধ্যমে সরকার-নিয়ন্ত্রিত সম্পদের পুনর্বণ্টন সমর্থন করে।এনপিপি সরকারকে জনশিক্ষা, সার্বজনীন স্বাস্থ্য বীমা, পরিবেশবাদী প্রকল্প এবং কল্যাণ কর্মসূচিতে তার সামরিক তহবিলের একটি উল্লেখযোগ্য অংশ পুনঃনির্দেশিত করার পরামর্শ দেয়। ন্যাশনাল পাবলিক রেডিও: ১৯৭০ সালে ৯০ টি পাবলিক রেডিও স্টেশনকে চার্টার সদস্য হিসাবে প্রতিষ্ঠিত করে, এনপিআর বর্তমানে সারা দেশে ৭৫০ টিরও বেশি মার্কিন রেডিও স্টেশনগুলির একটি শিথিল নেটওয়ার্ক, যার অনেকগুলি কলেজ এবং বিশ্ববিদ্যালয় ক্যাম্পাসের উপর ভিত্তি করে গঠিত।(উৎস)জাতীয় নিরাপত্তা আর্কাইভ তহবিল: এই দলটি আমেরিকান জাতীয় নিরাপত্তা এবং গোয়েন্দা এজেন্টদের সুরক্ষাকে আপস করে এমন একটি ডিগ্রিতে তথ্য স্বাধীনতা আইনের মাধ্যমে প্রাপ্ত ডিক্লায়েড নথি সংগ্রহ এবং প্রকাশ করে। জাতীয় মহিলা আইন কেন্দ্র: এই দলটি করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদা সমর্থন করে; রক্ষণশীল বিচার বিভাগীয় নিয়োগীদের বিরুদ্ধে লবিং; নিম্ন-আয়ের মায়েদের সহায়তা করার জন্য কল্যাণ ব্যয় বৃদ্ধি করে; এবং সরকারী কর্মসূচী যেমন মেডিকেড, খাদ্য স্ট্যাম্প, কল্যাণ, যত্ন যত্ন, স্বাস্থ্যসেবা, শিশু-সহায়তা প্রয়োগ এবং ছাত্র ঋণগুলির জন্য আরও তহবিল তৈরির উদ্দেশ্যে উচ্চতর কর প্রদান করে। নেচারাল রিসোর্সেস ডিফেন্স কাউন্সিল: মার্কিন যুক্তরাষ্ট্রের অন্যতম প্রভাবশালী পরিবেশগত লবিটিং গ্রুপ, জনগণের একটি পরিষদের সদস্য দাবি করে।নিউ আমেরিকা ফাউন্ডেশন: এই সংস্থা স্বাস্থ্য, পরিবেশবাদ, শক্তি নীতি, মিডইস্ট দ্বন্দ্ব, বিশ্বব্যাপী শাসন এবং আরও অনেক বিষয়ে জনমতকে প্রভাবিত করার জন্য নীতি কাগজপত্র, মিডিয়া নিবন্ধ, বই এবং শিক্ষামূলক ঘটনাগুলি ব্যবহার করে। নিউ ইজরায়েল তহবিল: এই সংস্থা এনজিওগুলিকে সহায়তা দেয় যা নিয়মিত মানবাধিকার লঙ্ঘন এবং ধর্মীয় নির্যাতনের অভিযোগ ইস্রায়েলকে অভিযুক্ত করে এমন প্রতিবেদন তৈরি করে। নিউজকর্পওয়াচ: আমেরিকার জন্য মিডিয়া ম্যাটারস প্রকল্পের একটি প্রকল্প, নিউজকর্পওয়াচ মিডিয়া ম্যাটারসকে ১ মিলিয়ন মার্কিন ডলার অনুদানের সহায়তায় প্রতিষ্ঠিত হয়েছিল। প্যাসিফিকা ফাউন্ডেশন: এই সত্তাটি প্যাসিফিক রেডিও পরিচালনা করে এবং তার জন্ম থেকে সমাজতান্ত্রিক-মার্কসবাদী বাগাড়ম্বরের ভিত্তিতে ধুয়ে দেয় এবং ৬০-যুদ্ধবিরোধী পুঁজিবাদ এবং আরও বামপন্থী সমিতিকে দেয়। এই সংস্থাটি মিডিয়া ম্যাটার্সের চেয়ে ৬০-শান্তি তহবিল দেয়।শান্তি উন্নয়ন তহবিল: পিডিএফ এস ক্যালকুলাসে মার্কিন যুক্তরাষ্ট্রের সামাজিক ও অর্থনৈতিক প্রতিষ্ঠানগুলোর ব্যাপক পরিবর্তন প্রয়োজন।সম্প্রতি পিডিএফ ব্যাখ্যা করছে, আমরা নব্য-উদারনীতিবাদ এবং পুঁজিবাদের বিশ্বায়নের নেতিবাচক প্রভাব, মার্কিন যুক্তরাষ্ট্রের শিল্পায়ন হ্রাস এবং ধনী ও দরিদ্র জনগণের মধ্যে মার্কিন পথের ক্রমবর্ধমান ব্যবধান প্রত্যক্ষ করেছি: এই দলটি প্যাট্রিয়ট অ্যাক্টের বিরোধিতা করে, সাধারণত সন্ত্রাস বিরোধী পদক্ষেপ এবং ধর্মীয় অধিকারের কথিত ক্রমবর্ধমান প্রভাবের বিরোধিতা করে।জনগণকে সংগঠিত করার মাধ্যমে সম্প্রদায় উন্নত করা: এই দলটি মানবাধিকার লঙ্ঘনের নিন্দা জানানোর জন্য আলিনস্কি-শৈলীর সাংগঠনিক কৌশলগুলি ব্যবহার করে। মানবাধিকারের জন্য চিকিৎসক: এই দলটি মানবাধিকার লঙ্ঘনের জন্য মার্কিন যুক্তরাষ্ট্র এবং ইসরাইলের সমালোচনায় বাছাই এবং ভারসাম্যহীনভাবে সমালোচনা করে। সামাজিক দায়বদ্ধতার জন্য চিকিৎসক: এটি একটি মার্কিন-সামরিক সংস্থা যা মৌলিক পরিবেশগত নীতিগুলিকেও আলিঙ্গন করে। পরিকল্পিত প্যারেন্টহুড: এই দলটি মার্কিন যুক্তরাষ্ট্রের বৃহত্তম গর্ভপাত সরবরাহকারী এবং করদাতা-অন-ডেমান্ডের সমর্থক। প্লাগশেয়ার তহবিল: এই পাবলিক অনুদান পিসি ফাউন্ডেশন আমেরিকাকে একটি অত্যন্ত সমালোচনামূলক অর্থনৈতিক উদ্যোগের বিরোধিতা করে, যা নিউ ইয়র্কের একটি নতুন জলবায়ু প্রকল্প তৈরিতে সহায়তা করে।সংগঠনটির প্রধান উপদেষ্টা বিপ্লবী কমিউনিস্ট ভ্যান জোন্স। প্রিজন মোরাটোরিয়াম প্রকল্প: এই উদ্যোগটি ১৯৯৫ সালে মার্কিন যুক্তরাষ্ট্রের সমস্ত কারাগার নির্মূল এবং সমস্ত বন্দীদের মুক্তির জন্য কাজ করার জন্য তৈরি করা হয়েছিল।বন্দীদশা কখনোই অপরাধ মোকাবেলা করার উপযুক্ত উপায় নয় এমন প্রতিজ্ঞা থেকে যুক্তি দিয়ে বলা হয়েছে, আমেরিকান সমাজ সহজাতভাবে সমস্ত অপরাধমূলক আচরণের মূল অযোগ্য বলে মনে করে। প্রগতিশীল পরিবর্তন প্রচারাভিযান কমিটি: এই সংস্থাটি সাহসী প্রগতিশীল প্রার্থীদের ফেডারেল অফিসে নির্বাচন করে এবং [তাদের] অর্থ সঞ্চয়, শ্রমকে আরও স্মার্ট করে এবং আরও বেশি করে জিততে সহায়তা করে।প্রগতিশীল রাজ্য নেটওয়ার্ক: পিএসএন মিশনটি ফরওয়ার্ড-চিন্তাশীল রাজ্য বিধানকারীদের সমন্বিত গবেষণা এবং কৌশলগত এডভোকেসি সরঞ্জাম সরবরাহ করে সমস্ত পঞ্চাশটি রাজ্যে প্রগতিশীল আইন পাস করা।প্রকল্প ভোট: এটি সোরোস-তহবিলকৃত একরনের ভোটার-মোবাইলাইজেশন বাহু।বছরের পর বছর ধরে একর্ন/প্রকল্প ভোট কার্যক্রম অনুসরণ করে আসছে।প্রো পাবলিকা: তদন্তমূলক সাংবাদিকতা ঝুঁকির মধ্যে রয়েছে দাবি করে, এই দলটি সরকার, ব্যবসা এবং অন্যান্য প্রতিষ্ঠানের ক্ষমতার অপব্যবহার এবং বিশ্বাসঘাতকতার কথা প্রকাশ করে [স্প্যানিশ ভাষায়] সংবাদ প্রকাশে এই লাক্ষানাটির প্রতিকার করার লক্ষ্যে অনুসন্ধানমূলক সাংবাদিকতার নৈতিক শক্তি ব্যবহার করে, যা অপরাধের স্থায়ী কেন্দ্রবিন্দুর মাধ্যমে সংস্কারের পক্ষে।প্রোটিয়াস ফান্ড: এই ফাউন্ডেশন বেশ কয়েকটি মৌলিক বামপন্থী সংস্থার প্রতি তার জনসেবা পরিচালনা করে। পাবলিক সিটিজেন ফাউন্ডেশন: পাবলিক সিটিজেন সিটিজেন কর্পোরেশনগুলির বিরুদ্ধে সরকারী হস্তক্ষেপ এবং মামলা মোকদ্দমা বৃদ্ধি করতে চায় এমন একটি অনুশীলনের উপর ভিত্তি করে যে আমেরিকান কর্পোরেশনগুলি, পুঁজিবাদী ব্যবস্থার মতো তারা অংশ, তারা সহজাতভাবে দুর্নীতির দিকে ঝুঁকে থাকে। পাবলিক জাস্টিস সেন্টার: আমেরিকাকে অবিচার ও বৈষম্যের সাথে একটি জাতি হিসাবে দেখে, এই সংস্থাটি আইন ও নীতি ওকালতিতে হস্তক্ষেপ করে অবহেলিতদের জন্য পদ্ধতিগত পরিবর্তন প্রচার করতে।রিবিল্ড অ্যান্ড রিনিউ আমেরিকা নাউ (এ.কে.এ.ইউনিটি ০৯): মুভঅন.অর্গ এর নেতৃত্বে আর দীর্ঘদিনের কর্মী হিথার বুথের তত্ত্বাবধানে, এই জোট গঠিত হয়েছিল প্রেসিডেন্ট ওবামাকে ২০১০ সালের জন্য ৩.৫ ট্রিলিয়ন ডলারের ঐতিহাসিক বাজেট পাসের সুবিধার্থে।রেস পাবলিকা: সারা বিশ্বের বিভিন্ন জায়গায় দূর-বামের এজেন্ডা এগিয়ে নেওয়ার চেষ্টা করে, আরপি ই-অ্যাডভোকেসি বা ওয়েব-ভিত্তিক আন্দোলন-ভবনে বিশেষজ্ঞ। স্টেট প্রজেক্টের সেক্রেটারি: এই প্রকল্পটি ২০০৬ সালের জুলাই মাসে ডেমোক্র্যাটদের নির্বাচিত সুইং বা যুদ্ধক্ষেত্রে সেক্রেটারি অফ স্টেটের অফিসে নির্বাচিত হতে সহায়তা করার জন্য নিবেদিত একটি স্বাধীন ৫২৭ সংস্থা হিসাবে শুরু হয়েছিল। প্রেরণ প্রকল্প: কারাগারে-সেন্সিং প্যাটার্নগুলি জাতিগতভাবে বৈষম্যমূলক, এই উদ্যোগটি অপরাধীদের পক্ষে ভোট দেওয়ার অধিকার সমর্থন করে। সামাজিক ন্যায়বিচার নেতৃত্ব: এই সংস্থাটি একটি নতুন সামাজিক-ন্যায়বিচার আন্দোলনের মাধ্যমে কথিত নির্দোষ আমেরিকাকে কেবল সমাজে রূপান্তরিত করতে চায়।শ্যাডো ডেমোক্রেটিক পার্টি: এটি জর্জ সোরোস এবং অন্যদের দ্বারা সংগঠিত অলাভজনক একটিভিস্ট গ্রুপগুলির একটি বিস্তৃত নেটওয়ার্ক যা সম্পদ অর্থ সংগ্রহ, ভোটের মাধ্যমে বেরিয়ে যাওয়া ড্রাইভ, প্রচারণা বিজ্ঞাপন এবং গণতান্ত্রিক প্রার্থীদের নির্বাচিত করার জন্য নীতি উদ্যোগ এবং বাম দিকে ডেমোক্রেটিক পার্টিকে গাইড করার জন্য সংগঠিত। সোজুরনার্স: এই ধর্মপ্রচারক খ্রিস্টান মন্ত্রিসভা মৌলিক বামপন্থী রাজনীতি প্রচার করে।১৯৮০-এর দশকে এটি মধ্য আমেরিকায় কমিউনিস্ট বিপ্লবকে সমর্থন করে এবং সোভিয়েতদের সম্পর্কে সবচেয়ে খারাপ অনুমান করার প্রবণতার জন্য মার্কিন নীতি নির্ধারকদের শাস্তি দেয়।আরো সম্প্রতি, সজরনার্স পরিবেশ আন্দোলনের কারণ তুলে ধরেছে, কল্যাণ সংস্কারের বিরোধিতা করেছে একটি অর্থ-উদ্দেশ্যপ্রণোদিত রিপাবলিকান এজেন্ডা হিসাবে, এবং ইতিবাচক পদক্ষেপের পক্ষ সমর্থন করেছে। দক্ষিণ দারিদ্র্য আইন কেন্দ্র: এই সংস্থা মার্কিন যুক্তরাষ্ট্রে ঘৃণা গোষ্ঠী বলে অভিহিত কার্যকলাপ পর্যবেক্ষণ করে।এটি আমেরিকান সংখ্যালঘুদের বিরুদ্ধে পরিচালিত সাদা বর্ণবাদের প্রাদুর্ভাবকে অতিরঞ্জিত করে। স্টেট ভয়েসেস: এই জোট ২২ টি রাজ্যের স্বাধীন স্থানীয় সক্রিয় কর্মীদের একটি বছরের ভিত্তিতে যৌথভাবে কাজ করতে সহায়তা করে, যাতে তাদের প্রচেষ্টার প্রভাব সর্বাধিক করতে পারে। ক্রান্তিকাল নিয়ে কথা বলা: নিউইয়র্কের নতুন নির্বাচিত গণতান্ত্রিক মেয়র বিল ডি ব্লাসিওর জন্য সিটি হলে রূপান্তরে সহায়তা করার জন্য ২০১৩ সালের নভেম্বরের গোড়ার দিকে এটি দুই সপ্তাহের একটি প্রকল্প শুরু হয়েছিল। অগ্রগতি চিন্তা করুন: এই ইন্টারনেট ব্লগ তার রক্ষণশীল লক্ষ্যগুলির বিপরীতে প্রতিদিন পিছনে ফিরে যায় এবং দ্রুত যোগাযোগ, আইনী পদক্ষেপ, তৃণমূল এবং অ্যাডভোকেসি এবং বিশ্বব্যাপী অন্যান্য প্রগতিশীল নেতাদের সাথে অংশীদারিত্ব সংগঠিত করার মাধ্যমে প্রগতিশীল ধারণাগুলিকে নীতিতে রূপান্তর করার চেষ্টা করে।থান্ডার রোড গ্রুপ: এই রাজনৈতিক পরামর্শ, যার সৃষ্টিতে সোরোসের একটি হাত ছিল, মিডিয়া ফান্ড, আমেরিকা একত্র হচ্ছে এবং আমেরিকা ভোটস এর জন্য সমন্বয় কৌশল।টাইডস ফাউন্ডেশন এবং টাইডস সেন্টার: টাইডস মৌলিক বাম মার্কিন যুক্তরাষ্ট্রের একটি প্রধান তহবিল।পাবলিক ইন্টারেস্ট রিসার্চ গ্রুপ: এটি ছাত্র গোষ্ঠীর একটি ছাতা সংগঠন যা বামপন্থী এজেন্ডা সমর্থন করে। সার্বজনীন স্বাস্থ্যসেবা অ্যাকশন নেটওয়ার্ক: এই সংস্থা কেন্দ্রীয় সরকার দ্বারা নিয়ন্ত্রিত একক-পেয়ার স্বাস্থ্য সেবা ব্যবস্থাকে সমর্থন করে। আরবান ইনস্টিটিউট: এই গবেষণা সংস্থা সামাজিক ঔষধ, ফেডারেল কল্যাণ আমলাতন্ত্রের সম্প্রসারণ এবং উচ্চ আয়ের-মালিকদের জন্য কর বৃদ্ধিকে সমর্থন করে। ইউএসএকশন এডুকেশন ফান্ড: ইউএসএকশন তার অগ্রাধিকারগুলির তালিকা করে যেমন: সঠিক পক্ষের এজেন্ডার বিরুদ্ধে লড়াই করা; তৃণমূল রাজনৈতিক ক্ষমতা গড়ে তোলা; সকলের জন্য সামাজিক, জাতিগত ও অর্থনৈতিক ন্যায়বিচার শিক্ষিত করা; করদাতাদের অর্থায়নে সামাজিক ঔষধের একটি সিস্টেমকে সমর্থন করা; মিলিয়নিয়ার এবং কর্পোরেশনগুলির জন্য বেপরোয়া কর কর্তনকে পুনরুজ্জীবিত করা যা তাদের নির্বাচিত পরিবেশগত বিষয়গুলির ন্যায্য ও প্রগতিশীল সরকারের পক্ষে কাজ করে; নির্বাচিত পরিবেশগত বিষয়গুলির জন্য তাদের কর্মপরিবেশগত কণ্ঠস্বরকে সমর্থন করে।ভোটো ল্যাটিনো: এই দলটি ল্যাটিন-আমেরিকানদের নিবন্ধিত ভোটার এবং রাজনৈতিক কর্মী হওয়ার জন্য একত্রিত করতে চায়। আমরা আমেরিকা জোট: এই জোট আমেরিকান রাজনৈতিক প্রক্রিয়ায় অভিবাসীদের দ্বারা নাগরিক অংশগ্রহণ বৃদ্ধিকে উৎসাহিত করে। ওয়ার্কিং ফ্যামিলিস পার্টি: সমাজতান্ত্রিক নতুন পার্টির বিকাশ, ডাব্লুএফপি বাম দিকে ডেমোক্রেটিক পার্টিকে চাপ দিতে সহায়তা করার চেষ্টা করে। নির্যাতনের বিরুদ্ধে ওয়ার্ল্ড অর্গানাইজেশন: এই জোট এমন দলগুলির সাথে ঘনিষ্ঠভাবে কাজ করে যারা ফিলিস্তিনি সন্ত্রাসবাদের বিরুদ্ধে ইসরায়েলি নিরাপত্তা ব্যবস্থাকে নিন্দা করে। ওয়াইডব্লিউসিএ ওয়ার্ল্ড অফিস, সুইজারল্যান্ড: ওয়াইডব্লিউসিএ সংযম শিক্ষার বিরোধিতা করে; করদাতা-অর্থায়িত গর্ভপাত-অন-ডেমান্ডের সার্বজনীন প্রবেশাধিকার সমর্থন করে; এবং স্কুল ভাউচারের বিরোধিতা করে।জর্জ সোরোস নেটওয়ার্কের মাধ্যমিক বা পরোক্ষ অধিভুক্তি সরাসরি জর্জ সোরোস এবং তার ওপেন সোসাইটি ইনস্টিটিউট (ওএসআই) দ্বারা অর্থায়ন করা সংস্থা ছাড়াও সোরোস নেটওয়ার্কের অসংখ্য মাধ্যমিক বা পরোক্ষ অনুমোদিত রয়েছে।এর মধ্যে আছে সেইসব সংস্থা যা সোরোস আর ওএসআই থেকে সরাসরি অর্থ পায় না, কিন্তু যা এক বা একাধিক সংস্থার দ্বারা অর্থায়ন করা হয়।- ড. রিচ সুইয়ার জর্জ সোরোসের সাথে সংশ্লিষ্ট সকল গৌণ গ্রুপের তালিকার জন্য, এখানে যান\n"
          ]
        }
      ],
      "source": [
        "max_len = 0\n",
        "max_len_itr =0\n",
        "\n",
        "for i in range(len(final_df)):\n",
        "  sent = sent = final_df['text'][i]\n",
        "\n",
        "  # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "  input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "  # Update the maximum sentence length.\n",
        "  leng = len(input_ids)\n",
        "  if(leng>max_len):\n",
        "    max_len = leng\n",
        "    max_len_itr = i\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "print('sentence: ', final_df['text'][max_len_itr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di5Ii3japzTP"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in final_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNLWYZP-oKns",
        "outputId": "56b6510e-66e4-4c85-c4db-634bcaa83ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শোকজগত ১৭ সেপ্টেম্বর বাংলাদেশ কৃষি বিশ্ববিদ্যালয়ে (বাকৃবি) উপাচার্যের কার্যালয়ে হট্টগোলের ঘটনায় দুইজনকে সাময়িক বরখাস্ত ও ছয় জনকে শোকজ করেছে বিশ্ববিদ্যালয় প্রশাসন। বুধবার বিশ্ববিদ্যালয় বাকৃবি রেজিস্ট্রার সাইফুল ইসলাম স্বাক্ষরিত এক নোটিশে আগামী ৭ দিনের মধ্যে উপযুক্ত উত্তর দেয়ার নির্দেশ দেয়া হয়েছে। এদিকে এ ঘটনায় আন্দোলনের সঙ্গে একাত্বতা প্রকাশ না করায় হামলার শিকার হয়ে কারিগরি কর্মচারী পরিষদের সভাপতি ও সাধারণ সম্পাদক হাসপাতালে ভর্তি হয়েছেন। সাময়িক বরখাস্তরা হলেন- শিক্ষা বিষয়ক শাখার কর্মচারী ও ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন ও কর্মকর্তা পরিষদের যুগ্ম সম্পাদক জিয়াউর রহমান টিটু। এছাড়া বিশ্ববিদ্যালয় সম্প্রসারণ কেন্দ্রের সহকারী পরিচালক মোহাম্মদ আবুল বাসার আমজাদ, ডেপুটি লাইব্রেরিয়ান মো.খাইরুল আলম নান্নু, মো.আবদুল বাতেন, ক্রীড়া প্রশিক্ষণ বিভাগের মোহাম্মদ মোস্তাইন কবীর সোহেল, সংস্থাপন শাখার সহকারী রেজিস্ট্রার মোহাম্মদ আশিকুল আলম বাচ্চু ও খামার ব্যবস্থাপনা শাখার অ্যাডিশনাল রেজিস্ট্রার ড. মো. হেলাল উদ্দীনকে কারণ দর্শানোর নোটিশ দেয় প্রশাসন।  নোটিশে উল্লেখ করা হয়, গত সোমবার দুপুরে সোয়া ১২টার দিকে উপাচার্যের অনুমতি ছাড়াই হঠাৎ করে উপাচার্যের কার্যালয়ে প্রবেশ করে ছাত্র বিষয়ক উপদেষ্টা, প্রক্টর, ডিন কাউন্সিলের আহ্বায়ক, রেজিস্ট্রার ও সাংবাদিকদের সামনে উপাচার্য ও উপ-উপাচার্যকে লক্ষ্য করে আঙ্গুল উচিয়ে কটুক্তি করে এবং অশালীন শারীরিক অঙ্গভঙ্গি করে। এতে করে বিশ্ববিদ্যালয়ের উচ্চ পর্যায়ের প্রাশাসনিক কার্যক্রম ব্যাহত হয় এবং উপাচার্যের সঙ্গে দুর্ব্যবহার করে যা বিশ্ববিদ্যালয়েল চাকরি সংবিধির সুস্পষ্ট লঙ্ঘন ও গুরুতর অপরাধ। এদিকে প্রশাসনের কারণ দর্শানোর নোটিশ পাওয়ার পর অফিসার পরিষদের নেতারা মিছিল নিয়ে হিসাব সংরক্ষণ শাখা, প্রকৌশল শাখা, পরিকল্পনা ও উন্নয়ন শাখায় তালা ঝুঁলিয়ে দেয়। তবে প্রশাসন ভবনে পুলিশ মোতায়ন থাকায় তালা দিতে ব্যর্থ হয়। কর্মকর্তাদের সঙ্গে একাত্বতা প্রকাশ করে কর্মচারীরাও ক্যাম্পাসে মিছিল করে। এসময় তারা প্রশাসনের বিরুদ্ধে বিভিন্ন ধরনে শ্লোগান দিতে থাকে।  এদিকে কারিগরি কর্মচারী পরিষদের পক্ষ থেকে আন্দোলনে সঙ্গে একাত্বতা প্রকাশ না করায় হামলা করে ৩য় ও চতুর্থ শ্রেণির কর্মচারীরা। এবিষয়ে কারিগরি কর্মচারী পরিষদের সভাপতি মো. আবদুল মোতালেব বলেন, আমরা চার দফা দাবিতে ঐক্যবদ্ধ হয়েছিলাম। গত ১৭ সেপ্টেম্বর আমাদের রেখেই ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন কর্মকর্তাদের সঙ্গে ভিসি সচিবালয়ে ঢুকে ভিসির সঙ্গে বেয়াদবি করে। পরবর্তীতে তাকে বিশ্ববিদ্যালয় থেকে শোকজ করলে আমাকে ও আমার সংগঠনের সকলকে তাদের সঙ্গে আন্দোলনে যেতে বলে। যোগ না দিলে পরে ৩য় ও ৪র্থ শ্রেণি মিলে আমাদের সংগঠনে হামলা করে, চেয়ার ভাঙে। এ ঘটনায় আমি ও আমার সংগঠনের সাধারণ সম্পাদক সুলতান আহমেদ আহত হয়ে বর্তমানে ময়মনসিংহ হাসপাতালে ভর্তি আছি। মো. শাহীন সরদার/আরএ/আরআইপি\n",
            "Token IDs: tensor([  101, 11839,  4804,  9417,  4194,  2047,  9294, 15447, 45517,  7932,\n",
            "         7590,  6807, 59969,  3283,  1011,  1026,  4389,  3952, 15547, 47861,\n",
            "          100, 45789, 48214, 13168,  2098, 36470,  2454,  8508, 46084, 19592,\n",
            "         7724,  2756,  8844,  1007, 15447,  4432,  1008, 79927,  8844,  2046,\n",
            "         3697,  7724,  2756,  8844, 11839,  4804,  9417, 27778,  2367,  9294,\n",
            "         7932, 41405, 13334, 33983,  3012,  6807, 59969,  3283,  2038, 14417,\n",
            "         9294,  4389,  3952, 15547,  4033,  2124,  8508, 46084, 19592,  7724,\n",
            "         2756,  9294, 25860, 37587,  1014, 16755,  5128,  8508, 46084, 19592,\n",
            "         7724,  2756,  9294, 15447,  4432, 60809, 22686,  3187,  9494,  2756,\n",
            "         2286, 29291, 46742,  3994,  2066, 10552, 45931, 12265,  2510,  1027,\n",
            "         2522, 31503,  8844,  4099,  9294, 20379, 40596, 12499,  4856, 14979,\n",
            "        21962, 12141,  4856,  7724, 86336,  1014,  3238,  2050,  2367,  9294,\n",
            "         7691, 10968,  4194,  5931, 47174,  9417,  5468, 59464,  3274,  2076,\n",
            "        27551,  2044,  2047,  9294,  3159,  2837, 33668,  2094,  5784, 51798,\n",
            "        12022,  2900,  2408,  2038,  2212,  7505, 97700,  2739, 71009, 86336,\n",
            "         2392,  1014, 13334, 33983,  3012,  6807, 59969, 64294,  2581,  1012,\n",
            "        26723, 15960,  8136,  9294,  3012,  4526, 51798, 12022,  2038,  1023,\n",
            "         9294, 14033,  2094, 28686,  2046,  2212,  7505, 97700,  2446,  2395,\n",
            "         1013,  2446, 48784, 39704,  6249, 38454,  2392,  2038, 33973,  8087,\n",
            "         3274,  2900, 13477, 27664,  7505, 97700,  2656,  7724, 10908,  2188,\n",
            "         2099,  4804,  1014,  2050, 14380,  8705,  8508, 46084, 19592,  7724,\n",
            "         2756,  9294,  7505, 12041,  9276,  2772,  2304, 73668,  2046,  2448,\n",
            "         2264,  2446, 49545, 66474,  5718, 14130,  2756,  7574,  6879,  1011,\n",
            "        29048,  2294, 53819,  6187,  5561, 19264,  2446,  2395,  1013, 55695,\n",
            "         2756,  2507,  2044, 31642,  1011,  2446,  2395,  1013, 38542,  2756,\n",
            "        27826,  1011,  3151,  2765,  8705, 25860,  3924, 41562,  2227,  2446,\n",
            "        49545, 66474,  5718,  2446,  7428, 10338,  2392, 10629,  2118, 14109,\n",
            "         9328,  1011, 67814, 12969, 21549,  4526,  2448, 60809, 22686,  3187,\n",
            "         2446, 49545, 66474,  5718, 16761,  2756,  2507, 57900,  7464,  2038,\n",
            "         7994,  5740, 69734,  2388, 12969, 31903,  4526,  3420,  7724, 73306,\n",
            "        60809, 22686,  3187,  3826,  1013,  2446,  2395,  1013, 11089, 14866,\n",
            "        17864,  2071,  2164,  5234, 61674,  3187, 10552, 45931,  4931,  4856,\n",
            "         9294, 25860, 37587,  1014, 10552, 45931, 12265,  8389, 43928,  2047,\n",
            "        33668,  1011,  2109,  2118,  8507,  5128, 77928,  6187,  2118, 43245,\n",
            "         2395,   100,  2165, 79927,  8844,  2046, 44363,  6399, 18655, 21545,\n",
            "         3451,  2039, 79927,  8844,  2046,  3697,  7724,  2756,  8844, 36419,\n",
            "         4931,  2039, 75752,  2046,  8136,  9294,  3012,  4099, 10968, 96152,\n",
            "         2395,  1011,  2076, 22146,  2046,  1011,  7140, 48720, 20655,  2040,\n",
            "        22620,  4393,  9294,  3012,  1011, 60809, 22686,  3187,  2038,  3104,\n",
            "         2459, 79927,  9294,  2038,  4099,  1012, 79927,  9294,  2071, 11977,\n",
            "        14691,  9294,  2039, 66914, 20547, 70071, 56885,  2094, 35523,  6399,\n",
            "         2039,  2042, 19239,  3675,  3420, 12351, 58759, 12351,  9422,  2039,\n",
            "         1014,  2224,  2039,  8508, 46084, 19592,  7724,  2756,  8844,  2046,\n",
            "        99477,  2076,  7724,  8844,  2046,  6407, 26762,  3924,  3697,  9294,\n",
            "         8087,  3547,  5740,  7724, 34216, 33668,  2042, 79927,  8844,  2046,\n",
            "        47174,  9417,  5234,  4282, 69734, 10425,  2039,  2120,  8508, 46084,\n",
            "        19592,  7724,  2756,  8844,  2756,  3276, 38226,  2046,  7405,  5829,\n",
            "        96152, 68113, 27541,  2038, 32993, 12499,  2958,  1014,  3238, 25860,\n",
            "        37587,  2040,  2164,  5234, 61674,  3187, 10552, 45931,  4931, 23841,\n",
            "        14979,  2076,  4833,  2900,  3791,  5331,  3919,  8844,  3119,  8182,\n",
            "        31002, 41562,  3574,  1011,   100,  3574,  1011, 10440, 13990, 31903,\n",
            "         2038,   102])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', final_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0oUn0Olq_Or",
        "outputId": "f29dc9c4-7fe9-4fd9-cbd9-5c1b013b5b6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8,513 training samples\n",
            "1,503 validation samples\n"
          ]
        }
      ],
      "source": [
        "# from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QLU1GDVrPqd"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e3b8067896e145e98078c19f014fad93",
            "f825c60aa16c45cc9505291ff7022756",
            "a248773f11b746a3a16811a2f51e7aef",
            "1f3406821e724581b857eabf7e8507dc",
            "267f629535f64037b3a209357b106353",
            "7e3cc575698e4f5ca4848526d40ed90b",
            "0a8bd5fbdbf54868861a2c0549cb72a7",
            "2cea705f08234c5f8fe47cf43b093867",
            "877634a2f07e4dd6b61f17491d5a7891",
            "4a2a88260b9a476f96f3040fc2774be1",
            "9499b2eddc9143be8350a0b9951eaeb6"
          ]
        },
        "id": "Q1TqBQ9Rr-Pt",
        "outputId": "faf60eca-1611-46b5-dce7-7d9c71d0dc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--sagorsarker--bangla-bert-base/snapshots/315fa6f024884c29b34a3909a016decc2b068222/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 102025\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/660M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3b8067896e145e98078c19f014fad93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--sagorsarker--bangla-bert-base/snapshots/315fa6f024884c29b34a3909a016decc2b068222/pytorch_model.bin\n",
            "Some weights of the model checkpoint at sagorsarker/bangla-bert-base were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sagorsarker/bangla-bert-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"sagorsarker/bangla-bert-base\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYFhvbHWsgG_"
      },
      "outputs": [],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNweRhQCsl00"
      },
      "outputs": [],
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0RmMrCAs5wL",
        "outputId": "b66ee2ca-91d9-44d7-aba1-d6a1e8f3a912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:03.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:03.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:03.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:03.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:03.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:03.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:03.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:03.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:03.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:03.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:03.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:03.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:03.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:13:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:00.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:00.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:00.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:00.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:00.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:00.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:00.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:00.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:00.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:00.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:13:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.09\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:00.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:00.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:00.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:00.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:00.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:00.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:00.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:00.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:00.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:59.\n",
            "\n",
            "  Average training loss: 0.03\n",
            "  Training epcoh took: 0:13:18\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.97\n",
            "  Validation Loss: 0.13\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:00.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:00.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:00.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:00.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:00.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:59.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:59.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:59.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:59.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:59.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:13:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.15\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:56:27 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CuZSUSwvyb-Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39f7cb2c-7029-4dc7-f1be-93e803821a46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/saved_models/sagorsarkerbbb/config.json\n",
            "Model weights saved in /content/drive/MyDrive/saved_models/sagorsarkerbbb/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "#TM_fnfn : tahsin mayeesha finetune+finetune (first fine tuned with regular train, then model summarized train data)\n",
        "model.save_pretrained('/content/drive/MyDrive/saved_models/sagorsarkerbbb/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXxZ4EBq78PZ"
      },
      "source": [
        "#load data for 2nd fine tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dEJPWWQkSjQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dcdae93-bc37-4369-df4a-58cd32f98ac9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/saved_models/sagorsarkerbbb/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"sagorsarker/bangla-bert-base\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 102025\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/saved_models/sagorsarkerbbb/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/saved_models/sagorsarkerbbb/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "#loading models\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/saved_models/sagorsarkerbbb/\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "loaded_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slFEmH3T720N"
      },
      "outputs": [],
      "source": [
        "#path2 contains modelsum_train\n",
        "final_df = pd.read_csv(path2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7B1q5Vy7hcS"
      },
      "source": [
        "#MODEL TRAINING 2 (modesum train data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omqXOkBa7hci"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in final_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RyUFqJpz7hcj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107c4a9e-eee1-405b-9868-87d150787c4c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  বাংলাদেশের কৃষি বিশ্ববিদ্যালয়ে উপাচার্যের কার্যালয়ে হট্টগোলের ঘটনায় দুইজনকে সাময়িক বরখাস্ত ও ছয় জনকে শোকজ করেছে বিশ্ববিদ্যালয় প্রশাসন। বাকৃবিতে হামলাকারীদের কারণ দর্শানোর নোটিশ দেয়া হয়েছে গত ১৭ সেপ্টেম্বরের দুপুরে। এ ঘটনাকে কেন্দ্র করে   Kuniকেল কোর্টের নির্দেশ অনুযায়ী আগামী ৭ দিনের মধ্যে উত্তর দেয়ার পরামর্শ দিয়েছেন বিশ্ববিদ্যালয়ের শিক্ষার্থীরা।. এর সঙ্গে BBC 코리아 .. ( ) - এই নিয়ে , বিবিসি । (সংবাদিকদের ধারণা : 'আন্তর্জাতিক নকল প্রকাশ বন্ধ করে দেয় প্রধান পক্ষ সরকার।'  এ বিভক্তি সবসময়ই হলেও, এখনো এ বিষয়ে আবারো আলোচনা চলছে। তবে এবারের আন্দোলনে এমন তিনজনকে গ্রেপ্তার করা হচ্ছে নতুন করে দুইজন বিশ্ববিদ্যালয় শিক্ষক এবং শিক্ষকদের বিরুদ্ধে বিভিন্ন ক্ষেত্রে আন্দোলন শুরু হওয়ার পর এখন পর্যন্ত সাক্ষীর সংখ্যা ছাড়াও এসব ব্যবস্থা গ্রহণ করতে চাইছে ছাত্র অধিকার সংগঠনগুলোর একটি বড় অংশের সাথে সামাজিক যোগাযোগ মাধ্যম ভিত্তিক সূত্রগুলোয় দেখা গেছে, যেখানে এ ধরণের বিতর্ক চরমে পৌঁছানো হয়েছে একাধিক অভিযোগের কথা রয়েছে এখানকার বিশ্ববিদ্যালয় কর্তৃপক্ষ।\n",
            "Token IDs: tensor([  101,  2119, 36470,  2454,  8508, 46084, 19592,  7724,  2756,  8844,\n",
            "        79927,  8844,  2046,  3697,  7724,  2756,  8844, 11839,  4804,  9417,\n",
            "        27778,  2367,  9294,  7932, 41405, 13334, 33983,  3012,  6807, 59969,\n",
            "         3283,  2038, 14417,  9294,  4389,  3952, 15547,  4033,  2124,  8508,\n",
            "        46084, 19592,  7724,  2756,  9294, 25860, 37587,  1014, 15447, 45517,\n",
            "        14652,  2164,  5234, 61674,  3187, 10552, 45931,  4931,  4856,  7724,\n",
            "        86336,  2109,   100, 45789, 48214, 13168,  2040, 77928,  6187,  1014,\n",
            "         2050,  8525,  2304, 23054,  2039,   100,  2285,  3187, 13259, 21962,\n",
            "        12141,  5562,  7724, 52395,  2510,  1027,  2522, 31503,  8844, 40596,\n",
            "        12499,  4856, 14979,  6407,  3547,  2046,  4931,  4973,  8844,  5872,\n",
            "         8508, 46084, 19592,  7724,  2756,  8844,  2046, 26723, 48004, 31476,\n",
            "         2429,  1014,  1013,  2063, 47174,  9417,   100,   100,  1013,  1013,\n",
            "         1007,  1008,  1012,  2045,  3919,  8844,  1011,  5098,  1014,  1007,\n",
            "         2824,  3924,  2237,  2509,  1040,  1006, 40230,  2046, 74898,  7809,\n",
            "         2076, 27551, 32188,  2039,  4856,  9294,  2076, 21992, 66821, 14691,\n",
            "         2167,  1014,  1006,  2050,  3309,  5500, 81528,  2132, 12755,  9294,\n",
            "         2062,  2312,  1011,  2112,  2094,  2395,  2050,  8136,  8844,  2239,\n",
            "         2094,  2395, 24182, 35705,  3867,  2525,  1014,  2087,  3690,  7691,\n",
            "        10968,  4194,  6552,  2168,  4809, 32993,  2094, 34687,  3187,  2047,\n",
            "         6264,  7464,  5843, 20670,  2392,  2039,  7932,  7590,  8508, 46084,\n",
            "        19592,  7724,  2756,  9294, 26723, 41425,  2042, 26723, 41425,  2237,\n",
            "        23469,  5718, 39530, 63495,  2392, 19675, 12499,  2094,  7691, 10968,\n",
            "         4194,  2392, 14033, 13669, 14979,  2076,  2112,  2076, 56469,  3283,\n",
            "        35985, 41329,  2046, 77583,  7724, 18655,  8705,  2058,  2189,  5740,\n",
            "        69734,  2388, 12969, 32993, 46510,  2059,  6118, 75752,  2046,  2577,\n",
            "         3153, 64716,  3187,  2051, 62081,  4877,  2179,  2486,  2060, 45928,\n",
            "         8844, 32360, 40806, 85596, 12446, 23299, 36079,  2046, 64716, 43245,\n",
            "         2129,  2149,  1011,  2460,  2050, 11323, 65506,  3012, 22157,   100,\n",
            "        86336,  3007, 79577,  2094, 71982,  2085, 90508,  4689,  8508, 46084,\n",
            "        19592,  7724,  2756,  9294,  3654, 45930, 14691,  1014,   102,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', final_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BZVrpwzh7hck",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "db6b68ee-732b-44aa-f91d-89d82ede4546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "8,513 training samples\n",
            "1,503 validation samples\n"
          ]
        }
      ],
      "source": [
        "# from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XGNi9S97hck"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P5qE-wZd7hcl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abb29c56-3048-4e22-a8b2-131cbec401a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = loaded_model\n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"Tahsin-Mayeesha/bangla-fake-news-mbert\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "#                     # You can increase this for multi-class tasks.   \n",
        "#     output_attentions = False, # Whether the model returns attentions weights.\n",
        "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# )\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzVp6fL27hcl"
      },
      "outputs": [],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73ZGCd4U7hcm"
      },
      "outputs": [],
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdF2QQ4u7hcn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d27140-b02d-4520-81c5-9b89cb3f3d4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:03.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:06.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:08.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:11.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:14.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:17.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:20.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:23.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:25.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:28.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:31.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:34.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:37.\n",
            "\n",
            "  Average training loss: 0.12\n",
            "  Training epcoh took: 0:13:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.06\n",
            "  Validation took: 0:00:54\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:03.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:06.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:08.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:11.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:14.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:17.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:19.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:22.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:25.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:28.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:31.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:33.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:36.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:13:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.11\n",
            "  Validation took: 0:00:54\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:03.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:06.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:09.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:11.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:14.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:17.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:20.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:22.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:25.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:28.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:30.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:33.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:36.\n",
            "\n",
            "  Average training loss: 0.01\n",
            "  Training epcoh took: 0:13:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.12\n",
            "  Validation took: 0:00:54\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:03.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:06.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:08.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:11.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:14.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:17.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:20.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:23.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:25.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:28.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:31.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:34.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:36.\n",
            "\n",
            "  Average training loss: 0.00\n",
            "  Training epcoh took: 0:13:55\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.14\n",
            "  Validation took: 0:00:54\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:59:18 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30E0E4h67hcp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3aa902ad-b6b0-47a6-f364-2b51dc3a458e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in /content/drive/MyDrive/saved_models/sagorsarkerbbb_fnfn/config.json\n",
            "Model weights saved in /content/drive/MyDrive/saved_models/sagorsarkerbbb_fnfn/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "#TM_fnfn : tahsin mayeesha finetune+finetune (first fine tuned with regular train, then model summarized train data)\n",
        "model.save_pretrained('/content/drive/MyDrive/saved_models/sagorsarkerbbb_fnfn/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1y2mQdbwGRR"
      },
      "source": [
        "#load model from saved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUMXkhrU7hcq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f2348c-9dbe-4a3c-e631-467d9645e5b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/saved_models/sagorsarkerbbb_fnfn/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/saved_models/sagorsarkerbbb/\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 102025\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/saved_models/sagorsarkerbbb_fnfn/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/saved_models/sagorsarkerbbb_fnfn/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(102025, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#loading models\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/saved_models/sagorsarkerbbb_fnfn/\",\n",
        "    num_labels = 2\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "loaded_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycrqMjV1z9ei"
      },
      "source": [
        "#Testing with test_df(regular)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiW-7TD8z9ez",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5238c4dc-4549-4c0d-a8b0-8280889f5712"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e5xOg7x_z9e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58dd1163-35d2-4d0c-9103-31370c7746d4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a1240a07-21e1-4c69-9ffb-f09b04369269\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a1240a07-21e1-4c69-9ffb-f09b04369269')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a1240a07-21e1-4c69-9ffb-f09b04369269 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a1240a07-21e1-4c69-9ffb-f09b04369269');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "test_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwmV1eRzz9e0"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "68hgybTvz9e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cfd5aba-224a-447a-fa2f-b3dda93b6a24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  অধ্যাপক গোলাম আযম যে ইস্কুলের মাষ্টার, আমি সে ইস্কুলের চানাচুরওলা: কাদের সিদ্দিকী | দৈনিক মতিকণ্ঠনিজস্ব মতিবেদকচলমান মানবতাবিরোধী অপরাধের বিচার নিয়ে তীব্র ক্ষোভ প্রকাশ করে মুক্তিযুদ্ধকালে কাদেরিয়া বাহিনীর প্রধান বঙ্গবীর আবদুল কাদের সিদ্দিকী বীর উত্তম বলেছেন, এ দেশে কোনো মানবতাবিরোধী অপরাধী নেই। যে দুইজন মানবতাবিরোধী অপরাধী ছিলো, তাদের দেশছাড়া করা হয়েছে। তাদের একজন শহীদ প্রেসিডেন্ট মুক্তিযোদ্ধা জিয়াউর রহমান বীর উত্তমের সন্তান তারেক জিয়া এখন লন্ডনে ফুর্তি করছে। অপরজন বেগম খালেদা জিয়ার অপর সন্তান আরাফাত কোকো বেংককে গেংবেং করছে। দেশ তাই মানবতাবিরোধী অপরাধীমুক্ত।আজ এক সংবাদ সম্মেলনে আবদুল কাদের সিদ্দিকী এ কথা বলেন।তিনি আবেগঘন গলায় বলেন, অধ্যাপক গোলাম আযম একজন অধ্যাপক। তিনি অধ্যাপনা করতেন। মুক্তিযুদ্ধ চলাকালে তিনি টিক্কা খানের শিশুপুত্র খালিদ খানকে আমপারা অধ্যাপনা করতে টিক্কা খানের বাসভবনে যেতেন। অথচ বাকশালীরা গুজব রটিয়েছে তিনি মানবতাবিরোধী অপরাধে লিপ্ত ছিলেন। টিক্কার ছেলেকে আরবী শেখান কেন মানবতাবিরোধী অপরাধ হবে?কাদের সিদ্দিকী বলেন, অনেকেই বলে টিক্কার সাথে অধ্যাপক গোলাম আযমের অবৈধ যৌন সম্পর্ক আছে। তারা ভুল বলে। এ কথা মোটেও সত্য নয়। টিক্কা খান অনেক জোরাজুরি করলেও অধ্যাপক গোলাম আযম কখনও টিক্কার সাথে যৌন সম্পর্কে লিপ্ত হননি। তিনি তখনও পাক ছিলেন, এখনও পাক আছেন।অধ্যাপক গোলাম আযমের কাছে অস্ত্র জমা দিচ্ছেন কাদের সিদ্দিকীআবেগঘন গলায় তিনি বলেন, মুক্তিযুদ্ধের পর ভারতীয় সেনাবাহিনী আমাকে অস্ত্র সমর্পনের আদেশ দিয়েছিল। আমি তাদের বলেছিলাম, তুমাদের আমি চুদি না। এরপর বাংলাদেশ সেনাবাহিনী আমাকে অস্ত্র সমর্পনের আদেশ দিয়েছিল। আমি তাদের বলেছিলাম, তুমাদেরও আমি চুদি না। এরপর ১৯৭৮ সালে অধ্যাপক গোলাম আযম দেশে ফিরে আমাকে অস্ত্র সমর্পনের আদেশ দেন। আমি তখন বলেছিলাম, হুজুর আমি আপনাকেই শুধু চুদি। আপনারা জানেন, আমি অধ্যাপক গোলাম আযমের কদম মুবারকে আমার থ্রি নট থ্রি রাইফেলটি জমা দিয়েছিলাম। কাদের সিদ্দিকী দৃপ্ত কণ্ঠে বলেন, “অস্ত্র জমা দিয়েছি, ট্রেনিং জমা দেই নাই। অধ্যাপক গোলাম আযমের ডাকে দরকার হলে আবার আরেকটি মুক্তিযুদ্ধে ঝাপিয়ে পড়ব। পাক সার জমিন সাদ বাদ।”\n",
            "Token IDs: tensor([  101, 42259,  7724, 45930, 11146, 69514, 19874,  2060, 18873, 40700,\n",
            "         2411, 96152,  3187,  1011,  2169,  2118, 18873, 40700,  2745, 35705,\n",
            "         2046, 30098,  1040,  2467, 53592, 17094,  2765,  1146,  4220, 28441,\n",
            "         3012,  2772, 56492, 14716,  6509, 28441, 31046,  3012, 70021, 19684,\n",
            "        12031,  2094, 41100,  2765,  5213,  2143,  3919,  8844, 67855, 13168,\n",
            "        19675, 28579,  2076, 27551,  2039, 31465,  6399,  9294,  5718, 64784,\n",
            "        21576,  2467, 56885,  2395,  3019,  2076, 21992, 94691,  6203, 16544,\n",
            "        38542,  2756,  2467, 53592, 17094,  2765,  5029, 40596,  4284,  2228,\n",
            "         1011,  2050,  2216,  2285, 31044,  2395, 19684, 12031,  2094, 41100,\n",
            "         2765,  7381,  2128,  1014,  2060,  7932,  7590, 19684, 12031,  2094,\n",
            "        41100,  2765,  7381,  2072,  2094,  2395,  1011,  2092,  2385, 14380,\n",
            "         8705,  2047, 86336,  1014,  2092,  2141,  2614,  2193, 39459,  7052,\n",
            "         4804, 31465,  6399,  8844, 20610, 15279,  2656,  7724, 10908,  2188,\n",
            "         5029, 40596,  4284,  2040, 11799, 14917,  6168,  2656,  7724,  2112,\n",
            "        23345, 18415,  2094,  4009,  6399,  2244,  1014, 28838,  2895,  2421,\n",
            "         2656, 14979,  3369, 11799, 14917, 12632,  2285, 17618,  2395, 63811,\n",
            "        29283, 11146,  4575,  6086,  4575,  2244,  1014,  2385,  2174, 19684,\n",
            "        12031,  2094, 41100,  2765,  7381, 51586,  3283,  1014,  2145,  2066,\n",
            "         2824,  7505, 25542,  6552, 38542,  2756,  2467, 53592, 17094,  2765,\n",
            "         2050,  2085,  2057,  1014,  2049, 31991,  7045,  9294,  2057,  1011,\n",
            "        42259,  7724, 45930, 11146, 69514, 19874,  2141, 42259,  7724, 45930,\n",
            "         1014,  2049, 42259, 39029,  2395,  2741,  1014, 31465,  6399,  9294,\n",
            "         5718, 15537,  7609,  2049, 20063,  5192,  3915, 72990, 34687,  2046,\n",
            "         8178,  8490,  5027, 32152, 42259, 39029,  2395,  2059, 20063,  5192,\n",
            "         3915, 10644,  9958,  1014,  2836, 23977, 15974, 58549, 43988, 56885,\n",
            "        50831,  2049, 19684, 12031,  2094, 41100,  2765,  5374, 22124,  3283,\n",
            "         2096,  1014, 20063,  5076,  7410, 15670, 23279,  2304, 19684, 12031,\n",
            "         2094, 41100,  2765,  2958,  2055,  1045,  2467, 53592, 17094,  2765,\n",
            "         2057,  1011,  2979,  2080, 20063,  5076,  2179, 42259,  7724, 45930,\n",
            "        11146, 69514, 31409,  2266,   100,  7505, 12041,  3012,  2086,  1014,\n",
            "         2131, 37974,  2080,  1014,  2050,  2085,  2446, 21327,  5792, 36079,\n",
            "         9294, 99459,  1014, 20063,  5192,  2328,  2115,  4803, 22880, 78217,\n",
            "         3524, 42259,  7724, 45930, 11146, 69514, 19874,  5426, 20063,  5076,\n",
            "         2179,   100,  7505, 12041,  2071, 22124,  3283,  6338,  1014,  2049,\n",
            "        15213,  8601,  2096,  1011,  6087,  8601,  2442,  1014, 42259,  7724,\n",
            "        45930, 11146, 69514, 31409,  2152, 19362, 12499,  2610,  4973,  7464,\n",
            "         5872,  2467, 53592, 17094,  2765, 62421, 27541,  7045,  9294,  2049,\n",
            "         2057,  1011, 31465,  6399,  9294,  5718, 68492,  2076, 14978,  9294,\n",
            "         4215,  2988, 19362, 12499, 16824, 55327,  2046,  2944,  4973,  8844,\n",
            "         7767,  1014,  2169,  2092, 11698,  1011, 33846,  2237,  2169, 10273,\n",
            "         7777,  2044,  1014,  2275,  2098,  4215,  2988, 19362, 12499, 16824,\n",
            "        55327,  2046,  2944,  4973,  8844,  7767,  1014,  2169,  2092, 11698,\n",
            "         1011, 33846,  2237,  2058,  2169, 10273,  7777,  2044,  1014,  2275,\n",
            "          100,  2068, 42259,  7724, 45930, 11146, 69514, 19874,  2216,  2377,\n",
            "         2988, 19362, 12499, 16824, 55327,  2046,  2944,  2170,  1014,  2169,\n",
            "         2213, 11698,  1011,  6474,  2046,  2169, 52041,  2893, 15537, 10273,\n",
            "         7777,  1014,  4644,  4406,  1011,  2169, 42259,  7724, 45930, 11146,\n",
            "        69514, 31409, 16468, 40719, 40132,  2211, 19440,  2454, 13012, 19440,\n",
            "         2454, 84419,  2610,  4973,  8844, 14523,  1014,  2467, 53592, 17094,\n",
            "         2765, 77928,  3283,  4134,  2772, 42118,  2057,  1011,  1563, 19362,\n",
            "        12499,  2610,  4973,  8844,  7710,  1011, 24223, 67951,  2610, 29059,\n",
            "         5549,   102])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgxoBxXDz9e1"
      },
      "source": [
        "We can see some of the results by the model here. Our model trains on half of the dataset and achieves around 0.80 in overall f1. Its likely that the model is trained longer it will achieve better performance. I might retrain it later on full data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4I0lcQmz9e1"
      },
      "outputs": [],
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQlh9EFOz9e1"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_VLqVCNz9e2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UaYkEw6z9e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3803f9-13d3-4117-9149-9fc7ec2f41d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.89\n",
            "  Test Loss: 0.85\n",
            "  Test took: 0:00:45\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#model = loaded_model\n",
        "loaded_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        outputs = loaded_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        _, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-5uNy9wz9e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0f88b51-00e7-452c-f459-4ae1c45ce23c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.84      0.88       600\n",
            "           1       0.85      0.94      0.89       600\n",
            "\n",
            "    accuracy                           0.89      1200\n",
            "   macro avg       0.89      0.89      0.89      1200\n",
            "weighted avg       0.89      0.89      0.89      1200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9qmSLwBtG_1"
      },
      "source": [
        "#Testing with modelsum_test(summarized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnEQAJ67tR_1"
      },
      "outputs": [],
      "source": [
        "path4 = '/content/drive/MyDrive/datasets/modelsum_test.csv'\n",
        "test_df = pd.read_csv(path4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjakwioetG_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94589ed5-d9ac-49de-a788-6b9e5e8b6c68"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX7Lt9NhtG_5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c18f90-0401-4a50-ed89-29ba9c585d2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yDdorCIHtG_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05482de4-d0eb-4657-bc1d-ebde0f0162d6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  বাংলাদেশের জনপ্রিয় কথাসাহিত্যিক মোস্তফা কামাল...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0e3a998f-be3a-4a4f-a4c2-e91902389df6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>বাংলাদেশের জনপ্রিয় কথাসাহিত্যিক মোস্তফা কামাল...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0e3a998f-be3a-4a4f-a4c2-e91902389df6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0e3a998f-be3a-4a4f-a4c2-e91902389df6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0e3a998f-be3a-4a4f-a4c2-e91902389df6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "test_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb-aFgRitG_7"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNUjhpu7tG_8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4dc732d-b3a2-46c9-df6d-1157a97508b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  বাংলাদেশে মানবতাবিরোধী অপরাধের বিচার নিয়ে তীব্র ক্ষোভ প্রকাশ করেছেন দৈনিক মতিকণ্ঠ। মুক্তিযুদ্ধের সময় বিএনপির চেয়ারপার্সন আবদুল কাদের সিদ্দিকী এবং তাঁর পরিবারের সদস্যরা তাকে গ্রেপ্তার ছাড়ার জন্য সরকার ব্যবস্থা গ্রহণ করেছে.  ,  BBC নিউজ এর পক্ষ থেকে এ বিষয়ে তৈরি কোন তথ্য বের হচ্ছে না - যার মধ্যে এক  Kuni ( ( ) ? ' বিবিসি ’ র সঙ্গে এখনও এই দেশে মানসিকতার বিচারে যুক্ত নেই .. এ সব ক্ষেত্রেই তারা গত কাল ঢাকায় জন্ম হল । এমন কী ভাবেন জাতিসংঘের একজন সাবেক প্রধানমন্ত্রী জিয়া খানকে গুলি করেন অধ্যাপক গোলাম আযমের বিরুদ্ধে যে অভিযোগ উঠেছে, সেই অভিজ্ঞতার কথা বললেও বিবিসির সংবাদ মাধ্যমে এসব খবর পাওয়া গেছে ইস্কুলের মাষ্টার, যিনি অবৈধভাবে টিক্কার সাথে যৌন সম্পর্কে লিপ্ত ছিলেন, তাদের দেশছাড়া তিনি এখনো বন্ধ করা হয়নি ; কিন্তু পাকিস্তানী নাগরিকদের কাছে এত মানুষের মত লোকজন এখানে আবারো যুদ্ধাপরাধীদের মৃত্যুর ঘটনা তো ঠিকই ছিলো, যে তিনজনের সামাজিক যোগাযোগ\n",
            "Token IDs: tensor([  101,  2368, 19684, 12031,  2094, 41100,  2765,  5213,  2143,  3919,\n",
            "         8844, 67855, 13168, 19675, 28579,  2076, 27551,  2102,  4220, 28441,\n",
            "         3012,  2772, 19519,  1014, 31465,  6399,  9294,  5718, 68492, 94306,\n",
            "         2364, 10790, 14979, 89821, 38542,  2756,  2467, 53592, 17094,  2765,\n",
            "         2042,  2056,  2569, 78383, 52349,  2395,  2271, 32993,  2094, 34687,\n",
            "         3187, 18655, 11544,  2181,  9294,  2167,  5740, 69734,  2388, 12969,\n",
            "        32993, 46510,  2124,  1013,  1011,   100,  6169,  2063, 66821, 14691,\n",
            "         2043,  2050,  8136,  8844,  2163,  2285,  5803, 48431,  9294,  2468,\n",
            "         6264,  7464,  5843,  2044,  1012,  2305, 31503,  8844,  2066,   100,\n",
            "         1007,  1007,  1008,  1045,  1006,  5098,  1561,  2313, 47174,  9417,\n",
            "         6087,  2045,  2216, 14369,  6609, 13477, 20379,  2128,  1013,  1013,\n",
            "         2050,  2132, 19675, 12499,  5981,  2131,  2109,  3373,  2185,  9294,\n",
            "        39747,  2245,  1014,  2168,  2201,  9974,  2917,  2141,  2290,  2076,\n",
            "        21992, 10951, 42396,  2656,  7724,  8490, 14464,  2053, 42259,  7724,\n",
            "        45930, 11146, 69514, 31409, 23469,  5718, 39530,  2060, 79577,  2094,\n",
            "        32360,  2864,  1011,  2123, 14631,  4033, 35828,  4305,  2085, 10124,\n",
            "         7533,  2824, 40806, 85596,  2094,  2189,  2550, 23841,  7724,  2149,\n",
            "        18873, 40700,  2411, 96152,  3187,  1011,  2730,  8179, 20063,  5076,\n",
            "         2179,   100,  7505, 12041,  2071, 22124,  3283,  2096,  1011,  2092,\n",
            "         2385, 14380,  8705,  2049,  2112,  2094,  2395, 32188,  2047, 33668,\n",
            "         4204,  1041, 77801, 70638,  2388, 14917,  2765,  4387,  2152,  2592,\n",
            "         3175, 47678,  2797,  5942, 15547,  7590,  2235,  2239,  2094,  2395,\n",
            "        13477,  5718, 36840,  2429, 32580,  2237,  2797, 52349,  2367,  4058,\n",
            "         2395,  6898,  2072,  2094,  2395,  1011,  2060,  7902,  2486,  2060,\n",
            "        45928,  8844, 32360,   102,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyp994tntG_9"
      },
      "source": [
        "We can see some of the results by the model here. Our model trains on half of the dataset and achieves around 0.80 in overall f1. Its likely that the model is trained longer it will achieve better performance. I might retrain it later on full data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww40748CtG_9"
      },
      "outputs": [],
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ5ly3hhtG_-"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwgOoNYYtG_-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWk58-BNtG__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e4d643-40b7-4f75-a888-189e358b4b07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.71\n",
            "  Test Loss: 2.49\n",
            "  Test took: 0:00:43\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#model = loaded_model\n",
        "loaded_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        outputs = loaded_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        _, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkMU8ESktHAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37638cc-5022-47a4-c39e-32d1743bb7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.53      0.65       600\n",
            "           1       0.65      0.89      0.76       600\n",
            "\n",
            "    accuracy                           0.71      1200\n",
            "   macro avg       0.74      0.71      0.70      1200\n",
            "weighted avg       0.74      0.71      0.70      1200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QloXfBVVjlZh",
        "EhQIDJ6il66B",
        "XpmaLJWyNB2U"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e71ce1a8c11a4dbd9d04dec7cc0b839f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c3d9f91817949fab42e7b31caf6e1fc",
              "IPY_MODEL_ed247d64a20649ff97fa16a3c10b12a9",
              "IPY_MODEL_52c81f6e1ae4469bab4543c967e41d07"
            ],
            "layout": "IPY_MODEL_40c9e1ebbbc549c89a933b0e1db22243"
          }
        },
        "1c3d9f91817949fab42e7b31caf6e1fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d324b2353524e01a6d95daa297e3997",
            "placeholder": "​",
            "style": "IPY_MODEL_e77d100ccc75411d9c134b24c573c1d9",
            "value": "Downloading: 100%"
          }
        },
        "ed247d64a20649ff97fa16a3c10b12a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d9152a954644180a976432303cf4882",
            "max": 491,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_116bf0cd6605422692b5f19e992eae72",
            "value": 491
          }
        },
        "52c81f6e1ae4469bab4543c967e41d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97665fb6c9d242a99c2f55897958ea1f",
            "placeholder": "​",
            "style": "IPY_MODEL_43998f6084a94bccb1273091429a2513",
            "value": " 491/491 [00:00&lt;00:00, 12.0kB/s]"
          }
        },
        "40c9e1ebbbc549c89a933b0e1db22243": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d324b2353524e01a6d95daa297e3997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e77d100ccc75411d9c134b24c573c1d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d9152a954644180a976432303cf4882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116bf0cd6605422692b5f19e992eae72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "97665fb6c9d242a99c2f55897958ea1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43998f6084a94bccb1273091429a2513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8462402fb6f4d089bf03448a009de92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d87c189509cf4e9f88b9c98ee5406911",
              "IPY_MODEL_6e8b57dbe1174601833ce23696bd7894",
              "IPY_MODEL_fbee4d0d018a4fd0b6c94b12dc34dd25"
            ],
            "layout": "IPY_MODEL_9b762e3c8dc446189e9c5e3df84679cd"
          }
        },
        "d87c189509cf4e9f88b9c98ee5406911": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_84e3edea666147ee8bc94a4ee13845e2",
            "placeholder": "​",
            "style": "IPY_MODEL_df27bcd352d64e8fad166d67b5e9f943",
            "value": "Downloading: 100%"
          }
        },
        "6e8b57dbe1174601833ce23696bd7894": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fc2c136474404801868f606efb71477b",
            "max": 2237676,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b2e36512eb35492aa75137b305ddcafc",
            "value": 2237676
          }
        },
        "fbee4d0d018a4fd0b6c94b12dc34dd25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d473c6b496ed450bac926920b51fe545",
            "placeholder": "​",
            "style": "IPY_MODEL_548b2c9c752d4b7fab5300f2bab94bfe",
            "value": " 2.24M/2.24M [00:00&lt;00:00, 7.27MB/s]"
          }
        },
        "9b762e3c8dc446189e9c5e3df84679cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84e3edea666147ee8bc94a4ee13845e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df27bcd352d64e8fad166d67b5e9f943": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fc2c136474404801868f606efb71477b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2e36512eb35492aa75137b305ddcafc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d473c6b496ed450bac926920b51fe545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "548b2c9c752d4b7fab5300f2bab94bfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3b8067896e145e98078c19f014fad93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f825c60aa16c45cc9505291ff7022756",
              "IPY_MODEL_a248773f11b746a3a16811a2f51e7aef",
              "IPY_MODEL_1f3406821e724581b857eabf7e8507dc"
            ],
            "layout": "IPY_MODEL_267f629535f64037b3a209357b106353"
          }
        },
        "f825c60aa16c45cc9505291ff7022756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e3cc575698e4f5ca4848526d40ed90b",
            "placeholder": "​",
            "style": "IPY_MODEL_0a8bd5fbdbf54868861a2c0549cb72a7",
            "value": "Downloading: 100%"
          }
        },
        "a248773f11b746a3a16811a2f51e7aef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cea705f08234c5f8fe47cf43b093867",
            "max": 660417638,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_877634a2f07e4dd6b61f17491d5a7891",
            "value": 660417638
          }
        },
        "1f3406821e724581b857eabf7e8507dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a2a88260b9a476f96f3040fc2774be1",
            "placeholder": "​",
            "style": "IPY_MODEL_9499b2eddc9143be8350a0b9951eaeb6",
            "value": " 660M/660M [00:09&lt;00:00, 39.1MB/s]"
          }
        },
        "267f629535f64037b3a209357b106353": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e3cc575698e4f5ca4848526d40ed90b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a8bd5fbdbf54868861a2c0549cb72a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cea705f08234c5f8fe47cf43b093867": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "877634a2f07e4dd6b61f17491d5a7891": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4a2a88260b9a476f96f3040fc2774be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9499b2eddc9143be8350a0b9951eaeb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}