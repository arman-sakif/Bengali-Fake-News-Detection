{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVbzepNk5h-X"
      },
      "source": [
        "##Pips"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOq7B_40lDK9",
        "outputId": "d31a4515-66fd-4d79-a13a-0bd980aa0691"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLXleXuvNmOV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e0Ni-8Uqswow",
        "outputId": "9ff97d77-fd6c-4eda-e33f-bf617044d001"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaUFAGkoOjw9"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeHFP-aKe8yS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEtV-2-RNpO5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQJ_1ZHyvhne"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import *\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spCh2Lun43Td"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, AutoTokenizer\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "import time\n",
        "import datetime\n",
        "import random\n",
        "#note: importing something 2nd time does not cause any performance loss \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PeSKEGgL6RaO"
      },
      "source": [
        "##Load Datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKsvtoZ-6QuU"
      },
      "outputs": [],
      "source": [
        "path1 = '/content/drive/MyDrive/datasets/train.csv'\n",
        "path2 = '/content/drive/MyDrive/datasets/modelsum_train.csv'\n",
        "path3 = '/content/drive/MyDrive/datasets/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J5EqTc526gg2"
      },
      "outputs": [],
      "source": [
        "final_df = pd.read_csv(path1)\n",
        "test_df = pd.read_csv(path3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycik9pTI6m26",
        "outputId": "236fab02-35f2-4155-ab4b-3d042a2fa50f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10016, 2), (1200, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "final_df.shape, test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw2nWrN06ufX",
        "outputId": "8b628041-567b-48c0-8fa9-d8370f634091"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5008\n",
              "0    5008\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "#this is necessary because model won't run if there are NAN values. Though Training set is clean, this is for double check\n",
        "final_df = final_df.dropna() \n",
        "final_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FJ8u5GuJ6qiD",
        "outputId": "9a809028-9d31-4a25-d0db-0a4ee516ad64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    5008\n",
              "0    5008\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "final_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ae5rhzVm6ySx",
        "outputId": "cb2a2ec7-e64a-443e-84ed-85df6a16be29"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   label                                               text\n",
              "0      1  হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শো...\n",
              "1      1  মালয়েশিয়ায় কর্মী পাঠানোর ব্যবস্থা নেয়ার সুপারি...\n",
              "2      1  প্রেমের প্রস্তাবে রাজি না হওয়ায় স্কুলছাত্রীকে ...\n",
              "3      1  মেডিয়েশনই মামলাজট নিরসনের পথ : বিচারপতি আহমেদ ...\n",
              "4      1  টকশোতে বক্তব্য দিতে গিয়ে জাপা নেতার মৃত্যুমাদা..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-568f4f01-1427-4c9a-8ca5-133224456da5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শো...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>মালয়েশিয়ায় কর্মী পাঠানোর ব্যবস্থা নেয়ার সুপারি...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>প্রেমের প্রস্তাবে রাজি না হওয়ায় স্কুলছাত্রীকে ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>মেডিয়েশনই মামলাজট নিরসনের পথ : বিচারপতি আহমেদ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>টকশোতে বক্তব্য দিতে গিয়ে জাপা নেতার মৃত্যুমাদা...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-568f4f01-1427-4c9a-8ca5-133224456da5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-568f4f01-1427-4c9a-8ca5-133224456da5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-568f4f01-1427-4c9a-8ca5-133224456da5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "final_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1e8eKa460zXB"
      },
      "source": [
        "#prerequisites for model train/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c9dcc0acd96e45c18f0e853bf403a794",
            "64bc8c0b98d24730988810a5ed9583fb",
            "4db6041e38664766abe5beb3e322f2f8",
            "b5de1eafeca647d1a1e9f25d93041811",
            "691ef4b9a9204180b8ed87f27c3f3210",
            "606ce278a16e404681719137483b2149",
            "0853097ad1ca40f98a472aeceafed905",
            "55edede4c4fe48289b1b3884a657a67e",
            "8a551944ff3e44d09553637a955add26",
            "629302cc44a64185bbbb8fcf15213473",
            "309ce77eac0541ff912e016e89abdea7",
            "238ec9805c45474987980d3ef28aaf02",
            "b9cb4c39d99b4788b34a0726f4b164ef",
            "5f37396b162440f1a9f9282e0f234bdc",
            "9c150cf5c35642cca4dfdfe714fb3e87",
            "86a4bbc8951c4dc1b7df1e6ac337b2a8",
            "58a147b23313435e8808dbb237a8cb60",
            "eca703045a1c4600a3347a2ceb1df57d",
            "183508222e2241d18541b96204b2b07e",
            "18a2ed183f394843a661ac0629e1435a",
            "a0ac548ca9fa453ebfc5675f5051038b",
            "11e2a10675804cfeb61ca3096467c4c9",
            "0d186fbfdc984819893be6ca213950cb",
            "08bb5d0162bf4c219f25397ee497a581",
            "685a0c6a4bf14ad1a81098d2dee681a9",
            "ff69ac9550264ab3a27645f09654a34e",
            "91e2c31539174b4da986daddd93c6896",
            "5095b1d9cd924d609b2ff39941e511fa",
            "a17bfe5576c84d17b7dad8793386b3b8",
            "96e68a1c7c0941ac9873697e5dea84d8",
            "277f6ecfc316410287b76d6490f51804",
            "a088bbfb0e8549a0a24dc17a7332a364",
            "a8eefd8c2ddb4dd88048aa679a69dff5",
            "5f6e80fa4bdc4b60b9730ceb0b91ef73",
            "b3533b21db984eb2a6ee5acba40c3b53",
            "01533dbb8fcb4e01817aec67242cba2b",
            "c3133b3a187148d2b83684c62a113b27",
            "30aa584466804722bffebe3a3fa14d0f",
            "b82990028d834fc3b86281f80fb7d8e6",
            "0de5c100100f4531bf69f6579766095e",
            "48df543bcfd74e7ea4848a847c51d948",
            "c8743e0d46ad404aba69641edcce70b1",
            "d0bdccb7dc1b4e10bf71d8097abee067",
            "b51444cb720f437eabb121bc7dc60a02"
          ]
        },
        "id": "3f-UgLMel4fl",
        "outputId": "e48b6320-2e8f-45ce-859e-ca15bf4f9f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading BERT tokenizer...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/29.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c9dcc0acd96e45c18f0e853bf403a794"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/625 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "238ec9805c45474987980d3ef28aaf02"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0d186fbfdc984819893be6ca213950cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.96M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f6e80fa4bdc4b60b9730ceb0b91ef73"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/vocab.txt\n",
            "loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# from transformers import BertTokenizer, AutoTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = AutoTokenizer.from_pretrained('bert-base-multilingual-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WOaNQVs81VkV"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy of our predictions vs labels\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fm6bcFR7syJH"
      },
      "outputs": [],
      "source": [
        "# import time\n",
        "# import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhQIDJ6il66B"
      },
      "source": [
        "#MODEL TRAINING 1 (train data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GjHYMxNtmCsS",
        "outputId": "fc70b578-7004-4144-d0e1-4e30bf3dbf9d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (1061 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Max sentence length:  19694\n",
            "sentence:  আমেরিকা বিরোধী জর্জ সরস ট্রাম্পের বিরুদ্ধে এনএফএল দিয়ে অস্ত্র আটক করেছেআমরা এইমাত্র এনএফএলকে সমর্থন না করার আরেকটি কারণ আবিষ্কার করলাম যে ব্যক্তিটি সবচেয়ে এন্টি-আমেরিকান, যাকে আমরা জানি সে এখন ন্যাশনাল ফুটবল লীগ প্লেয়ারস অ্যাসোসিয়েশন (এনএফএলপিএ)-এর সাথে যুক্ত। এনএফএলপিএ সম্প্রতি আর্থিক ভাবে এমন এক সত্যকে সমর্থন করেছে যে দূর-বাম সংগঠনের তালিকা তৈরি করেছে, প্লানড প্যারেন্টহুড থেকে শুরু করে অবৈধ অভিবাসীদের বিতাড়নের প্রতিবাদে সংগঠন, যাদের মধ্যে অনেকের ঘটনা রয়েছে।এই ধরনের একজন ব্যক্তি ওপেন সোসাইটি ফাউন্ডেশন ছাড়া আর কেউ নন, যার প্রধান কোটিপতি জর্জ সোরস.২য় ভোট পেয়েছেন এনএফএলপিএ সোরোস সেন্টার ফর কমিউনিটি চেঞ্জ এ্যাকশন নামক প্রতিষ্ঠানের সামাজিক ন্যায়বিচার শাখাকে আর্থিক সহায়তা প্রদান করছে। ওয়াশিংটন ফ্রি বিকন-এর মতে এই প্রতিষ্ঠানটি নভেম্বরের আগে এবং পরে প্রেসিডেন্ট ডোনাল্ড ট্রাম্প এবং রিপাবলিকানদের বিরুদ্ধে সরাসরি ব্যবস্থা গ্রহণ করেছে।এনএফএলপিএ কমপক্ষে ২০১৩ সালের দিকে ডেটিং করে বেশ কয়েকটি সুদূরপ্রসারী এবং বিরোধী-ট্রাম্প কারণ দান করছে। মার্কিন যুক্তরাষ্ট্রে সর্বাধিক মৌলিক এবং দূর-বাম কারণগুলির কয়েকটি তহবিলের একটি দীর্ঘ ইতিহাস রয়েছে। তিনি ২০১২ সালের ওয়াল স্ট্রিট দখল প্রতিবাদকে সমর্থন করেছেন বলে জানা যায়, ন্যাশনাল রিসোর্স ডিফেন্স কাউন্সিল, একটি ট্রাম বিরোধী পরিবেশবাদী সংগঠন, পরিকল্পিত প্যারেন্টহুড সহ গর্ভপাত-পন্থী আন্দোলন এবং অসংখ্য অ্যান্টি-ট্রাম্প প্রতিরোধের কারণও রয়েছে। সোরোস ওয়াশিংটনের উইমেনস মার্চের মূল অংশীদারদের অন্তত ৫৬ টি তহবিল দিয়েছে, যা ট্রাম্পের উদ্বোধনের পরের দিন ঘটেছিল। আরেকটি মাঠপর্যায়ের স্বত:স্ফূর্ত অভিযানের জন্য তহবিল গঠন করা হয়েছে, এবং এটি আরও স্বতঃস্ফূর্তভাবে পরিচালিত হবে।এই ১৮৭টি সংস্থা সরাসরি জর্জ সোরোসের অর্থায়নে পরিচালিত এই তালিকার কয়েকটি নাম আপনাকে হতবাক করবে গর্ভপাত গ্রুপ, উন্মুক্ত সীমান্ত, অভিবাসী গ্রুপ, গ্রুপ, গ্রুপকে আমরা যেভাবে ভোট দিই, বৈশ্বিক স্বাস্থ্যসেবা, জলবায়ু পরিবর্তন, ক্যাথলিক, সমাজতান্ত্রিক এবং কমিউনিস্টদের পরিবর্তন করতে।সোরোসের আসলে একটা দল রয়েছে, যাদের লক্ষ্য হল ধনী যিহুদিদের কাছ থেকে টাকাপয়সা নিয়ে কম লোকেদের কাছে তা দেওয়া।গতকাল প্রকাশিত একটি ভিডিওতে জর্জ সোরোস (একজন ইহুদি) স্বীকার করেছেন যে তিনি দ্বিতীয় বিশ্বযুদ্ধের সময় ইহুদিদের কাছ থেকে সম্পত্তি বাজেয়াপ্ত করতে সাহায্য করেছেন, এই ধারণা যে সোরোস এমন একটি দলকে অর্থায়ন করছে তা আসলে অত আশ্চর্যজনক নয়। তারা সবাই এখানে।১৮৭ টি দল আমেরিকাকে ধ্বংস করতে ব্যবহৃত হচ্ছে, ধন্যবান কোটিপতি জর্জ সোরোস।এখানে সেই সব দল যারা ট্রাম্পের নির্বাচনকে আমেরিকা দখলের অজুহাত হিসেবে ব্যবহার করছে: জর্জ সোরোস এবং তার যৌথবাদী সক্রিয়তা নিয়ে অনেক নিবন্ধ লেখা হয়েছে।সোরোস একজন ব্যবসায়ী, বিনিয়োগকারী, জনহিতৈষী এবং লেখক যিনি ইহুদি-হাঙ্গেরিয়ান বংশোদ্ভূত এবং দ্বৈত নাগরিকত্বের অধিকারী।তিনি সোরোস ফান্ড ম্যানেজমেন্টের চেয়ারম্যান।আবিষ্কার নেটওয়ার্কস সোরোস এবং তার ওপেন সোসাইটি ইনস্টিটিউটের অর্থায়নে পরিচালিত সংস্থাগুলির একটি বিস্তৃত তালিকা প্রকাশ করেছে। এই দলগুলির মধ্যে কয়েকটি সক্রিয়ভাবে রাষ্ট্রপতি ডোনাল্ড ট্রাম্পের বিরোধিতা করেছে এবং তার সমাবেশে দেখা সাম্প্রতিক সহিংসতা ও বিশৃঙ্খলার স্তরের অংশ হতে পারে।অনেক গোষ্ঠীই সমর্থন করে: উন্মুক্ত সীমানা, রাজক্ষমা, অবৈধ ভোটের অধিকার প্রদান, মুসলিম অভিবাসন এবং সামাজিক ন্যায়বিচার। সাম্প্রতিক বছরগুলিতে জর্জ সোরোস এবং তাঁর ওপেন সোসাইটি ইনস্টিটিউট (ওএসআই) থেকে সরাসরি তহবিল এবং সহায়তা পেয়েছে এমন সংস্থাগুলি নিম্নরূপ:(ডিসকভারদ্যনেটওয়ার্কস.অর্গ এর গ্রুপ বিভাগে প্রতিটির সমন্বিত প্রোফাইল পাওয়া যায়): অ্যাডভান্সমেন্ট প্রকল্প: এই সংস্থা বাম বিশ্বের মতামত এবং মূল্যগুলি বিস্তৃতভাবে একটি অত্যাধুনিক যোগাযোগ বিভাগের মাধ্যমে যতটা সম্ভব ছড়িয়ে দেওয়ার সময় রঙের সম্প্রদায়গুলিকে রাজনৈতিকভাবে সমন্বয়মূলক ইউনিটগুলিতে সংগঠিত করার জন্য কাজ করে। এয়ার আমেরিকা রেডিও: এখন বিলুপ্ত, এটি একটি স্ব-চিহ্নিত উদার রেডিও নেটওয়ার্ক ছিল। আমাদের সবাই বা না: এই সংস্থা ভোটিং আইনগুলি পরিবর্তন করতে চায় যা প্রাক্তন-বন্দী, চরমপন্থীদের এবং এমনকি বর্তমান কারাবন্দীদের রাজনৈতিক নির্বাচনে তাদের ব্যালটগুলি নিক্ষেপ করতে অনুমতি দেওয়ার জন্য রাষ্ট্র থেকে রাজ্যে পরিবর্তিত হয়। ন্যায়বিচার গ্রুপ হিসাবে পরিচিত: প্রজাতন্ত্রের এই সক্রিয়তার জন্য ধারাবাহিকভাবে একটি ফেডারেল বিচারক হিসাবে পরিচিত।আমেরিকা একত্রিত হচ্ছে: সোরোস এই গ্রুপ তৈরিতে একটি প্রধান ভূমিকা পালন করেছে, যার উদ্দেশ্য ছিল গণতন্ত্রপন্থী ভোটার-মোবাইলাইজেশন প্রোগ্রামগুলির সমন্বয় এবং সংগঠিত করা। আমেরিকা ভোটস: সোরোসও এই গ্রুপ তৈরিতে একটি প্রধান ভূমিকা পালন করেছে, যার ভোটের প্রচারণা সম্ভাব্য গণতান্ত্রিক ভোটারদের লক্ষ্য করে। আমেরিকা এস ভয়েস: এই উন্মুক্ত বর্ডার গ্রুপ বিস্তৃত অভিবাসন সংস্কার প্রচার করতে চায় যার মধ্যে অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমার পক্ষে একটি শক্তিশালী এজেন্ডা রয়েছে। আমেরিকান বার অ্যাসোসিয়েশন কমিশন অন ইমিগ্রেশন পলিসি: এই সংস্থা নিয়োগকর্তা এবং শিক্ষা, স্বাস্থ্যসেবা বা অভিবাসন অবস্থা যাচাই করার জন্য অন্যান্য সামাজিক পরিষেবা প্রদানকারী ব্যক্তিদের আইনের বিরোধিতা করে।আমেরিকান ব্রিজ ২১শ শতাব্দী: এই সুপার প্যাক গণতান্ত্রিক রাজনৈতিক প্রার্থীদের তাদের রিপাবলিকান শত্রুদের পরাজিত করতে সাহায্য করার জন্য ডিজাইন করা বিরোধী গবেষণা পরিচালনা করে। আমেরিকান সিভিল লিবার্টিস ইউনিয়ন: এই দলটি মার্কিন সরকারের ৯/১১ পরবর্তী সমস্ত জাতীয় নিরাপত্তা ব্যবস্থার বিরোধিতা করে।এটি উন্মুক্ত সীমান্ত সমর্থন করে, সন্দেহভাজন সন্ত্রাসী এবং তাদের সহায়তাকারীদের প্রতিরক্ষায় দ্রুত এগিয়ে এসেছে এবং প্রাক্তন নিউ লেফট সন্ত্রাসী বার্নার্ডিন ডর্নকে এর উপদেষ্টা বোর্ডের জন্য নিযুক্ত করেছে। আমেরিকান সংবিধান সোসাইটি ফর ল এন্ড পলিসি: এই ওয়াশিংটন, ডিসি-ভিত্তিক চিন্তাবিদরা তরুণ আইন শিক্ষার্থীদের নিয়োগ, দীক্ষা এবং সংগঠিত করে ক্ষমতার অবস্থান অর্জনে সাহায্য করে বাম দিকে আমেরিকান আইনশাস্ত্রকে স্থানান্তরিত করার চেষ্টা করে।এটি বামপন্থী ডেমোক্রেটদের একটি উৎপীড়ক মঞ্চও সরবরাহ করে যা তাদের রাজনৈতিক প্রতিপক্ষের নিন্দা করে। আমেরিকান ফ্যামিলি ভয়েস: এই দলটি রিপাবলিকানদের বিরুদ্ধে অন্যায়ের অভিযোগ আনে এমন মিডিয়া প্রচারণা তৈরি এবং সমন্বয় সাধন করে। আমেরিকান ফেডারেশন অফ টিচারস: ১৯৯৭ সালে দীর্ঘদিনের এএফটি প্রেসিডেন্ট আলবার্ট শ্যাঙ্কার মারা যাওয়ার পরে, তিনি সান্ড্রা ফেল্ডম্যানের স্থলাভিষিক্ত হন, যিনি ধীরে ধীরে ইউনিয়নটিকে নতুন শ্রম আন্দোলনের সবচেয়ে শক্তিশালী বামপন্থী উপাদানগুলির সাথে সংযুক্ত করেন।২০০৪ সালে ফেল্ডম্যানের মৃত্যুর পর, এডওয়ার্ড ম্যাকএলরয় তার স্থলাভিষিক্ত হন এবং ২০০৮ সালে র্যান্ডি ওয়েঙ্গার্টেন তার স্থলাভিষিক্ত হন।আমেরিকান ফ্রেন্ডস সার্ভিস কমিটি: এই দলটি যুক্তরাষ্ট্রকে সারা বিশ্বের মানুষের দুঃখকষ্টের প্রধান কারণ হিসেবে দেখে থাকে।যেমন, এটা আমেরিকাকে একতরফা নিরস্ত্রীকরণ, আমেরিকান সীমানা বিলোপ, অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমা, মৃত্যুদণ্ড বিলোপ এবং প্যাট্রিয়ট অ্যাক্ট বাতিলের পক্ষে। আমেরিকান ইমিগ্রেশন কাউন্সিল: এই অলাভজনক সংস্থা উন্মুক্ত সীমান্ত লবির বিশিষ্ট সদস্য।এটি আমেরিকান ইমিগ্রেশন ল ফাউন্ডেশনে বসবাসকারী অবৈধ এলিয়েনদের অধিকার এবং ক্ষমা প্রসারিত করে: এই দলটি অবৈধ এলিয়েনদের জন্য ক্ষমাকে সমর্থন করে, যার পক্ষে এটি মার্কিন সরকারের বিরুদ্ধে মামলা করে। আমেরিকান ইন্ডিপেন্ডেন্ট নিউজ নেটওয়ার্ক: এই সংস্থাটি প্রগতিশীল পরিবর্তনের পক্ষে সমর্থনকারী প্রভাব সাংবাদিকতা প্রচার করে।আমেরিকান ইনস্টিটিউট ফর সোসাল জাস্টিস: এআইএসজে এর লক্ষ্য হচ্ছে দক্ষ সম্প্রদায়ের সংগঠক তৈরি করা যারা শহুরে পরিষেবা, মাদক নিষেধাজ্ঞা, অপরাধ প্রতিরোধ, গৃহায়ণ, পাবলিক সেক্টরের কাজ, স্বাস্থ্যসেবা এবং পাবলিক স্কুলগুলিতে বর্ধিত সরকারী ব্যয় বৃদ্ধির জন্য বিক্ষোভ করে দরিদ্র সম্প্রদায়কে রূপান্তরিত করতে পারে। আমেরিকান লাইব্রেরি অ্যাসোসিয়েশন: এই দলটি সন্ত্রাসের বিরুদ্ধে বুশ প্রশাসনের যুদ্ধ এর একটি স্পষ্টবাদী সমালোচক, মার্কিন প্যাট্রিয়ট অ্যাক্টের ধারা ২১৫, যা লাইব্রেরি ব্যবহারকারীদের সাংবিধানিক অধিকার এবং গোপনীয়তা অধিকারের বর্তমান বিপদ বলে অভিহিত করে।দ্য আমেরিকান প্রসপেক্ট, ইনক: এই কর্পোরেশন তরুণ বামপন্থী সাংবাদিকদের প্রশিক্ষণ দেয় এবং বামপন্থী নেতাদের জন্য কৌশল সভার আয়োজন করে।অ্যামনেস্টি ইন্টারন্যাশনাল: এই সংস্থা যুক্তরাষ্ট্র আর ইজরায়েলে মানবাধিকার লঙ্ঘনের জন্য তাদের সমালোচনার একটা অসামঞ্জস্য ভাগ ঠিক করে। ফলিত গবেষণা কেন্দ্র: আমেরিকাকে এমন একটা জাতি হিসাবে দেখা যেখানে কাঠামোগত বর্ণবাদ সমাজের কাঠামোর মধ্যে গভীরভাবে প্রোথিত, আরসি চেষ্টা করে একটা ন্যায় আর সমান সমাজ গড়ে তুলতে আমাদের সব থেকে শক্তিশালী প্রতিষ্ঠান থেকে সুনির্দিষ্ট পরিবর্তন দাবি করে।আরব আমেরিকান ইনস্টিটিউট ফাউন্ডেশন: আরব আমেরিকান ইনস্টিটিউট ৯/১১ পরবর্তী সময়ে আরব আমেরিকানদের বিরুদ্ধে পরিচালিত ব্যাপক নাগরিক স্বাধীনতা লঙ্ঘনের নিন্দা করে এবং ইস্রায়েলকে ফিলিস্তিনি জনগণের নৃশংস নিপীড়নকারী হিসাবে চিহ্নিত করে। অ্যাসপেন ইনস্টিটিউট: এই সংস্থা মৌলিক পরিবেশবাদ প্রচার করে এবং আমেরিকাকে এমন একটি জাতি হিসাবে দেখে যা গভীর আসনের কাঠামোগত বর্ণবাদ দ্বারা জর্জরিত।অ্যাসোসিয়েশন অফ কমিউনিটি অরগানাইজেশন ফর রিফর্ম নাউ: এই দলটি বামপন্থী ডেমোক্রেটদের পক্ষে ভোটার আন্দোলন পরিচালনা করে।এই উদ্যোগগুলো প্রতারণা এবং দুর্নীতির দ্বারা কুখ্যাতভাবে ক্ষতিগ্রস্ত হয়েছে। ব্যালট ইনিশিয়েটিভ স্ট্র্যাটেজি সেন্টার: এই সংস্থা একটি জাতীয় প্রগতিশীল কৌশলকে এগিয়ে নিয়ে যাওয়ার চেষ্টা করছে ভোটের মাধ্যমে রাষ্ট্র-স্তরের আইনী প্রস্তাবগুলি যা একটি পিটিশন (উদ্যোগ) প্রক্রিয়ার মাধ্যমে সফলভাবে পাস হয় এবং তারপর জনগণের দ্বারা ভোট দেওয়া হয়। বিল অফ রাইটস ডিফেন্স কমিটি: এই দলটি সক্রিয় কর্মীদের জন্য একটি বিস্তারিত ব্লুপ্রিন্ট সরবরাহ করে যারা তাদের স্থানীয় শহর, শহর এবং এমনকি কলেজ ক্যাম্পাসগুলিকে তাদের দেশপ্রেম আইনের বিরোধিতা প্রকাশ্যে ঘোষণা করতে এবং নিজেদের নাগরিক স্বাধীনতা নিরাপদ অঞ্চল হিসাবে চিহ্নিত করতে আগ্রহী।সংগঠনটি সন্ত্রাসবাদের জন্য বস্তুগত সহায়তা প্রদানের জন্য ২০০৫ সালে দোষী সাব্যস্ত হওয়া মৌলবাদী অ্যাটর্নি লিন স্টুয়ার্টের প্রতিরক্ষায়ও এসেছিল। ব্ল্যাক অ্যালায়েন্স ফর জাস্ট ইমিগ্রেশন: এই সংস্থা কালো জাতিগত পরিচয়ের উপর কেন্দ্রীভূত সামাজিক ও অর্থনৈতিক ন্যায়বিচারের জন্য একটি ঐক্যবদ্ধ আন্দোলন তৈরি করতে চায়। ব্লুপ্রিন্ট নর্থ ক্যারোলিনা: এই দলটি উত্তর ক্যারোলিনায় রাষ্ট্রীয় নীতি প্রভাবিত করতে চায় যাতে রাজ্যের বাসিন্দারা আরও প্রগতিশীল নীতিগুলি যেমন স্বাস্থ্যসেবা, উচ্চতর মজুরি, আরও সাশ্রয়ী মূল্যের হাউজিং, নিরাপদ, পরিষ্কার পরিবেশ এবং প্রজনন স্বাস্থ্যসেবা অ্যাক্সেস থেকে উপকৃত হয়।ব্রেনান সেন্টার ফর জাস্টিস: এই চিন্তাবিদ ট্যাঙ্ক/আইনী একটিভিস্ট গ্রুপ পাণ্ডিত্যপূর্ণ গবেষণা তৈরি করে, প্রচার মাধ্যমের প্রচারণা বৃদ্ধি করে, এমিকাসের সংক্ষিপ্ত নথি প্রকাশ করে, সক্রিয় কর্মীদের জন্য বোনো সমর্থন প্রদান করে এবং মৌলিক পরিবর্তনের জন্য পরীক্ষামূলক মামলা দায়ের করে।ব্রুকিংস ইনস্টিটিউশন: এই সংগঠনটি বিভিন্ন আন্তর্জাতিকতাবাদী এবং রাষ্ট্র-পৃষ্ঠপোষক প্রোগ্রামগুলির সাথে জড়িত, যার মধ্যে একটি জাতিসংঘ-শাসিত বিশ্ব সরকার প্রতিষ্ঠার জন্য উত্সাহী।ব্রুকিংস ফেলোগণ ব্যবসা ও ব্যাংকিং-এর উপর বৈশ্বিক সহযোগিতা, কিয়োটো প্রটোকলের সম্প্রসারণ এবং শিশুদের জন্য জাতীয়কৃত স্বাস্থ্য বীমার আহবান জানিয়েছেন।নয় জন ব্রুকিংস অর্থনীতিবিদ ২০০৩ সালে প্রেসিডেন্ট বুশের বিরুদ্ধে একটি পিটিশনে স্বাক্ষর করেছেন। আমেরিকার ভবিষ্যৎ এর জন্য ক্যাম্পেইন: এই দলটি কর বৃদ্ধি, সামাজিক ঔষধ, এবং সামাজিক কল্যাণ কর্মসূচির নাটকীয় সম্প্রসারণ সমর্থন করে। উন্নততর স্বাস্থ্যসেবার জন্য ক্যাম্পেইন: এই সংস্থাটি একক প্রদায়ক, সরকার পরিচালিত, সার্বজনীন স্বাস্থ্যসেবা ব্যবস্থাকে সমর্থন করে।ক্যাম্পেইন ফর ইয়থ জাস্টিস: এই সংগঠন দাবি করে যে, কিশোর-কিশোরীদের প্রাপ্তবয়স্ক অপরাধ-বিচার ব্যবস্থায় স্থানান্তরিত করা, অপরাধ-প্রতিরোধের উচ্চ হারের দিকে পরিচালিত করে, কারারুদ্ধ করে রাখে এবং অপ্রয়োজনীয় ঝুঁকিতে আটক রাখে, তাদের প্রতিরোধের মূল্য খুব কম এবং জনগণের নিরাপত্তা বৃদ্ধি করে না।ক্যাম্পাস প্রোগ্রেস: সোরোস-ব্যাংকরোলড সেন্টার ফর আমেরিকান প্রগ্রেসের একটি প্রকল্প, এই দলটি কলেজ এবং বিশ্ববিদ্যালয় ক্যাম্পাসগুলিতে প্রগতিশীল কণ্ঠস্বরকে শক্তিশালী করার চেষ্টা করে, ক্যাম্পাসে ডানপন্থী দলগুলোর ক্রমবর্ধমান প্রভাব মোকাবেলা করে এবং নতুন প্রজন্মের প্রগতিশীল নেতাদের ক্ষমতায়ন করে।কাসা ডি ম্যারিল্যান্ড: এই সংস্থাটি মার্কিন যুক্তরাষ্ট্রে বর্তমানে বসবাসরত অবৈধ এলিয়েনদের ক্ষমা সহ প্রসারিত অধিকারগুলির প্রচার করা নীতিগুলির পক্ষে ভোট দেওয়ার জন্য বিধায়কদের তীব্রভাবে লবি করে। ক্যাটালিস্ট: এটি একটি লাভজনক রাজনৈতিক পরামর্শ যা প্রগতিশীল সংস্থাগুলিকে সাহায্য করতে চায়, প্রতিটি ভোট-বয়স আমেরিকানের একটি শক্তিশালী জাতীয় ভোটার ডাটাবেস নির্মাণ এবং পরিচালনা করে নাগরিক অংশগ্রহণ এবং নির্বাচনী সাফল্যের পরিমাপযোগ্য বৃদ্ধি উপলব্ধি করতে।ক্যাথলিক ফর চয়েজ: এই নামমাত্র ক্যাথলিক সংস্থা মহিলাদের গর্ভপাত-অন-চাহিদার অধিকার সমর্থন করে। অ্যালায়েন্স ফর দ্য কমন গুড: এই রাজনৈতিক অলাভজনক গ্রুপ বামপন্থী প্রার্থী, কারণ এবং আইন প্রণয়নের জন্য ক্যাথলিক সম্প্রদায়ের কাছ থেকে সমর্থন আদায়ের জন্য নিবেদিত। আমেরিকান অগ্রগতির জন্য কেন্দ্র: এই বামপন্থী চিন্তাবিদের নেতৃত্বে প্রাক্তন ক্লিনটন চিফ অফ স্টাফ জন পোডেস্টা, হিলারি ক্লিনটনের সাথে ঘনিষ্ঠভাবে কাজ করেন এবং অসংখ্য প্রাক্তন ক্লিনটন প্রশাসন কর্মী নিয়োগ করেন।এটি একটি প্রগতিশীল আমেরিকা সম্পর্কে একটি দীর্ঘমেয়াদী ধারণা গড়ে তুলতে এবং নতুন প্রগতিশীল ধারণা ও নীতি প্রস্তাব তৈরির জন্য একটি ফোরাম তৈরি করতে প্রতিশ্রুতিবদ্ধ।সেন্টার ফর কমিউনিটি চেঞ্জ: এই দলটি বামপন্থী রাজনৈতিক ইস্যু প্রচারণার নেতৃত্ব দেওয়ার জন্য কর্মীদের নিয়োগ এবং প্রশিক্ষণ দেয়।দারিদ্রের সাথে সম্পর্কিত প্রধান জাতীয় বিষয়গুলির প্রতি দৃষ্টি আকর্ষণ করে সামাজিক কল্যাণ কর্মসূচির জন্য বর্ধিত তহবিল গঠন করে, কেন্দ্রটি প্রখ্যাত মৌলবাদী সংগঠক শৌল আলিনস্কির শেখানো কৌশলগুলির উপর তার প্রশিক্ষণ কর্মসূচির ভিত্তি করে। সাংবিধানিক অধিকারের জন্য কেন্দ্র: এই ক্যাস্ট্রোপন্থী সংগঠনটি উন্মুক্ত সীমান্ত লবির মূল সদস্য, মার্কিন সরকারের ৯/১১ পরবর্তী সমস্ত সন্ত্রাসবাদ বিরোধী পদক্ষেপের বিরোধিতা করেছে এবং অভিযোগ করেছে যে আমেরিকান অবিচার আন্তর্জাতিক সন্ত্রাসবাদের কাজকে প্ররোচিত করে। অর্থনৈতিক ও নীতি গবেষণা কেন্দ্র: এই দলটি কল্যাণ সংস্কারের বিরোধিতা করে, জীবিত মজুরি আইন সমর্থন করে, কর কর্তন প্রত্যাখ্যান করে এবং ধারাবাহিকভাবে সমাজতান্ত্রিক শাসকদের কৃতিত্বগুলিকে প্রশংসা করে, বিশেষত ভেনিজুয়েলা। সমস্ত উত্পাদনশীল মিশন, মহিলাদের জন্য নিরাপদ গর্ভপাতের নিশ্চয়তা দেয়।সংস্থাটি নিম্ন-আয়ের মহিলাদের জন্য করদাতা-অর্থায়িত গর্ভপাত (মেডিকেডের মাধ্যমে) অ্যাক্সেসের দাবি করে রাজ্য ও ফেডারেল মামলা দায়ের করেছে। দায়ী ঋণ কেন্দ্রের: এই সংস্থাটি সাব-প্রাইম বন্ধক সংকটের একটি প্রধান খেলোয়াড় ছিল।ফিল কারপেন (আমেরিকানদের প্রোস্পারিটি নীতির ভাইস প্রেসিডেন্ট) এর মতে, সিআরএল বাতিল করে দিয়েছে আর ব্যাংকগুলোকে হয়রানি করেছে অযোগ্য ঋণগ্রহীতাদের খারাপ ঋণ দিতে।এছাড়াও, সিআরএল বাজেট এবং নীতি অগ্রাধিকারের উপর ফ্যানি মে সেন্টারকে উচ্চ ঝুঁকির ঋণের শর্ত হিসাবে কাজ করতে সক্ষম করে এমন একটি চুক্তি নিয়ে আলোচনা করেছে: কর কর্তন সাধারণত ধনীদের সহায়তা করে এমন প্রাঙ্গণ থেকে যুক্তি দিয়ে, এই সংস্থাটি নিম্ন আয়ের লোকদের জন্য সামাজিক কল্যাণ কর্মসূচির উপর বৃহত্তর কর ব্যয়কে সমর্থন করে। উইসকনসিন স্ট্র্যাটেজি (সিওএস) কেন্দ্র: যাদের আয় গড়ের উপরে তাদের উপর আরোপিত উচ্চতর করের মাধ্যমে সম্পদকে পুনর্বণ্টনের লক্ষ্যে, কাওস যুক্তি দেখায় যে এটি গুরুত্বপূর্ণ যে রাষ্ট্রীয় সরকার কর্পোরেশন এবং ধনী সহ সমাজের সমস্ত অংশ থেকে ন্যায্য অবদান সংগ্রহ করতে সক্ষম হবে।চেঞ্জ আমেরিকা নাউ: ২০০৬ সালের ডিসেম্বর মাসে গঠিত চেঞ্জ আমেরিকা নাউ নিজেকে একটি স্বাধীন রাজনৈতিক সংস্থা হিসাবে বর্ণনা করেছে যা রিপাবলিকান কংগ্রেসের ব্যর্থ নীতি সম্পর্কে নাগরিকদের শিক্ষিত করার জন্য তৈরি করা হয়েছিল এবং একটি গণতান্ত্রিক এজেন্ডা দ্বারা প্রদত্ত প্রতিশ্রুতির সাথে ব্যর্থতার রেকর্ডের বিপরীতে।ওয়াশিংটনে দায়িত্ব ও নৈতিকতার জন্য নাগরিক: এই দলটি সরকারি কর্মকর্তাদের বিরুদ্ধে মামলা দায়ের করে এবং নৈতিকতার অভিযোগ আনে, যারা বিশেষ স্বার্থের জন্য সাধারণ কল্যাণকে বিসর্জন দেয় এবং জনগণের আস্থাকে বিশ্বাসঘাতকতা করে।এর প্রায় সকল লক্ষ্য রিপাবলিকান। একটি আন্তর্জাতিক অপরাধ আদালতের জন্য সহযোগিতা: এই দলটি একটি আন্তর্জাতিক আদালতের কাছে আমেরিকান অপরাধ-বিচার পদ্ধতি অধস্তন করতে চায়। সাধারণ কারণ: এই সংস্থার লক্ষ্য হল প্রচারণা-অর্থ সংস্কার আনা, ফেয়ারনেস ডকট্রিনের মতো মিডিয়া সংস্কার অনুসরণ করা এবং সামাজিক-কল্যাণ এবং পরিবেশগত ব্যয় বাড়ানোর পক্ষে সামরিক বাজেট হ্রাস করা। সংবিধান প্রকল্প: এই সংস্থা সামরিক কমিশনের বৈধতা চ্যালেঞ্জ করতে চায়; শত্রু যোদ্ধাদের আটক শেষ করা; সন্ত্রাসীদের সরকারি নজরদারির নিন্দা করা; এবং রাষ্ট্রপতির নির্বাহী সুবিধা সীমিত করা। ওয়াইল্ডলাইফ অ্যাকশন ফান্ডের রক্ষাকারীরা: আলাস্কার জাতীয় বন্যপ্রাণী তেল অনুসন্ধানের বিরোধিতা করে।এটি লগিং, র্যাঞ্চিং, মাইনিং এবং এমনকি বিনোদনমূলক মোটরচালিত যানবাহনকে পরিবেশের জন্য ধ্বংসাত্মক কার্যকলাপ হিসাবে ব্যবহার করাকে নিন্দা করে। গণতন্ত্র জোট: এই স্ব-বর্ণিত উদার সংগঠন বামপন্থী দলগুলির জন্য তহবিল ক্লিয়ারিং হাউস বিকাশের জন্য ২০০ মিলিয়ন ডলার সংগ্রহ করার লক্ষ্য রাখে।সোরোস এই দলের প্রধান দাতা। ডেমোক্রাসি ২১: এই দলটি ২০০২ সালের দ্বিপক্ষীয় প্রচারণা সংস্কার আইনের একনিষ্ঠ সমর্থক, এছাড়াও এটি ম্যাককেইন-ফিঙ্গোল্ড অ্যাক্ট.ডেমোক্রাসি নাও নামে পরিচিত!: ডেমোক্রেসি নাউ!ডব্লিউবিআই রেডিও সংবাদ পরিচালক এমি গুডম্যান এবং চার অংশীদার ১৯৯৬ সালে মার্কিন কর্পোরেট-পৃষ্ঠপোষক মিডিয়াতে কদাচিৎ শোনা দৃষ্টিকোণগুলি সরবরাহ করার জন্য তৈরি করেছিলেন, উদাহরণস্বরূপ, র্যাডিকাল এবং বিদেশী সাংবাদিকদের দৃষ্টিভঙ্গি, বামপন্থী এবং শ্রম কর্মী এবং পুঁজিবাদের মতাদর্শিক শত্রু। ডেমোক্রেটিক জাস্টিস ফান্ড: ডিজেএফ প্যাট্রিয়ট অ্যাক্টের বিরোধিতা করে এবং যুক্তরাষ্ট্রে বিশেষত সন্ত্রাসী জাতি হিসাবে স্টেট ডিপার্টমেন্টের মনোনীত দেশ থেকে অভিবাসন নিয়ন্ত্রণ বা নিয়ন্ত্রণের সর্বাধিক প্রচেষ্টা।ডেমোক্রেটিক পার্টি: সোরোস তহবিল কার্যক্রম মূলত ডেমোক্রেটিক পার্টিকে তার ক্ষমতার ভিত্তি দৃঢ় করতে সাহায্য করার জন্য নিবেদিত।২০০৩ সালের নভেম্বর মাসে এক সাক্ষাৎকারে সোরোস বলেছিলেন যে, ২০০৪ সালে প্রেসিডেন্ট বুশকে পরাজিত করাই আমার জীবন ও মৃত্যুর মূল বিষয়।তিনি বুশকে পরাজিত করার জন্য ৭৫ মিলিয়ন মার্কিন ডলার সংগ্রহ করার অঙ্গীকার করেছিলেন এবং ব্যক্তিগতভাবে বুশ-বিরোধী সংস্থাগুলিকে সেই অর্থের এক তৃতীয়াংশ দান করেছিলেন।তিনি বলেন, বুশের অধীনস্থ আমেরিকা বিশ্বের জন্য একটি বিপদ এবং আমি আমার মুখ যেখানে আছে সেখানে আমার টাকা দিতে ইচ্ছুক।ডেমোস: এই সংস্থা ফেডারেল আর রাষ্ট্রীয় নীতি নির্ধারকদের কাছে আবেদন করেছে অর্থনৈতিক নিরাপত্তা আর বৈষম্য তুলে ধরার জন্য যা আজকে আমেরিকান সমাজের বৈশিষ্ট্য তুলে ধরে; সম্পদ, আয় আর রাজনৈতিক প্রভাবের মধ্যে ফাঁক কমানোর ধারণা তুলে ধরে; আর ধনীদের জন্য কর বাড়ানোকে সমর্থন করে। ড্রাম মেজর ইন্সটিটিউট: এই দল নিজেকে বর্ণনা করে নির্দলীয়, অলাভজনক চিন্তাবিদ হিসাবে যা এই ধারণা তৈরি করে যা প্রগতিশীল আন্দোলনকে উৎসাহিত করে, নীতি নির্ধারক আর মতামত নেতাদের রাজি করার চূড়ান্ত লক্ষ্য নিয়ে যে পদক্ষেপ নেয়া সামাজিক আর অর্থনৈতিক ন্যায় বিচার সম্পর্কে তাদের দৃষ্টিকে এগিয়ে নিয়ে যাবে।আর্থজাস্টিস: এই দলটি মার্কিন যুক্তরাষ্ট্রের ভূমি ও জলপথ কিভাবে ব্যবহার করা যেতে পারে তার উপর কঠোর বিধিনিষেধ আরোপ করতে চায়।এটি বেশিরভাগ খনি ও লগিং উদ্যোগ, বাণিজ্যিক মাছ ধরার ব্যবসা এবং অনুন্নত এলাকায় মোটরচালিত যানবাহন ব্যবহারের বিরোধিতা করে। অর্থনৈতিক নীতি ইনস্টিটিউট: এই সংস্থা বিশ্বাস করে যে সরকারকে অর্থনৈতিকভাবে দুর্বলদের রক্ষা, সমান সুযোগ নিশ্চিত এবং সমস্ত আমেরিকানদের কল্যাণের জন্য একটি সক্রিয় ভূমিকা পালন করতে হবে।ইলেকট্রনিক প্রাইভেসি ইনফরমেশন সেন্টার: এই সংগঠনটি মার্কিন প্যাট্রিওট আইনের কঠোর সমালোচক এবং আমেরিকান সিভিল লিবার্টিজ ইউনিয়নে যোগদান করেছে।এলা বেকার সেন্টার ফর হিউম্যান রাইটস: বিপ্লবী কমিউনিস্ট ভ্যান জোনসের সহ-প্রতিষ্ঠাতা এই দারিদ্র্য-বিরোধী সংগঠন দাবি করেছে যে, আমাদের শহরগুলোতে দশকের পর দশক ধরে মাত্রাতিরিক্ত, বর্ণবাদী পুলিশিং এবং অতি কারাদণ্ডের কারণে হতাশা এবং গৃহহীনতার সৃষ্টি হয়েছে।এমিলি এস লিস্ট: এই রাজনৈতিক নেটওয়ার্ক গণতান্ত্রিক মহিলা রাজনৈতিক প্রার্থীদের জন্য অর্থ সংগ্রহ করে যারা করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদা. এনার্জি অ্যাকশন কোয়ালিশনে অবাধ প্রবেশাধিকার সমর্থন করে: ২০০৪ সালে প্রতিষ্ঠিত, এই দলটি নিজেকে যুব নেতৃত্বাধীন ৫০ টি পরিবেশগত ও সামাজিক ন্যায়বিচার গোষ্ঠীর জোট হিসাবে বর্ণনা করে যারা যুব পরিষ্কার শক্তি এবং জলবায়ু আন্দোলন গড়ে তোলার জন্য একত্রে কাজ করছে।ইকুয়াল জাস্টিস ইউএসএ: এই দল দাবি করে যে আমেরিকা অপরাধ-বিচার ব্যবস্থা উল্লেখযোগ্য জাতি এবং শ্রেণীগত পক্ষপাতিত্বের দ্বারা ক্ষতিগ্রস্ত এবং এইভাবে বড় সংস্কারের প্রচার চায়।ফেয়ার ইমিগ্রেশন রিফর্ম মুভমেন্ট: এটি সেন্টার ফর কমিউনিটি চেঞ্জের উন্মুক্ত সীমান্ত বাহু। বিশ্বস্ত আমেরিকা: এই সংগঠনটি সম্পদের পুনর্বন্টন প্রচার করে, যুদ্ধবন্দীদের সাথে যুদ্ধের মাধ্যমে জিজ্ঞাসাবাদের প্রক্রিয়া উন্নত করা, বৈশ্বিক উষ্ণায়নের বিরুদ্ধে লড়াই করার জন্য নীতিমালা প্রণয়ন এবং সরকার পরিচালিত তাপ যত্ন ব্যবস্থা তৈরির প্রচার করে। নারীবাদী সংখ্যাগরিষ্ঠতা: মার্কিন যুক্তরাষ্ট্রকে অন্তর্নিহিত যৌনবাদী জাতি হিসাবে চিহ্নিত করা, এই দলটি পুরুষদের সাথে মহিলাদের আইনি, সামাজিক ও রাজনৈতিক সমতার অগ্রগতির বিরোধিতা করে এবং মার্কিন যুক্তরাষ্ট্রে নারীবাদী আন্দোলনের জন্য ভবিষ্যতের নেতৃত্বকে উত্সাহিত করার জন্য তরুণ নারীবাদীদের নিয়োগ এবং প্রশিক্ষণ দেয়।ফোর ফ্রিডম ফান্ড: এই সংগঠনটি একটি কন্ডুইট হিসাবে কাজ করার জন্য ডিজাইন করা হয়েছিল যার মাধ্যমে বড় ফাউন্ডেশনগুলি রাষ্ট্রীয়-ভিত্তিক উন্মুক্ত সীমান্ত সংস্থাগুলিকে আরও স্পষ্ট এবং দ্রুত তহবিল সরবরাহ করতে পারে। ক্যাম্পাসে ফ্রি এক্সচেঞ্জ: এই সংগঠনটি কেবল এক ব্যক্তির প্রচেষ্টার বিরোধিতা করার জন্য তৈরি করা হয়েছিল, ডেভিড হোরোইটজ এবং বিশ্ববিদ্যালয়গুলিকে একটি একাডেমিক বিল অফ রাইটস গ্রহণ করার জন্য তার প্রচারণা, পাশাপাশি হোরোইটজ এস ২০০৬ বই অধ্যাপকদের নিন্দা করার জন্য তৈরি করা হয়েছিল।এফইসি'র সদস্য সংগঠনগুলোর মধ্যে রয়েছে ক্যাম্পাস প্রোগ্রেস (সেন্টার ফর আমেরিকান প্রগ্রেসের একটি প্রকল্প); আমেরিকান এসোসিয়েশন অফ ইউনিভার্সিটি প্রফেসরস; আমেরিকান সিভিল লিবার্টিজ ইউনিয়ন; পিপল ফর আমেরিকান ওয়ে; মার্কিন যুক্তরাষ্ট্রের ছাত্র সংগঠন; সেন্টার ফর ক্যাম্পাস ফ্রি স্পিচ; আমেরিকান লাইব্রেরি অ্যাসোসিয়েশন; ফ্রি প্রেস; এবং ন্যাশনাল অ্যাসোসিয়েশন অফ স্টেট পাবলিক ইন্টারেস্ট রিসার্চ গ্রুপ। ফ্রি প্রেস: এই মিডিয়া সংস্কার সংস্থা আমেরিকার জন্য মিডিয়া ম্যাটারস, এয়ার আমেরিকা রেডিও, গ্লোবাল এক্সচেঞ্জ, কোড পিংক, ফেয়ারনেস এবং প্রতিবেদনের শুদ্ধতা, বিপ্লবী কমিউনিস্ট পার্টি, মাদার জোনস ম্যাগাজিন, এবং প্যাসিফিক রেডিওর মতো উল্লেখযোগ্য বামপন্থীদের সাথে ঘনিষ্ঠভাবে কাজ করেছে।ফান্ডিং এক্সচেঞ্জ: সামাজিক পরিবর্তনের বাহন হিসাবে জনসেবার ধারণার প্রতি নিবেদিত, এই সংগঠনটি বামপন্থী দাতাদের সাথে এবং সমমনা দল ও কর্মীদের সাথে ফাউন্ডেশন যারা তাদের নিজেদের প্রগতিশীল পরিবর্তন এবং সামাজিক ন্যায়বিচারের সংস্করণ আনতে নিবেদিত।এই অনুদানপ্রাপ্তদের অনেকেই অনুমান করেন যে আমেরিকান সমাজ বর্ণবাদ, বৈষম্য, শোষণ এবং অযোগ্যতায় পরিপূর্ণ এবং টেকসই শিক্ষা, সক্রিয়তা এবং সামাজিক আন্দোলনের মাধ্যমে তাদের সংস্কার করা প্রয়োজন। গামালিয়েল ফাউন্ডেশন: ষাটের দশকের প্রগতিবাদী সক্রিয় কর্মী সোল আলিনস্কির কৌশলের মডেল তৈরি করে এই দলটি বর্তমান মাতৃভূমি নিরাপত্তা ব্যবস্থা এবং অভিবাসন বিধিনিষেধের বিরুদ্ধে দৃঢ় অবস্থান নিয়েছে। গিশা: আন্দোলনের স্বাধীনতার আইনী সুরক্ষা কেন্দ্র: এই ইজরায়েল বিরোধী সংগঠন ফিলিস্তিনিদের আন্দোলনের স্বাধীনতার অধিকার অনুশীলনে সহায়তা করার চেষ্টা করছে।গ্লোবাল সেন্টার ফর দ্য রেসপন্সিবিলিটি টু প্রটেক্ট: এই গ্রুপ দাবি করে যে যখন একটি রাষ্ট্র তার সীমানার মধ্যে সংঘটিত গণহত্যা থেকে বেসামরিক নাগরিকদের রক্ষা করতে অক্ষম বা অনিচ্ছুক প্রমাণিত হয়, তখন সম্ভব হলে শান্তিপূর্ণভাবে হস্তক্ষেপ করা আন্তর্জাতিক সম্প্রদায়ের দায়িত্ব, তবে প্রয়োজনে সামরিক বাহিনীর সাথে। গ্লোবাল এক্সচেঞ্জ: ১৯৮৮ সালে ক্যাস্ট্রো-পন্থী র্যাডিকাল মিডিয়া বেঞ্জামিন দ্বারা প্রতিষ্ঠিত, এই দলটি আমেরিকাকে ধারাবাহিকভাবে বিদেশী নীতি, ব্যবসা অনুশীলন এবং গার্হস্থ্য জীবন নিন্দা করে।৯/১১ এর সন্ত্রাসী হামলার পর, গ্লোবাল এক্সচেঞ্জ আমেরিকানদের পরামর্শ দিয়েছে মধ্য প্রাচ্যের তেলের উপর আমাদের নির্ভরতা থেকে ইজরায়েলের প্রতি আমাদের পক্ষপাতিত্বমূলক নীতি পর্যন্ত আরব বিশ্বে যুক্তরাষ্ট্রের বিরুদ্ধে অসন্তোষের মূল কারণ পরীক্ষা করে দেখতে।গ্রান্টমেকারস উইদাউট বর্ডারস: জিডব্লিউবি বামপন্থী পরিবেশ, যুদ্ধ বিরোধী এবং নাগরিক অধিকার গোষ্ঠীর খুব সমর্থন করে।এটি সাধারণত পুঁজিবাদের বিরোধী, যা প্রধান রাজনৈতিক, অর্থনৈতিক এবং সামাজিক ব্যবস্থাগুলির মধ্যে একটি বলে মনে করা হয় যা একটি বড় সামাজিক ব্যাধির জন্ম দেয়।গ্রীন ফর অল: ফেডারেল জলবায়ু, শক্তি এবং অর্থনৈতিক নীতি উদ্যোগের জন্য লবি করার জন্য ভ্যান জোন্স এই গ্রুপ তৈরি করেছিলেন।হেলথ কেয়ার ফর আমেরিকা নাউ: এই গ্রুপ একটি একক পেয়ার মডেল সমর্থন করে যেখানে ফেডারেল সরকার সমগ্র মার্কিন স্বাস্থ্য ব্যবস্থা অর্থায়ন এবং পরিচালনার দায়িত্বে থাকবে।হিউম্যান রাইটস ক্যাম্পেইন: যুক্তরাষ্ট্রের বৃহত্তম সমকামী-সমকামী-ট্রান্সজেন্ডার লবিং গ্রুপ, এইচআরসি রাজনৈতিক প্রার্থী এবং আইন সমর্থন করে যা এলজিবিটি এজেন্ডাকে এগিয়ে নিয়ে যাবে।ঐতিহাসিকভাবে, এইচআরসি সর্বাধিক জোরালোভাবে এইচআইভি / এইডস সম্পর্কিত আইন, ঘৃণা অপরাধ আইন, সামরিক এস ডন টি এসকের বিলোপ, ডন টি টেল নীতি এবং সমকামী বিবাহের বৈধতাকে সমর্থন করেছে। মানবাধিকার প্রথম: এই দলটি উন্মুক্ত সীমানা এবং অবৈধ এলিয়েনদের অধিকার সমর্থন করে; অভিযোগ যে প্যাট্রিয়ট আইন মার্কিন নাগরিক স্বাধীনতা গুরুতরভাবে হ্রাস করে; সন্ত্রাসের সন্দেহভাজন জোসে প্যাডিলার পক্ষে অ্যামিকাস কিউরিয়া সংক্ষিপ্ত দায়ের করেছে; এবং গুয়ান্তানামো বে আটক সুবিধাগুলির সমালোচনা করে। হিউম্যান রাইটস ওয়াচ: এই দলটি মার্কিন যুক্তরাষ্ট্র এবং ইজরায়েলে তার সমালোচনার একটি অসমঞ্জস্য ভাগ নির্দেশ করে।এটি সকল ক্ষেত্রে মৃত্যুদণ্ডের বিরোধিতা করে এবং অবৈধ এলিয়েনদের জন্য উন্মুক্ত সীমান্ত এবং ক্ষমা সমর্থন করে।আমি লাম: ইজরায়েল বিরোধী এই এনজিও আরব মিডিয়ার উন্নয়ন আর ক্ষমতায়নের চেষ্টা করছে আর ফিলিস্তিনি বিষয় নিয়ে কথা বলছে।অভিবাসী প্রতিরক্ষা প্রকল্প: অবৈধ অভিবাসীদের কারণকে এগিয়ে নিয়ে যাওয়ার জন্য, আইডিপি অভিবাসন আইন ব্যাকআপ সমর্থন এবং নিউ ইয়র্ক প্রতিরক্ষা অ্যাটর্নি এবং অন্যান্য যারা অপরাধমূলক ন্যায়বিচার এবং অভিবাসন ব্যবস্থায় অভিবাসীদের প্রতিনিধিত্ব বা সহায়তা করে, পাশাপাশি অভিবাসীদেরও সহায়তা করে। অভিবাসী আইনী সম্পদ কেন্দ্র: এই দলটি মার্কিন যুক্তরাষ্ট্রে প্রায় ত্রিশ লক্ষ অবৈধ বিদেশীর জন্য ক্ষমা পেতে সহায়তা করেছে বলে দাবি করে, এবং ১৯৮০-এর দশকে অভয়ারণ্য আন্দোলনের অংশ ছিল যা মধ্য আমেরিকার ব্যর্থ কমিউনিস্ট রাজ্যগুলি থেকে শরণার্থীদের আশ্রয় দিতে চেয়েছিল। অভিবাসী শ্রমিক নাগরিকত্ব প্রকল্প: এই উন্মুক্ত-সীমানা সংস্থা মার্কিন ইমিগ্রেশন নেটওয়ার্ককে গণ অভিবাসনের পক্ষে সমর্থন করে: নিম্ন-আয়ের সংস্থাগুলির ন্যায়বিচার বৃদ্ধি এবং অভিবাসীদের অধিকার আদায়ের জন্য সহায়তা করার এই জোটটি তাদেরকে জোরদার করতে চায়।অভিবাসন নীতি কেন্দ্র: আইপিসি উন্মুক্ত সীমান্তের এক প্রবক্তা এবং তারা দাবী করছে যে আমেরিকায় অবৈধ অভিবাসীর বিশাল পরিমাণ প্রবেশ ঘটেছে যুক্তরাষ্ট্রের সরকারের নীতির কারণে, বিশেষ করে যখন ভেঙ্গে পড়া অভিবাসন ব্যবস্থা [ ] অবৈধ অভিবাসনকে প্রথম স্থানে নিয়ে যায়।স্বাধীন মিডিয়া সেন্টার: এই ইন্টারনেট ভিত্তিক, সংবাদ এবং ইভেন্ট বুলেটিন বোর্ড অনিবার্যভাবে বামপন্থী, পুঁজিবাদ বিরোধী দৃষ্টিভঙ্গি উপস্থাপন করে এবং বিশ্বায়ন-বিরোধী / আমেরিকা বিরোধী থিমগুলির জন্য একটি মুখপাত্র হিসাবে কাজ করে। স্বাধীন মিডিয়া ইনস্টিটিউট: আইএমআই এসপিএন প্রকল্প (কৌশলগত প্রেস ইনফরমেশন নেটওয়ার্ক) পরিচালনা করে, যা তাদের সামাজিক ন্যায়বিচার লক্ষ্য অর্জনে সহায়তা করার জন্য অ্যাক্সেসযোগ্য এবং সাশ্রয়ী কৌশলগত যোগাযোগ, প্রশিক্ষণ, নেটওয়ার্কিং সুযোগ এবং কংক্রিট সরঞ্জামগুলি সহ বামপন্থী সংগঠনগুলিকে সরবরাহ করে।ইনস্টিটিউট ফর আমেরিকাস ফিউচার: আইএএফ সামাজিক ঔষধ সমর্থন করে, শিক্ষার জন্য সরকারী তহবিল বৃদ্ধি করে এবং প্রগতিশীল সংখ্যাগরিষ্ঠের কণ্ঠস্বর যাতে শোনা যায় তা নিশ্চিত করার জন্য একটি অবকাঠামো তৈরি করে।ইনস্টিটিউট ফর নিউ ইকোনমিক থিঙ্কিং: একটি নতুন বিশ্বব্যাপী অর্থনৈতিক দৃষ্টান্ত তৈরি করার চেষ্টা করছে, এই সংস্থাটি অসংখ্য ব্যক্তি দ্বারা পরিচালিত যারা জাতীয় অর্থনীতিতে সরকারী হস্তক্ষেপকে সমর্থন করে এবং যারা পুঁজিবাদকে একটি ত্রুটিযুক্ত সিস্টেম হিসাবে দেখে। পলিসি স্টাডিজ ইনস্টিটিউট: এই চিন্তাবিদটি দীর্ঘকাল ধরে বিশ্বব্যাপী কমিউনিস্ট এবং আমেরিকান বিরোধী কারণগুলিকে সমর্থন করে আসছে।অনিয়ন্ত্রিত লোভের জন্য পুঁজিবাদকে একটি প্রজনন ক্ষেত্র হিসাবে দেখে, আইপিএস অনিয়ন্ত্রিত বাজার এবং ব্যক্তিস্বাতন্ত্র্যকে সংশোধন করতে চায়।জাতিসংঘের ধার্মিকতায় একটি প্রশ্নাতীত বিশ্বাসের কথা স্বীকার করে, এটি জাতিসংঘের নিয়ন্ত্রণে আমেরিকান বৈদেশিক নীতি নিয়ে আসার লক্ষ্যে কাজ করে। পাবলিক এককিউরেসি ইনস্টিটিউট: এই আমেরিকান-বিরোধী, পুঁজিবাদী-বিরোধী, ইজরায়েল-বিরোধী সংস্থা স্পনসর্ড অভিনেতা শন পেন এস ২০০২ সালে বাগদাদ সফর উদযাপন করেছিলেন।এটি ডেমোক্রেটিক কংগ্রেসম্যান নিক রাহাল এবং সাবেক ডেমোক্রেট সিনেটর জেমস আবুরেজক ইনস্টিটিউট ফর উইমেনস পলিসি রিসার্চ দ্বারা ইরাকে সফর স্পনসর করেছিল: এই গ্রুপ মার্কিন যুক্তরাষ্ট্রকে নারীর প্রতি বৈষম্যের সাথে একটি জাতি হিসেবে দেখে এবং এই কথিত অবস্থার দিকে দৃষ্টি আকর্ষণ করার জন্য গবেষণা প্রকাশ করে।এ ছাড়া, এটি করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদার অবাধ প্রবেশাধিকারকে সমর্থন করে, এই বলে যে নারী ও মেয়েদের অর্থনৈতিক মঙ্গলের জন্য গর্ভপাতে প্রবেশাধিকার অপরিহার্য।আন্তর্জাতিক ক্রাইসিস গ্রুপ: এই সংস্থার নেতৃস্থানীয় ব্যক্তিত্বদের মধ্যে একজন হলেন মিডইস্ট ডিরেক্টর রবার্ট ম্যালি, যিনি আরব-ইসরায়েল বিষয়ক বিশেষ সহকারী প্রেসিডেন্ট বিল ক্লিনটন ছিলেন।মিডইস্ট সংঘাত নিয়ে তার বিশ্লেষণ ফিলিস্তিনিপন্থী। জে স্ট্রিট: এই ইজরায়েল বিরোধী দল সাবধান করে দেয় যে হামাসের সন্ত্রাসী হামলা বন্ধের জন্য সামরিক পদক্ষেপ নেয়া ইজরায়েলের উচিত পাল্টা ফলপ্রসু হবে আর কেবলমাত্র এই অঞ্চলের ইহুদি ফান্ড ফর জাস্টিসের সংঘাত চক্রকে গভীর করবে: এই সংস্থা সরকারের হস্তক্ষেপ আর করদাতাদের অর্থায়নকে আলোকিত সামাজিক নীতির গুরুত্বপূর্ণ অংশ হিসাবে দেখে।এটি গার্হস্থ্য অর্থনৈতিক ও সামাজিক অবিচারের মূল কারণগুলির বিরুদ্ধে লড়াই করার জন্য যিহূদী দাতাদের কাছ থেকে স্বল্প-আয়ের সম্প্রদায়গুলিতে সম্পদ পুনর্বন্টনের চেষ্টা করে।জেএফজে এস হিসাব অনুযায়ী, মূল কারণগুলির মধ্যে প্রধান হল পুঁজিবাদের অন্তর্নিহিত নেতিবাচক উপজাতগুলি, বিশেষত বর্ণবাদ এবং চরম অর্থনৈতিক বৈষম্য।যৌথ বিজয় অভিযান ২০০৪: জর্জ সোরোস এবং হ্যারল্ড ইকস দ্বারা প্রতিষ্ঠিত, ২০০৪ সালের নির্বাচন চক্রের সময় এই দলটি ডেমোক্রেটদের জন্য একটি প্রধান তহবিল সংগ্রহের সংস্থা ছিল।এই দলটি ডেমক্রেটিক্সের পক্ষে কাজ করে। স্টেকে ন্যায়বিচার: এই জোটটি বিচারকদের নির্দলীয়, মেধা নির্বাচন নামে পরিচিত একটি প্রক্রিয়ায় নিযুক্ত করার আহ্বান জানায়, ভোটদানকারী জনগণের দ্বারা নির্বাচিত না হয়ে। ল্যাটিনো জাস্টিস পিআরএলডিএফ: এই সংস্থাটি দ্বিভাষিক শিক্ষাকে সমর্থন করে, ভোটিং জেলার জাতিগত যাযাবরকরণকে সমর্থন করে এবং অবৈধ এলিয়েনদের জন্য অধিকার প্রসারিত করে। আইনের অধীনে নাগরিক অধিকারের জন্য আইনজীবী কমিটি: এই দলটি আমেরিকাকে একটি অঘোষিত বর্ণবাদী জাতি হিসাবে দেখে; আদালত এই আইনের মাধ্যমে ইতিবাচক জাতি-ভিত্তিক ব্যবসায়ের সীমাবদ্ধতাকে সমর্থন করে।লিন স্টুয়ার্ট ডিফেন্স কমিটি: আইআরএস রেকর্ড নির্দেশ করে যে সোরোস এস ওপেন সোসাইটি ইনস্টিটিউট ২০০২ সালের সেপ্টেম্বর মাসে এই সংস্থাকে ২০,০০০ মার্কিন ডলার অনুদান প্রদান করে।স্টুয়ার্ট ছিলেন অপরাধী-প্রতিরক্ষা অ্যাটর্নি যিনি পরে তার মক্কেল অন্ধ শেখ ওমর আব্দেল রহমানকে তার ইসলামী গ্রুপের সাথে সম্পর্কিত সন্ত্রাসী কর্মকাণ্ডে সহায়তা করার জন্য দোষী সাব্যস্ত হন। ম্যাকসোম ওয়াচ: এই সংস্থাটি নিজেকে ইসরায়েলি নারীদের একটি আন্দোলন, ইসরায়েলি সমাজের সমস্ত ক্ষেত্রের শান্তি কর্মী, যারা ইসরায়েলি দখলদারিত্বের বিরোধিতা করে এবং তাদের দেশে অবাধে চলাচল করার ফিলিস্তিনি অধিকার অস্বীকার করে।মাদ্রেঃ এই আন্তর্জাতিক নারী সংগঠন আমেরিকাকে মানবাধিকার লংঘনকারী হিসেবে গণ্য করে।যেমন, এটি বিশ্বজুড়ে সহিংসতা, দারিদ্র্য এবং নিপীড়নের মুখোমুখি হওয়া নারী এবং পরিবারগুলির উপর মার্কিন নীতির বাস্তব জীবনের প্রভাব এবং মার্কিন নীতিগুলির বিকল্প দাবি করার জন্য যোগাযোগ [স্প্যানিশ] করার চেষ্টা করে।এছাড়াও এটি করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদার অবাধ প্রবেশাধিকারকে সমর্থন করে। ম্যালকম এক্স গ্রাসরুটস মুভমেন্ট: এই দলটি মার্কিন যুক্তরাষ্ট্রকে বর্ণবাদ এবং কালোদের বিরুদ্ধে বৈষম্যের সাথে পরিপূর্ণ একটি জাতি হিসাবে দেখে; দক্ষিণ-পূর্ব যুক্তরাষ্ট্রে একটি স্বাধীন কালো জাতি প্রতিষ্ঠা করতে চায়; এবং দাসত্বের জন্য ক্ষতিপূরণ দাবি করে। ম্যাসাচুসেটস অভিবাসী এবং শরণার্থী অ্যাডভোকেসি কোয়ালিশন: এই দলটি অবৈধ এলিয়েনদের জন্য নাগরিক অধিকার এবং স্বাধীনতা সম্প্রসারণের আহ্বান জানায়; শোক প্রকাশ করে যে আমেরিকাতে অবৈধ এলিয়েনরা সাধারণত শোষণের শিকার হয়; কলেজে পড়াশোনার জন্য পদ্ধতিগত-সহায়তা প্রোগ্রামকে সমর্থন করে; এবং প্যাট্রিয়টস এই আইনটিকে একটি অত্যন্ত রক্ষণশীল রাজনৈতিক গণমাধ্যম তহবিল হিসাবে চিহ্নিত করে, যার মুদ্রিত স্বাধীনতার জন্য খুব অসুবিধা সৃষ্টি করে।দলটি সোরোস-সমর্থিত সেন্টার ফর আমেরিকান প্রোগ্রেসের সাথে ঘনিষ্ঠভাবে কাজ করে এবং গণতন্ত্র জোট দ্বারা ব্যাপকভাবে অর্থায়ন করা হয়, যার মধ্যে সোরোস একজন প্রধান অর্থ যোগানদাতা। মার্সি কর্পস: আরব-ইসরায়েলি সংঘাতের মুখোমুখি হয়ে, মার্সি কর্পস ফিলিস্তিনি দারিদ্র্য এবং সরাসরি ইসরাইলের উপর দুর্ভোগের জন্য দায়ী। মেক্সিকান আমেরিকান লিগ্যাল ডিফেন্স অ্যান্ড এডুকেশন ফান্ড: এই দলটি উন্মুক্ত সীমানা, অবৈধ এলিয়েনদের জন্য কলেজে পড়ার অনুমতি দেয়, হিস্পানিকদের থাকার জন্য শিক্ষাগত মান হ্রাস করে এবং অপরাধীদের পক্ষে ভোট দেওয়ার অধিকার রাখে।মালডেফ এর মতে, ইংরেজীকে আমেরিকার সরকারী ভাষা করার সমর্থকরা বর্ণবাদ আর অভিবাসী বিরোধী মনোভাবের দ্বারা অনুপ্রাণিত, আর নিয়োগকর্তাদের বিরুদ্ধে নিষেধাজ্ঞা যারা অবৈধ শ্রমের উপরে নির্ভরশীল তারা বাদামী চামড়ার মানুষের বিরুদ্ধে বৈষম্যমূলক আচরণ করতে চায়।মেয়ার, সুজ্জি, ইংরেজ এবং ক্লেইন, পিসি: বিগ লেবারের এই প্রভাবশালী সমর্থকের নেতৃত্বে আছেন ডেমোক্রেটের সক্রিয় কর্মী হ্যারল্ড আইকস।মিডওয়েস্ট একাডেমী: এই সত্তা সরাসরি কাজ, লক্ষ্য, সংঘর্ষ এবং ভীতি প্রদর্শনের কৌশলগুলিতে মৌলবাদী কর্মীদের প্রশিক্ষণ দেয়। মাইগ্রেশন পলিসি ইনস্টিটিউট: এই দলটি মাঝারি পর্যায়ে স্থায়ী অভিবাসনের সাথে ধীরে অদৃশ্য সীমান্ত নিয়ন্ত্রণের সাথে উত্তর আমেরিকা তৈরি করতে চায়।সামরিক পরিবার কথা বলছে: এই দলটি যুক্তরাষ্ট্রের ইরাক আক্রমণকে আমেরিকান সাম্রাজ্যবাদ এবং তেলের লালসার সাথে তুলনা করেছে। মিসৌরিয়ানরা সংস্কার ও ক্ষমতায়নের জন্য সংগঠিত: এই দলটি এখন বিলুপ্ত, প্রো-সোশালিস্ট, কমিউনিটি সংস্থা একরন.মুভঅন.অর্গ এর পুনরায় ব্র্যান্ডেড মিসৌরি শাখা: এই ওয়েব-ভিত্তিক সংগঠন গণতান্ত্রিক রাজনৈতিক প্রার্থীদের তহবিল সংগ্রহ, বিজ্ঞাপন, এবং ভোট প্রদানের উদ্যোগের মাধ্যমে সমর্থন করে।ফাউন্ডেশন ফর উইমেন: এই দলটি মার্কিন সমাজের বিস্তৃত এবং স্থায়ী ত্রুটি: বর্ণবাদ, লিঙ্গ বৈষম্য, হোমোফোবিয়া এবং নাগরিক অধিকার ও স্বাধীনতা লংঘনের বিষয়ে এটি যা মনে করে তা নিয়ে দুঃখ প্রকাশ করেছে।এটি নারীদের জন্য ইতিবাচক পদক্ষেপ, করদাতাদের দ্বারা পরিচালিত গর্ভপাত-অন-চাহিদার অবাধ অ্যাক্সেস, অবৈধ এলিয়েনদের জন্য সাধারণ ক্ষমা এবং বড় সরকারগুলির উপর দৃষ্টি নিবদ্ধ করে। নারাল প্রো-চোইস আমেরিকা: এই দলটি করদাতা-অর্থায়িত গর্ভপাত-অন-দাবি সমর্থন করে এবং গর্ভপাত-বিরোধী ডেমোক্র্যাটদের নির্বাচিত করার জন্য কাজ করে। এনএএসিপি আইনী প্রতিরক্ষা এবং শিক্ষা তহবিল: এনএএসিপি কর্মসংস্থান এবং শিক্ষার জাতিগত পছন্দ এবং ভোটিং জেলার জাতিগত জিমন্যান্ডারিং সমর্থন করে।বর্ণ পছন্দগুলির জন্য তার সমর্থন জোর দিয়ে বিশ্বাস করা হয় যে মার্কিন যুক্তরাষ্ট্রে সাদা বর্ণবাদ একটি অপরিবর্তনীয়, মূলত অনিশ্চিত, ঘটনা। দ্য নেশন ইনস্টিটিউট: এই অলাভজনক সত্তা প্রগতিবাদী কর্মীদের জন্য বামপন্থী সম্মেলন, ফেলোশিপ, পুরষ্কার এবং সাংবাদিকতা ইন্টার্নশিপ স্পনসর করে। জাতীয় গর্ভপাত ফেডারেশন: এই গ্রুপ রাষ্ট্র বা ফেডারেল পর্যায়ে গর্ভপাতের উপর যে কোনও বিধিনিষেধের বিরোধিতা করে এবং বিশ্বের উন্নয়নশীল অঞ্চলে অবাধ গর্ভপাত প্রবর্তনের চ্যাম্পিয়ন। মৃত্যুদন্ড বাতিল করতে জাতীয় জোট: এই দলটি ১৯৭৬ সালে প্রতিষ্ঠিত হয়েছিল প্রথম সম্পূর্ণরূপে কর্মী জাতীয় সংস্থা হিসাবে একচেটিয়াভাবে মৃত্যুদন্ড বিলুপ্ত করার জন্য নিবেদিত।ন্যাশনাল কমিটি ফর রেসপন্সিভ ফিল্যানথ্রপি: এই দলটি মার্কিন যুক্তরাষ্ট্রকে এমন একটি জাতি হিসাবে বর্ণনা করে যা জনহিতৈষী সংস্থার অর্থায়নে নাটকীয় কাঠামোগত পরিবর্তনের প্রয়োজন।এটি ব্যাপকভাবে অনুদান প্রদানকারী এবং অনুদানপ্রাপ্তদের বামপন্থী এজেন্ডার সাথে প্রচার করে, তাদের রক্ষণশীল সহযোগীদের সমালোচনা করে। ভোটিং ইন্টিগ্রিটির জন্য জাতীয় কমিটি: এই দলটি নির্বাচনের অখণ্ডতা নিশ্চিত করার উপায় হিসাবে আমেরিকার নির্বাচনে যোগ্য ভোটারদের নাগরিকত্ব প্রমাণ এবং ছবি সনাক্তকরণ প্রয়োজনীয়তা প্রয়োগের বিরোধিতা করে।ন্যাশনাল কাউন্সিল ফর রিসার্চ অন ওমেন: এই গ্রুপ বড় সরকার, উচ্চ কর, সামরিক ব্যয় হ্রাস, সামাজিক কল্যাণ ব্যয় বৃদ্ধি, এবং করদাতাদের গর্ভপাত-অন-চাহিদার অনিয়ন্ত্রিত অধিকার সমর্থন করে। লা রাজা জাতীয় পরিষদ: এই গ্রুপ জাতিগত পছন্দ, দ্বিভাষিক শিক্ষা, কঠোর ঘৃণা-অপরাধ আইন, গণ অভিবাসন এবং অবৈধ এলিয়েনদের জন্য ক্ষমা দাবি করে। ন্যাশনাল কাউন্সিল অফ ওমেন এস অর্গানাইজেশনস: এই গ্রুপ মার্কিন যুক্তরাষ্ট্রকে নারী ও মহিলাদের বিরুদ্ধে অবিচারের সাথে একটি জাতি হিসাবে দেখে।এটি সামাজিক কল্যাণ কর্মসূচির জন্য উচ্চ স্তরের ব্যয় সমর্থন করে এবং সংখ্যালঘু এবং ব্যবসায় ও একাডেমিয়ায় নারীদের জন্য জাতি ও লিঙ্গ পছন্দ সমর্থন করে। জাতীয় অভিবাসন ফোরাম: বর্তমান অভিবাসন আইনগুলির প্রয়োগের বিরোধিতা করে, এই সংস্থাটি মার্কিন সরকারকে বর্তমানে মার্কিন যুক্তরাষ্ট্রে যে সমস্ত অবৈধ এলিয়েনদের কোন অপরাধমূলক রেকর্ড নেই তাদের আইনীকরণের জন্য এবং মার্কিন যুক্তরাষ্ট্রে অভিবাসন করতে ইচ্ছুকদের জন্য ভিসার সংখ্যা নাটকীয়ভাবে বৃদ্ধি করার আহ্বান জানিয়েছে।ফোরামটি বিশেষত অদক্ষ, নিম্ন-আয়ের শ্রমিকদের জন্য সীমান্ত উন্মুক্ত করতে প্রতিশ্রুতিবদ্ধ এবং তাদেরকে কল্যাণ ও সামাজিক পরিষেবা কার্যক্রমের জন্য উপযুক্ত করে তুলতে প্রতিশ্রুতিবদ্ধ। জাতীয় অভিবাসন আইন কেন্দ্র: এই দলটি অবৈধ এলিয়েনদের জন্য সরকার-তহবিলকৃত সামাজিক কল্যাণ কর্মসূচিতে অবাধ প্রবেশাধিকার পেতে চায়। জাতীয় আইনজীবী গিল্ড: এই দলটি উন্মুক্ত সীমানা প্রচার করে; আমেরিকা গোয়েন্দা-সংগ্রহকারী সংস্থাগুলিকে দুর্বল করার চেষ্টা করে; নাগরিক স্বাধীনতার উপর আক্রমণ হিসাবে প্যাট্রিয়ট অ্যাক্টকে নিন্দা করে; পুঁজিবাদকে একটি অহিংস অর্থনৈতিক ব্যবস্থা হিসাবে প্রত্যাখ্যান করে; দোষী সন্ত্রাসী এবং তাদের সহায়তাকারীদের প্রতিরক্ষা করতে ছুটে এসেছে; এবং সাধারণত মার্কিন যুক্তরাষ্ট্রের সমস্ত বিদেশী নীতির অবস্থানের বিরোধিতা করে, ঠিক যেমন এটি সোভিয়েত-জাতীয় লিঙ্গ বৈষম্য ওমেন সম্প্রদায়কে সমর্থন করার সময় করেছিল।এটি গর্ভাবস্থার যে কোনও পর্যায়ে এবং যে কোনও কারণে করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদা ভোগ করার জন্য নারীদের সর্বজনীন অধিকারের পক্ষেও পরামর্শ দেয়। জাতীয় অগ্রাধিকার প্রকল্প: এই গোষ্ঠী উচ্চতর কর এবং সামাজিক কল্যাণ কর্মসূচিতে বৃহত্তর ব্যয়ের মাধ্যমে সরকার-নিয়ন্ত্রিত সম্পদের পুনর্বণ্টন সমর্থন করে।এনপিপি সরকারকে জনশিক্ষা, সার্বজনীন স্বাস্থ্য বীমা, পরিবেশবাদী প্রকল্প এবং কল্যাণ কর্মসূচিতে তার সামরিক তহবিলের একটি উল্লেখযোগ্য অংশ পুনঃনির্দেশিত করার পরামর্শ দেয়। ন্যাশনাল পাবলিক রেডিও: ১৯৭০ সালে ৯০ টি পাবলিক রেডিও স্টেশনকে চার্টার সদস্য হিসাবে প্রতিষ্ঠিত করে, এনপিআর বর্তমানে সারা দেশে ৭৫০ টিরও বেশি মার্কিন রেডিও স্টেশনগুলির একটি শিথিল নেটওয়ার্ক, যার অনেকগুলি কলেজ এবং বিশ্ববিদ্যালয় ক্যাম্পাসের উপর ভিত্তি করে গঠিত।(উৎস)জাতীয় নিরাপত্তা আর্কাইভ তহবিল: এই দলটি আমেরিকান জাতীয় নিরাপত্তা এবং গোয়েন্দা এজেন্টদের সুরক্ষাকে আপস করে এমন একটি ডিগ্রিতে তথ্য স্বাধীনতা আইনের মাধ্যমে প্রাপ্ত ডিক্লায়েড নথি সংগ্রহ এবং প্রকাশ করে। জাতীয় মহিলা আইন কেন্দ্র: এই দলটি করদাতা-অর্থায়িত গর্ভপাত-অন-চাহিদা সমর্থন করে; রক্ষণশীল বিচার বিভাগীয় নিয়োগীদের বিরুদ্ধে লবিং; নিম্ন-আয়ের মায়েদের সহায়তা করার জন্য কল্যাণ ব্যয় বৃদ্ধি করে; এবং সরকারী কর্মসূচী যেমন মেডিকেড, খাদ্য স্ট্যাম্প, কল্যাণ, যত্ন যত্ন, স্বাস্থ্যসেবা, শিশু-সহায়তা প্রয়োগ এবং ছাত্র ঋণগুলির জন্য আরও তহবিল তৈরির উদ্দেশ্যে উচ্চতর কর প্রদান করে। নেচারাল রিসোর্সেস ডিফেন্স কাউন্সিল: মার্কিন যুক্তরাষ্ট্রের অন্যতম প্রভাবশালী পরিবেশগত লবিটিং গ্রুপ, জনগণের একটি পরিষদের সদস্য দাবি করে।নিউ আমেরিকা ফাউন্ডেশন: এই সংস্থা স্বাস্থ্য, পরিবেশবাদ, শক্তি নীতি, মিডইস্ট দ্বন্দ্ব, বিশ্বব্যাপী শাসন এবং আরও অনেক বিষয়ে জনমতকে প্রভাবিত করার জন্য নীতি কাগজপত্র, মিডিয়া নিবন্ধ, বই এবং শিক্ষামূলক ঘটনাগুলি ব্যবহার করে। নিউ ইজরায়েল তহবিল: এই সংস্থা এনজিওগুলিকে সহায়তা দেয় যা নিয়মিত মানবাধিকার লঙ্ঘন এবং ধর্মীয় নির্যাতনের অভিযোগ ইস্রায়েলকে অভিযুক্ত করে এমন প্রতিবেদন তৈরি করে। নিউজকর্পওয়াচ: আমেরিকার জন্য মিডিয়া ম্যাটারস প্রকল্পের একটি প্রকল্প, নিউজকর্পওয়াচ মিডিয়া ম্যাটারসকে ১ মিলিয়ন মার্কিন ডলার অনুদানের সহায়তায় প্রতিষ্ঠিত হয়েছিল। প্যাসিফিকা ফাউন্ডেশন: এই সত্তাটি প্যাসিফিক রেডিও পরিচালনা করে এবং তার জন্ম থেকে সমাজতান্ত্রিক-মার্কসবাদী বাগাড়ম্বরের ভিত্তিতে ধুয়ে দেয় এবং ৬০-যুদ্ধবিরোধী পুঁজিবাদ এবং আরও বামপন্থী সমিতিকে দেয়। এই সংস্থাটি মিডিয়া ম্যাটার্সের চেয়ে ৬০-শান্তি তহবিল দেয়।শান্তি উন্নয়ন তহবিল: পিডিএফ এস ক্যালকুলাসে মার্কিন যুক্তরাষ্ট্রের সামাজিক ও অর্থনৈতিক প্রতিষ্ঠানগুলোর ব্যাপক পরিবর্তন প্রয়োজন।সম্প্রতি পিডিএফ ব্যাখ্যা করছে, আমরা নব্য-উদারনীতিবাদ এবং পুঁজিবাদের বিশ্বায়নের নেতিবাচক প্রভাব, মার্কিন যুক্তরাষ্ট্রের শিল্পায়ন হ্রাস এবং ধনী ও দরিদ্র জনগণের মধ্যে মার্কিন পথের ক্রমবর্ধমান ব্যবধান প্রত্যক্ষ করেছি: এই দলটি প্যাট্রিয়ট অ্যাক্টের বিরোধিতা করে, সাধারণত সন্ত্রাস বিরোধী পদক্ষেপ এবং ধর্মীয় অধিকারের কথিত ক্রমবর্ধমান প্রভাবের বিরোধিতা করে।জনগণকে সংগঠিত করার মাধ্যমে সম্প্রদায় উন্নত করা: এই দলটি মানবাধিকার লঙ্ঘনের নিন্দা জানানোর জন্য আলিনস্কি-শৈলীর সাংগঠনিক কৌশলগুলি ব্যবহার করে। মানবাধিকারের জন্য চিকিৎসক: এই দলটি মানবাধিকার লঙ্ঘনের জন্য মার্কিন যুক্তরাষ্ট্র এবং ইসরাইলের সমালোচনায় বাছাই এবং ভারসাম্যহীনভাবে সমালোচনা করে। সামাজিক দায়বদ্ধতার জন্য চিকিৎসক: এটি একটি মার্কিন-সামরিক সংস্থা যা মৌলিক পরিবেশগত নীতিগুলিকেও আলিঙ্গন করে। পরিকল্পিত প্যারেন্টহুড: এই দলটি মার্কিন যুক্তরাষ্ট্রের বৃহত্তম গর্ভপাত সরবরাহকারী এবং করদাতা-অন-ডেমান্ডের সমর্থক। প্লাগশেয়ার তহবিল: এই পাবলিক অনুদান পিসি ফাউন্ডেশন আমেরিকাকে একটি অত্যন্ত সমালোচনামূলক অর্থনৈতিক উদ্যোগের বিরোধিতা করে, যা নিউ ইয়র্কের একটি নতুন জলবায়ু প্রকল্প তৈরিতে সহায়তা করে।সংগঠনটির প্রধান উপদেষ্টা বিপ্লবী কমিউনিস্ট ভ্যান জোন্স। প্রিজন মোরাটোরিয়াম প্রকল্প: এই উদ্যোগটি ১৯৯৫ সালে মার্কিন যুক্তরাষ্ট্রের সমস্ত কারাগার নির্মূল এবং সমস্ত বন্দীদের মুক্তির জন্য কাজ করার জন্য তৈরি করা হয়েছিল।বন্দীদশা কখনোই অপরাধ মোকাবেলা করার উপযুক্ত উপায় নয় এমন প্রতিজ্ঞা থেকে যুক্তি দিয়ে বলা হয়েছে, আমেরিকান সমাজ সহজাতভাবে সমস্ত অপরাধমূলক আচরণের মূল অযোগ্য বলে মনে করে। প্রগতিশীল পরিবর্তন প্রচারাভিযান কমিটি: এই সংস্থাটি সাহসী প্রগতিশীল প্রার্থীদের ফেডারেল অফিসে নির্বাচন করে এবং [তাদের] অর্থ সঞ্চয়, শ্রমকে আরও স্মার্ট করে এবং আরও বেশি করে জিততে সহায়তা করে।প্রগতিশীল রাজ্য নেটওয়ার্ক: পিএসএন মিশনটি ফরওয়ার্ড-চিন্তাশীল রাজ্য বিধানকারীদের সমন্বিত গবেষণা এবং কৌশলগত এডভোকেসি সরঞ্জাম সরবরাহ করে সমস্ত পঞ্চাশটি রাজ্যে প্রগতিশীল আইন পাস করা।প্রকল্প ভোট: এটি সোরোস-তহবিলকৃত একরনের ভোটার-মোবাইলাইজেশন বাহু।বছরের পর বছর ধরে একর্ন/প্রকল্প ভোট কার্যক্রম অনুসরণ করে আসছে।প্রো পাবলিকা: তদন্তমূলক সাংবাদিকতা ঝুঁকির মধ্যে রয়েছে দাবি করে, এই দলটি সরকার, ব্যবসা এবং অন্যান্য প্রতিষ্ঠানের ক্ষমতার অপব্যবহার এবং বিশ্বাসঘাতকতার কথা প্রকাশ করে [স্প্যানিশ ভাষায়] সংবাদ প্রকাশে এই লাক্ষানাটির প্রতিকার করার লক্ষ্যে অনুসন্ধানমূলক সাংবাদিকতার নৈতিক শক্তি ব্যবহার করে, যা অপরাধের স্থায়ী কেন্দ্রবিন্দুর মাধ্যমে সংস্কারের পক্ষে।প্রোটিয়াস ফান্ড: এই ফাউন্ডেশন বেশ কয়েকটি মৌলিক বামপন্থী সংস্থার প্রতি তার জনসেবা পরিচালনা করে। পাবলিক সিটিজেন ফাউন্ডেশন: পাবলিক সিটিজেন সিটিজেন কর্পোরেশনগুলির বিরুদ্ধে সরকারী হস্তক্ষেপ এবং মামলা মোকদ্দমা বৃদ্ধি করতে চায় এমন একটি অনুশীলনের উপর ভিত্তি করে যে আমেরিকান কর্পোরেশনগুলি, পুঁজিবাদী ব্যবস্থার মতো তারা অংশ, তারা সহজাতভাবে দুর্নীতির দিকে ঝুঁকে থাকে। পাবলিক জাস্টিস সেন্টার: আমেরিকাকে অবিচার ও বৈষম্যের সাথে একটি জাতি হিসাবে দেখে, এই সংস্থাটি আইন ও নীতি ওকালতিতে হস্তক্ষেপ করে অবহেলিতদের জন্য পদ্ধতিগত পরিবর্তন প্রচার করতে।রিবিল্ড অ্যান্ড রিনিউ আমেরিকা নাউ (এ.কে.এ.ইউনিটি ০৯): মুভঅন.অর্গ এর নেতৃত্বে আর দীর্ঘদিনের কর্মী হিথার বুথের তত্ত্বাবধানে, এই জোট গঠিত হয়েছিল প্রেসিডেন্ট ওবামাকে ২০১০ সালের জন্য ৩.৫ ট্রিলিয়ন ডলারের ঐতিহাসিক বাজেট পাসের সুবিধার্থে।রেস পাবলিকা: সারা বিশ্বের বিভিন্ন জায়গায় দূর-বামের এজেন্ডা এগিয়ে নেওয়ার চেষ্টা করে, আরপি ই-অ্যাডভোকেসি বা ওয়েব-ভিত্তিক আন্দোলন-ভবনে বিশেষজ্ঞ। স্টেট প্রজেক্টের সেক্রেটারি: এই প্রকল্পটি ২০০৬ সালের জুলাই মাসে ডেমোক্র্যাটদের নির্বাচিত সুইং বা যুদ্ধক্ষেত্রে সেক্রেটারি অফ স্টেটের অফিসে নির্বাচিত হতে সহায়তা করার জন্য নিবেদিত একটি স্বাধীন ৫২৭ সংস্থা হিসাবে শুরু হয়েছিল। প্রেরণ প্রকল্প: কারাগারে-সেন্সিং প্যাটার্নগুলি জাতিগতভাবে বৈষম্যমূলক, এই উদ্যোগটি অপরাধীদের পক্ষে ভোট দেওয়ার অধিকার সমর্থন করে। সামাজিক ন্যায়বিচার নেতৃত্ব: এই সংস্থাটি একটি নতুন সামাজিক-ন্যায়বিচার আন্দোলনের মাধ্যমে কথিত নির্দোষ আমেরিকাকে কেবল সমাজে রূপান্তরিত করতে চায়।শ্যাডো ডেমোক্রেটিক পার্টি: এটি জর্জ সোরোস এবং অন্যদের দ্বারা সংগঠিত অলাভজনক একটিভিস্ট গ্রুপগুলির একটি বিস্তৃত নেটওয়ার্ক যা সম্পদ অর্থ সংগ্রহ, ভোটের মাধ্যমে বেরিয়ে যাওয়া ড্রাইভ, প্রচারণা বিজ্ঞাপন এবং গণতান্ত্রিক প্রার্থীদের নির্বাচিত করার জন্য নীতি উদ্যোগ এবং বাম দিকে ডেমোক্রেটিক পার্টিকে গাইড করার জন্য সংগঠিত। সোজুরনার্স: এই ধর্মপ্রচারক খ্রিস্টান মন্ত্রিসভা মৌলিক বামপন্থী রাজনীতি প্রচার করে।১৯৮০-এর দশকে এটি মধ্য আমেরিকায় কমিউনিস্ট বিপ্লবকে সমর্থন করে এবং সোভিয়েতদের সম্পর্কে সবচেয়ে খারাপ অনুমান করার প্রবণতার জন্য মার্কিন নীতি নির্ধারকদের শাস্তি দেয়।আরো সম্প্রতি, সজরনার্স পরিবেশ আন্দোলনের কারণ তুলে ধরেছে, কল্যাণ সংস্কারের বিরোধিতা করেছে একটি অর্থ-উদ্দেশ্যপ্রণোদিত রিপাবলিকান এজেন্ডা হিসাবে, এবং ইতিবাচক পদক্ষেপের পক্ষ সমর্থন করেছে। দক্ষিণ দারিদ্র্য আইন কেন্দ্র: এই সংস্থা মার্কিন যুক্তরাষ্ট্রে ঘৃণা গোষ্ঠী বলে অভিহিত কার্যকলাপ পর্যবেক্ষণ করে।এটি আমেরিকান সংখ্যালঘুদের বিরুদ্ধে পরিচালিত সাদা বর্ণবাদের প্রাদুর্ভাবকে অতিরঞ্জিত করে। স্টেট ভয়েসেস: এই জোট ২২ টি রাজ্যের স্বাধীন স্থানীয় সক্রিয় কর্মীদের একটি বছরের ভিত্তিতে যৌথভাবে কাজ করতে সহায়তা করে, যাতে তাদের প্রচেষ্টার প্রভাব সর্বাধিক করতে পারে। ক্রান্তিকাল নিয়ে কথা বলা: নিউইয়র্কের নতুন নির্বাচিত গণতান্ত্রিক মেয়র বিল ডি ব্লাসিওর জন্য সিটি হলে রূপান্তরে সহায়তা করার জন্য ২০১৩ সালের নভেম্বরের গোড়ার দিকে এটি দুই সপ্তাহের একটি প্রকল্প শুরু হয়েছিল। অগ্রগতি চিন্তা করুন: এই ইন্টারনেট ব্লগ তার রক্ষণশীল লক্ষ্যগুলির বিপরীতে প্রতিদিন পিছনে ফিরে যায় এবং দ্রুত যোগাযোগ, আইনী পদক্ষেপ, তৃণমূল এবং অ্যাডভোকেসি এবং বিশ্বব্যাপী অন্যান্য প্রগতিশীল নেতাদের সাথে অংশীদারিত্ব সংগঠিত করার মাধ্যমে প্রগতিশীল ধারণাগুলিকে নীতিতে রূপান্তর করার চেষ্টা করে।থান্ডার রোড গ্রুপ: এই রাজনৈতিক পরামর্শ, যার সৃষ্টিতে সোরোসের একটি হাত ছিল, মিডিয়া ফান্ড, আমেরিকা একত্র হচ্ছে এবং আমেরিকা ভোটস এর জন্য সমন্বয় কৌশল।টাইডস ফাউন্ডেশন এবং টাইডস সেন্টার: টাইডস মৌলিক বাম মার্কিন যুক্তরাষ্ট্রের একটি প্রধান তহবিল।পাবলিক ইন্টারেস্ট রিসার্চ গ্রুপ: এটি ছাত্র গোষ্ঠীর একটি ছাতা সংগঠন যা বামপন্থী এজেন্ডা সমর্থন করে। সার্বজনীন স্বাস্থ্যসেবা অ্যাকশন নেটওয়ার্ক: এই সংস্থা কেন্দ্রীয় সরকার দ্বারা নিয়ন্ত্রিত একক-পেয়ার স্বাস্থ্য সেবা ব্যবস্থাকে সমর্থন করে। আরবান ইনস্টিটিউট: এই গবেষণা সংস্থা সামাজিক ঔষধ, ফেডারেল কল্যাণ আমলাতন্ত্রের সম্প্রসারণ এবং উচ্চ আয়ের-মালিকদের জন্য কর বৃদ্ধিকে সমর্থন করে। ইউএসএকশন এডুকেশন ফান্ড: ইউএসএকশন তার অগ্রাধিকারগুলির তালিকা করে যেমন: সঠিক পক্ষের এজেন্ডার বিরুদ্ধে লড়াই করা; তৃণমূল রাজনৈতিক ক্ষমতা গড়ে তোলা; সকলের জন্য সামাজিক, জাতিগত ও অর্থনৈতিক ন্যায়বিচার শিক্ষিত করা; করদাতাদের অর্থায়নে সামাজিক ঔষধের একটি সিস্টেমকে সমর্থন করা; মিলিয়নিয়ার এবং কর্পোরেশনগুলির জন্য বেপরোয়া কর কর্তনকে পুনরুজ্জীবিত করা যা তাদের নির্বাচিত পরিবেশগত বিষয়গুলির ন্যায্য ও প্রগতিশীল সরকারের পক্ষে কাজ করে; নির্বাচিত পরিবেশগত বিষয়গুলির জন্য তাদের কর্মপরিবেশগত কণ্ঠস্বরকে সমর্থন করে।ভোটো ল্যাটিনো: এই দলটি ল্যাটিন-আমেরিকানদের নিবন্ধিত ভোটার এবং রাজনৈতিক কর্মী হওয়ার জন্য একত্রিত করতে চায়। আমরা আমেরিকা জোট: এই জোট আমেরিকান রাজনৈতিক প্রক্রিয়ায় অভিবাসীদের দ্বারা নাগরিক অংশগ্রহণ বৃদ্ধিকে উৎসাহিত করে। ওয়ার্কিং ফ্যামিলিস পার্টি: সমাজতান্ত্রিক নতুন পার্টির বিকাশ, ডাব্লুএফপি বাম দিকে ডেমোক্রেটিক পার্টিকে চাপ দিতে সহায়তা করার চেষ্টা করে। নির্যাতনের বিরুদ্ধে ওয়ার্ল্ড অর্গানাইজেশন: এই জোট এমন দলগুলির সাথে ঘনিষ্ঠভাবে কাজ করে যারা ফিলিস্তিনি সন্ত্রাসবাদের বিরুদ্ধে ইসরায়েলি নিরাপত্তা ব্যবস্থাকে নিন্দা করে। ওয়াইডব্লিউসিএ ওয়ার্ল্ড অফিস, সুইজারল্যান্ড: ওয়াইডব্লিউসিএ সংযম শিক্ষার বিরোধিতা করে; করদাতা-অর্থায়িত গর্ভপাত-অন-ডেমান্ডের সার্বজনীন প্রবেশাধিকার সমর্থন করে; এবং স্কুল ভাউচারের বিরোধিতা করে।জর্জ সোরোস নেটওয়ার্কের মাধ্যমিক বা পরোক্ষ অধিভুক্তি সরাসরি জর্জ সোরোস এবং তার ওপেন সোসাইটি ইনস্টিটিউট (ওএসআই) দ্বারা অর্থায়ন করা সংস্থা ছাড়াও সোরোস নেটওয়ার্কের অসংখ্য মাধ্যমিক বা পরোক্ষ অনুমোদিত রয়েছে।এর মধ্যে আছে সেইসব সংস্থা যা সোরোস আর ওএসআই থেকে সরাসরি অর্থ পায় না, কিন্তু যা এক বা একাধিক সংস্থার দ্বারা অর্থায়ন করা হয়।- ড. রিচ সুইয়ার জর্জ সোরোসের সাথে সংশ্লিষ্ট সকল গৌণ গ্রুপের তালিকার জন্য, এখানে যান\n"
          ]
        }
      ],
      "source": [
        "max_len = 0\n",
        "max_len_itr =0\n",
        "\n",
        "for i in range(len(final_df)):\n",
        "  sent = sent = final_df['text'][i]\n",
        "\n",
        "  # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "  input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "  # Update the maximum sentence length.\n",
        "  leng = len(input_ids)\n",
        "  if(leng>max_len):\n",
        "    max_len = leng\n",
        "    max_len_itr = i\n",
        "\n",
        "print('Max sentence length: ', max_len)\n",
        "print('sentence: ', final_df['text'][max_len_itr])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Di5Ii3japzTP"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in final_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNLWYZP-oKns",
        "outputId": "24c81e24-c503-4132-afef-b24d7cc4389b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শোকজগত ১৭ সেপ্টেম্বর বাংলাদেশ কৃষি বিশ্ববিদ্যালয়ে (বাকৃবি) উপাচার্যের কার্যালয়ে হট্টগোলের ঘটনায় দুইজনকে সাময়িক বরখাস্ত ও ছয় জনকে শোকজ করেছে বিশ্ববিদ্যালয় প্রশাসন। বুধবার বিশ্ববিদ্যালয় বাকৃবি রেজিস্ট্রার সাইফুল ইসলাম স্বাক্ষরিত এক নোটিশে আগামী ৭ দিনের মধ্যে উপযুক্ত উত্তর দেয়ার নির্দেশ দেয়া হয়েছে। এদিকে এ ঘটনায় আন্দোলনের সঙ্গে একাত্বতা প্রকাশ না করায় হামলার শিকার হয়ে কারিগরি কর্মচারী পরিষদের সভাপতি ও সাধারণ সম্পাদক হাসপাতালে ভর্তি হয়েছেন। সাময়িক বরখাস্তরা হলেন- শিক্ষা বিষয়ক শাখার কর্মচারী ও ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন ও কর্মকর্তা পরিষদের যুগ্ম সম্পাদক জিয়াউর রহমান টিটু। এছাড়া বিশ্ববিদ্যালয় সম্প্রসারণ কেন্দ্রের সহকারী পরিচালক মোহাম্মদ আবুল বাসার আমজাদ, ডেপুটি লাইব্রেরিয়ান মো.খাইরুল আলম নান্নু, মো.আবদুল বাতেন, ক্রীড়া প্রশিক্ষণ বিভাগের মোহাম্মদ মোস্তাইন কবীর সোহেল, সংস্থাপন শাখার সহকারী রেজিস্ট্রার মোহাম্মদ আশিকুল আলম বাচ্চু ও খামার ব্যবস্থাপনা শাখার অ্যাডিশনাল রেজিস্ট্রার ড. মো. হেলাল উদ্দীনকে কারণ দর্শানোর নোটিশ দেয় প্রশাসন।  নোটিশে উল্লেখ করা হয়, গত সোমবার দুপুরে সোয়া ১২টার দিকে উপাচার্যের অনুমতি ছাড়াই হঠাৎ করে উপাচার্যের কার্যালয়ে প্রবেশ করে ছাত্র বিষয়ক উপদেষ্টা, প্রক্টর, ডিন কাউন্সিলের আহ্বায়ক, রেজিস্ট্রার ও সাংবাদিকদের সামনে উপাচার্য ও উপ-উপাচার্যকে লক্ষ্য করে আঙ্গুল উচিয়ে কটুক্তি করে এবং অশালীন শারীরিক অঙ্গভঙ্গি করে। এতে করে বিশ্ববিদ্যালয়ের উচ্চ পর্যায়ের প্রাশাসনিক কার্যক্রম ব্যাহত হয় এবং উপাচার্যের সঙ্গে দুর্ব্যবহার করে যা বিশ্ববিদ্যালয়েল চাকরি সংবিধির সুস্পষ্ট লঙ্ঘন ও গুরুতর অপরাধ। এদিকে প্রশাসনের কারণ দর্শানোর নোটিশ পাওয়ার পর অফিসার পরিষদের নেতারা মিছিল নিয়ে হিসাব সংরক্ষণ শাখা, প্রকৌশল শাখা, পরিকল্পনা ও উন্নয়ন শাখায় তালা ঝুঁলিয়ে দেয়। তবে প্রশাসন ভবনে পুলিশ মোতায়ন থাকায় তালা দিতে ব্যর্থ হয়। কর্মকর্তাদের সঙ্গে একাত্বতা প্রকাশ করে কর্মচারীরাও ক্যাম্পাসে মিছিল করে। এসময় তারা প্রশাসনের বিরুদ্ধে বিভিন্ন ধরনে শ্লোগান দিতে থাকে।  এদিকে কারিগরি কর্মচারী পরিষদের পক্ষ থেকে আন্দোলনে সঙ্গে একাত্বতা প্রকাশ না করায় হামলা করে ৩য় ও চতুর্থ শ্রেণির কর্মচারীরা। এবিষয়ে কারিগরি কর্মচারী পরিষদের সভাপতি মো. আবদুল মোতালেব বলেন, আমরা চার দফা দাবিতে ঐক্যবদ্ধ হয়েছিলাম। গত ১৭ সেপ্টেম্বর আমাদের রেখেই ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন কর্মকর্তাদের সঙ্গে ভিসি সচিবালয়ে ঢুকে ভিসির সঙ্গে বেয়াদবি করে। পরবর্তীতে তাকে বিশ্ববিদ্যালয় থেকে শোকজ করলে আমাকে ও আমার সংগঠনের সকলকে তাদের সঙ্গে আন্দোলনে যেতে বলে। যোগ না দিলে পরে ৩য় ও ৪র্থ শ্রেণি মিলে আমাদের সংগঠনে হামলা করে, চেয়ার ভাঙে। এ ঘটনায় আমি ও আমার সংগঠনের সাধারণ সম্পাদক সুলতান আহমেদ আহত হয়ে বর্তমানে ময়মনসিংহ হাসপাতালে ভর্তি আছি। মো. শাহীন সরদার/আরএ/আরআইপি\n",
            "Token IDs: tensor([   101,    979,  18513,  33072,  20725, 105525,    100,  17660,  13104,\n",
            "        111237,  47356,  15613,  55145,  77983,    970,  11128,  79045,  83924,\n",
            "           117,    999,  39002,  18243,    976,  16431,  13104,  24383,  72177,\n",
            "         37962,  44394,  27470,    948, 111237,  34070,  12235,    100,    113,\n",
            "         17660,  13104, 111237,  47356,    114,    941,  22335,  12079,  85746,\n",
            "         50263,    100,    979,  18513,  33072,  20725, 105525,  11421,    100,\n",
            "         55145,  77983,  18243,    100,    970,  11128,  79045,  83924,    946,\n",
            "           100,  39002,  18243,    976,  16431,  13104,  24383,  72567,    100,\n",
            "           968,  21790,  92910,  80214,    920,    970,  16166,  56251,  36213,\n",
            "           100,  17660,  13104, 111237,  47356,    974,  11199, 110013,  71482,\n",
            "         21790,  15010,    978,  40102,  54632,  30277,    939,  15258,  97963,\n",
            "           978,  29806, 105069, 111240,  34070,  82742,  13542,  28777,    967,\n",
            "         16431,  14176,  57189,  41026,  58354,  13100,   1000,  71839,  11421,\n",
            "         20430,    941,  22335,  84466,  43578,    100,    967,  27268,  72614,\n",
            "        105496,    100,    100,    920,    944, 107106,    944,    100,    938,\n",
            "        104306, 105525,  26796,  52082,  28777,  43004,  29806,  19668,  75973,\n",
            "         26109,    100,    979,  58354,  67876,    976,  98994,    100,    948,\n",
            "         15010,  12235,  54032,  12235,    948,  94686,  85746,  13100,  29740,\n",
            "         12235,  34070,  16755,    978,  96341,  76939,    946,  89075,    978,\n",
            "         15002, 111240,  22335, 101655,  13104,    979,  30831,  22335,  43004,\n",
            "         28725,  11199,    971,  11128,  50782,    100,    920,    100,    970,\n",
            "         11128,  79045,  83924,  28410,  92576,  11737,    118,  75114,    100,\n",
            "           976,  96105,  11128,    948,  94686,  85746,  13100,    946,    100,\n",
            "           976,  80187,  20513,  27268,  89075,    978,  15002, 111240,  22335,\n",
            "        101655,  13104,    972,  16431,    119,    972,  16431,  92910,  11128,\n",
            "         54632,    979,  16431,  29993,  11737,    946,    948,  94686,  13104,\n",
            "         11128,  72659,  29740,  12235,  34070,  16755,    973,  16166,  20725,\n",
            "        111240,  15002,    978,  15002, 111240,  22335, 101655,  13104,    100,\n",
            "           974,  26145,  29454,  65288,  18513,  16166,    920,    100,    100,\n",
            "           978,  15002, 111240,  22335,  21790,  60398,  40652, 100869,  11421,\n",
            "        109087,  56836,  29740,  12235,  39427,  28725,  13104,    972,  16431,\n",
            "         88105,    938,  19910,  30277,  17660,  60398,  11128,    938,  15002,\n",
            "        105495,  17511,    117,    960,  11199,  22335,  16166,  14176,    100,\n",
            "           972,  16431,    119,  80501,  14998,  11128,  30277,  76837,  15002,\n",
            "         26109,  99182,  16166,    117,    972,  16431,    119,    938,  19910,\n",
            "         17511,  30277,  17660,  15613,  11737,    117,    100,    968,  21790,\n",
            "         97303,  98320,  83703,  11421,    972,  16431,  88105,    972,  16431,\n",
            "         83924,  40102,  11737,    948,  70060,  11128,    978,  16431,  26145,\n",
            "         42620,    117,    978,  22756, 102069,  71943,    976,  96105,  11128,\n",
            "        109087,  56836,    974,  11199, 110013,  71482,  21790,  15010,    972,\n",
            "         16431,  88105,    938,  97303,  13104,  30277,  76837,  15002,  17660,\n",
            "         39427, 111240,  39427,  16166,    946,  80501,  55077,    970,  15215,\n",
            "        106676,  71943,  12079,    976,  96105,  11128,    937,  40685,  38044,\n",
            "        102916,  20979,  13458,    974,  11199, 110013,  71482,  21790,  15010,\n",
            "           960,    119,    972,  16431,    119,    979, 100970,  13458,    941,\n",
            "         17511,  72614,  81337,  18243,  79092,    965,  11128, 111240,  92910,\n",
            "         53294,  11128,    967,  16431,  14176,  22875,    100,    968,  21790,\n",
            "         92910,  80214,    920,    967,  16431,  14176,  57189,    941,  13458,\n",
            "        111240,  28799,  42651,  14704,    100,    117,    950,  13542,    978,\n",
            "         16431,  15002,  36213,    965,  16166,  31947,  11199,    100,  37048,\n",
            "         53883,  53512,    941,  22335,  12079,  85746,  50263,    937,  11737,\n",
            "         16166,  15002,  29904,    100,    979, 111232,  12079,  45284,  13334,\n",
            "           941,  22335,  12079,  85746,  50263,    100,    968,  21790,  99092,\n",
            "         13334,    954,  43004,  21790,    100,    941,  22335,  91602,  38695,\n",
            "         12079,    117,    968,  21790,  13104,  33072,  11128,    117,    960,\n",
            "         39994,    948,  12079,  89362,  11737,  27556,  62753,  11421,    100,\n",
            "           117,    974,  11199, 110013,  71482,  21790,  15010,    102])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', final_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_0oUn0Olq_Or",
        "outputId": "01bd5312-3869-4fdd-99f7-e6816785182a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8,513 training samples\n",
            "1,503 validation samples\n"
          ]
        }
      ],
      "source": [
        "# from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QLU1GDVrPqd"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q1TqBQ9Rr-Pt",
        "outputId": "4be84709-9f0f-4cb1-d260-96753c3f7a3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n",
            "Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "82b8d945740f4d4abc617dc5be98649c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/714M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/pytorch_model.bin\n",
            "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-multilingual-cased\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "    num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "                    # You can increase this for multi-class tasks.   \n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DYFhvbHWsgG_"
      },
      "outputs": [],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNweRhQCsl00"
      },
      "outputs": [],
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y0RmMrCAs5wL",
        "outputId": "0b6825d1-4474-4c4b-cabd-a98857992e58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:00.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:00.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:00.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:00.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:00.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:59.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:59.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:59.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:59.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:59.\n",
            "\n",
            "  Average training loss: 0.16\n",
            "  Training epcoh took: 0:13:17\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.09\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:59.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:59.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:59.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:59.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:59.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:59.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:59.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:59.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:58.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:58.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:58.\n",
            "\n",
            "  Average training loss: 0.08\n",
            "  Training epcoh took: 0:13:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.09\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:00.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:59.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:59.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:59.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:59.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:59.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:59.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:59.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:59.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:58.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:58.\n",
            "\n",
            "  Average training loss: 0.05\n",
            "  Training epcoh took: 0:13:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:00.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:00.\n",
            "  Batch   120  of    533.    Elapsed: 0:02:59.\n",
            "  Batch   160  of    533.    Elapsed: 0:03:59.\n",
            "  Batch   200  of    533.    Elapsed: 0:04:59.\n",
            "  Batch   240  of    533.    Elapsed: 0:05:59.\n",
            "  Batch   280  of    533.    Elapsed: 0:06:59.\n",
            "  Batch   320  of    533.    Elapsed: 0:07:59.\n",
            "  Batch   360  of    533.    Elapsed: 0:08:59.\n",
            "  Batch   400  of    533.    Elapsed: 0:09:59.\n",
            "  Batch   440  of    533.    Elapsed: 0:10:58.\n",
            "  Batch   480  of    533.    Elapsed: 0:11:58.\n",
            "  Batch   520  of    533.    Elapsed: 0:12:58.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:13:16\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:48\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:56:17 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CuZSUSwvyb-Y",
        "outputId": "eac1b33c-8ddf-40e3-fca0-f3c089e9934a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/saved_models/multibert/config.json\n",
            "Model weights saved in /content/drive/MyDrive/saved_models/multibert/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "#TM_fnfn : tahsin mayeesha finetune+finetune (first fine tuned with regular train, then model summarized train data)\n",
        "model.save_pretrained('/content/drive/MyDrive/saved_models/multibert/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXxZ4EBq78PZ"
      },
      "source": [
        "#load data for 2nd fine tune"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dEJPWWQkSjQV",
        "outputId": "307b289f-5419-43db-8519-aea6b7843c2f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file /content/drive/MyDrive/saved_models/multibert/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/saved_models/multibert/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/saved_models/multibert/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#loading models\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/saved_models/multibert/\",\n",
        "    num_labels = 2,\n",
        "    output_attentions = False, # Whether the model returns attentions weights.\n",
        "    output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "loaded_model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slFEmH3T720N"
      },
      "outputs": [],
      "source": [
        "#path2 contains modelsum_train\n",
        "final_df = pd.read_csv(path2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7B1q5Vy7hcS"
      },
      "source": [
        "#MODEL TRAINING 2 (modesum train data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "omqXOkBa7hci"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in final_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyUFqJpz7hcj",
        "outputId": "c8955d79-e1b6-472e-bf58-8409fc752432"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original:  বাংলাদেশের কৃষি বিশ্ববিদ্যালয়ে উপাচার্যের কার্যালয়ে হট্টগোলের ঘটনায় দুইজনকে সাময়িক বরখাস্ত ও ছয় জনকে শোকজ করেছে বিশ্ববিদ্যালয় প্রশাসন। বাকৃবিতে হামলাকারীদের কারণ দর্শানোর নোটিশ দেয়া হয়েছে গত ১৭ সেপ্টেম্বরের দুপুরে। এ ঘটনাকে কেন্দ্র করে   Kuniকেল কোর্টের নির্দেশ অনুযায়ী আগামী ৭ দিনের মধ্যে উত্তর দেয়ার পরামর্শ দিয়েছেন বিশ্ববিদ্যালয়ের শিক্ষার্থীরা।. এর সঙ্গে BBC 코리아 .. ( ) - এই নিয়ে , বিবিসি । (সংবাদিকদের ধারণা : 'আন্তর্জাতিক নকল প্রকাশ বন্ধ করে দেয় প্রধান পক্ষ সরকার।'  এ বিভক্তি সবসময়ই হলেও, এখনো এ বিষয়ে আবারো আলোচনা চলছে। তবে এবারের আন্দোলনে এমন তিনজনকে গ্রেপ্তার করা হচ্ছে নতুন করে দুইজন বিশ্ববিদ্যালয় শিক্ষক এবং শিক্ষকদের বিরুদ্ধে বিভিন্ন ক্ষেত্রে আন্দোলন শুরু হওয়ার পর এখন পর্যন্ত সাক্ষীর সংখ্যা ছাড়াও এসব ব্যবস্থা গ্রহণ করতে চাইছে ছাত্র অধিকার সংগঠনগুলোর একটি বড় অংশের সাথে সামাজিক যোগাযোগ মাধ্যম ভিত্তিক সূত্রগুলোয় দেখা গেছে, যেখানে এ ধরণের বিতর্ক চরমে পৌঁছানো হয়েছে একাধিক অভিযোগের কথা রয়েছে এখানকার বিশ্ববিদ্যালয় কর্তৃপক্ষ।\n",
            "Token IDs: tensor([   101,  39325,    948, 111237,  34070,  12235,  77952,  11199,    941,\n",
            "         22335,  12079,  85746,  50263,    948,  15010,  40685,  13458,  24758,\n",
            "           979,  18513,  33072,  20725, 105525,  11421,    951,  18513, 101089,\n",
            "         55145,  77983,  18243,    978,  58354,  13228,  15691,    970,  11128,\n",
            "         79045,  83924,    946,    954,  13228,  39002,  18243,    976,  16431,\n",
            "         13104,  24383,  72567,  77952,    968,  21790,  92910,  80214,    920,\n",
            "         17660,  13104, 111237,  47356,  15613,    979,  58354,  29621,  56836,\n",
            "         16755,  79092,    965,  11128, 111240,  92910,  53294,  11128,    967,\n",
            "         16431,  14176,  22875,  97474,  28515,    950,  13542,  37962,  44394,\n",
            "         11421,    965,  16166,  31947,  11199,    920,    944,    951,  18513,\n",
            "         20979,  18243, 100869,  13334,  29184,  10116,  18243,  13458,    948,\n",
            "         47719,  33072,  11421,    967,  27268,  72614, 105496,  90564,  41026,\n",
            "         58354,  13100,   1000,  71839,  11421,  20430,  43578,  97474,  11128,\n",
            "         29740,  58354,  11128, 111240,  22875,  38583,  43468,  77952,  11421,\n",
            "         75114,  11128,  38833,  27608,  12079,    920,    119,  14770,  52082,\n",
            "         11721,   9812,  31065,    119,    119,    113,    114,    118,  14112,\n",
            "         31527,    117,    970,  12235,  47356,  45733,    920,    113,    978,\n",
            "         22756,  74765,  15691,  16755,    966,  93168,  12079,    131,    112,\n",
            "         56781,    967,  13104,  13458,  75973,    970,  11737,  66199,  13334,\n",
            "         66363,  38628,    968,  68988,  62853,    920,    112,    944,    970,\n",
            "         12235,  61596,  72593, 100024,  15258,  15002,  13228,  14998,  92576,\n",
            "         18262,    117,    944,  42651,  53294,    944,    970,  12235,  34070,\n",
            "         24758, 106681,  16431,  76837,  16431,  58914,    953,  13458,  32294,\n",
            "           920,  46406,    944,  87828,    938, 104306, 105525,  30023, 109477,\n",
            "         98146,  77983,  18243,    950,  80187,  77139,  15010,  14704,  53372,\n",
            "         58169,  13334,  55145,  77983,  77952,    976,  15691, 111240, 103598,\n",
            "         12051,    976,  15691, 111240, 103598,  16755,  93370,  34792,  76605,\n",
            "           938, 104306, 105525,  11737,  33151,  96347,  29740,    944,  42651,\n",
            "         11737,  34491,    978, 105069, 111240,  34070,  27608,  79066,    954,\n",
            "         92525,  18262,    944,  86373,    970,  15215, 106676,  84294,  28517,\n",
            "           953,  40102,  32294,    954,  43004,  21790,    937,  68259,  15010,\n",
            "           978,  22756,  20725,  93996,  72977,  11128,  14374,  59620,  47687,\n",
            "         11421,  22904,    978,  58354, 100277,  15691, 106535,  12079,  61777,\n",
            "         18601,  56251,  15215,  15002,    971,  17460,  50782,  13104,    978,\n",
            "        111236,  42783,  72977,  13228,  51743,    950, 109432,    117,  77745,\n",
            "           944,    966, 102582,    970,  17460,  63490,    953,  11128,  65045,\n",
            "           968, 111239, 111219,  53574,  18770,  16431,  28515,  28777,  12079,\n",
            "         68259,    937,  80045,  61777,  11421,  72088,  29638,    944,  79045,\n",
            "         11737,  35884,  77952,    948,  11128,  45947, 111237,  22335,  68988,\n",
            "           920,    102,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', final_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZVrpwzh7hck",
        "outputId": "f0848905-f830-4e84-f1b6-1325101bd441"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8,513 training samples\n",
            "1,503 validation samples\n"
          ]
        }
      ],
      "source": [
        "# from torch.utils.data import TensorDataset, random_split\n",
        "\n",
        "# Combine the training inputs into a TensorDataset.\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "# Create a 90-10 train-validation split.\n",
        "\n",
        "# Calculate the number of samples to include in each set.\n",
        "train_size = int(0.85 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "\n",
        "# Divide the dataset by randomly selecting samples.\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9XGNi9S97hck"
      },
      "outputs": [],
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# The DataLoader needs to know our batch size for training, so we specify it \n",
        "# here. For fine-tuning BERT on a specific task, the authors recommend a batch \n",
        "# size of 16 or 32.\n",
        "batch_size = 16\n",
        "\n",
        "# Create the DataLoaders for our training and validation sets.\n",
        "# We'll take training samples in random order. \n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,  # The training samples.\n",
        "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
        "            batch_size = batch_size # Trains with this batch size.\n",
        "        )\n",
        "\n",
        "# For validation the order doesn't matter, so we'll just read them sequentially.\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, # The validation samples.\n",
        "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
        "            batch_size = batch_size # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5qE-wZd7hcl",
        "outputId": "643f9406-108b-4ce4-8979-da625b47c435"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "# Load BertForSequenceClassification, the pretrained BERT model with a single \n",
        "# linear classification layer on top. \n",
        "model = loaded_model\n",
        "# model = BertForSequenceClassification.from_pretrained(\n",
        "#     \"Tahsin-Mayeesha/bangla-fake-news-mbert\", # Use the 12-layer BERT model, with an uncased vocab.\n",
        "#     num_labels = 2, # The number of output labels--2 for binary classification.\n",
        "#                     # You can increase this for multi-class tasks.   \n",
        "#     output_attentions = False, # Whether the model returns attentions weights.\n",
        "#     output_hidden_states = False, # Whether the model returns all hidden-states.\n",
        "# )\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "model.cuda()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzVp6fL27hcl"
      },
      "outputs": [],
      "source": [
        "# Note: AdamW is a class from the huggingface library (as opposed to pytorch) \n",
        "# I believe the 'W' stands for 'Weight Decay fix\"\n",
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
        "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
        "                )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73ZGCd4U7hcm"
      },
      "outputs": [],
      "source": [
        "# from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
        "# We chose to run for 4, but we'll see later that this may be over-fitting the\n",
        "# training data.\n",
        "epochs = 4\n",
        "\n",
        "# Total number of training steps is [number of batches] x [number of epochs]. \n",
        "# (Note that this is not the same as the number of training samples).\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "# Create the learning rate scheduler.\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
        "                                            num_training_steps = total_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdF2QQ4u7hcn",
        "outputId": "7984cfc2-b266-4823-8782-f2deee2c3f66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:02.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:04.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:05.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:06.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:07.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:09.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:10.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:11.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:12.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:14.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:15.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:16.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:17.\n",
            "\n",
            "  Average training loss: 0.13\n",
            "  Training epcoh took: 0:13:36\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:51\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:02.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:03.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:05.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:06.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:07.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:08.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:09.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:10.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:11.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:12.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:14.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:15.\n",
            "\n",
            "  Average training loss: 0.07\n",
            "  Training epcoh took: 0:13:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.07\n",
            "  Validation took: 0:00:51\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:03.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:04.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:05.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:06.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:07.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:08.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:09.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:10.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:11.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:12.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:14.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:15.\n",
            "\n",
            "  Average training loss: 0.04\n",
            "  Training epcoh took: 0:13:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:50\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of    533.    Elapsed: 0:01:01.\n",
            "  Batch    80  of    533.    Elapsed: 0:02:02.\n",
            "  Batch   120  of    533.    Elapsed: 0:03:03.\n",
            "  Batch   160  of    533.    Elapsed: 0:04:04.\n",
            "  Batch   200  of    533.    Elapsed: 0:05:05.\n",
            "  Batch   240  of    533.    Elapsed: 0:06:06.\n",
            "  Batch   280  of    533.    Elapsed: 0:07:08.\n",
            "  Batch   320  of    533.    Elapsed: 0:08:09.\n",
            "  Batch   360  of    533.    Elapsed: 0:09:10.\n",
            "  Batch   400  of    533.    Elapsed: 0:10:11.\n",
            "  Batch   440  of    533.    Elapsed: 0:11:12.\n",
            "  Batch   480  of    533.    Elapsed: 0:12:13.\n",
            "  Batch   520  of    533.    Elapsed: 0:13:14.\n",
            "\n",
            "  Average training loss: 0.02\n",
            "  Training epcoh took: 0:13:33\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.98\n",
            "  Validation Loss: 0.08\n",
            "  Validation took: 0:00:51\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:57:37 (h:mm:ss)\n"
          ]
        }
      ],
      "source": [
        "# import random\n",
        "# import numpy as np\n",
        "\n",
        "# This training code is based on the `run_glue.py` script here:\n",
        "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
        "\n",
        "# Set the seed value all over the place to make this reproducible.\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# We'll store a number of quantities such as training and validation loss, \n",
        "# validation accuracy, and timings.\n",
        "training_stats = []\n",
        "\n",
        "# Measure the total training time for the whole run.\n",
        "total_t0 = time.time()\n",
        "\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    # Measure how long the training epoch takes.\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    # Put the model into training mode. Don't be mislead--the call to \n",
        "    # `train` just changes the *mode*, it doesn't *perform* the training.\n",
        "    # `dropout` and `batchnorm` layers behave differently during training\n",
        "    # vs. test (source: https://stackoverflow.com/questions/51433378/what-does-model-train-do-in-pytorch)\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "            # Report progress.\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a\n",
        "        # backward pass. PyTorch doesn't do this automatically because \n",
        "        # accumulating the gradients is \"convenient while training RNNs\". \n",
        "        # (source: https://stackoverflow.com/questions/48001598/why-do-we-need-to-call-zero-grad-in-pytorch)\n",
        "        model.zero_grad()        \n",
        "\n",
        "        # Perform a forward pass (evaluate the model on this training batch).\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # It returns different numbers of parameters depending on what arguments\n",
        "        # arge given and what flags are set. For our useage here, it returns\n",
        "        # the loss (because we provided labels) and the \"logits\"--the model\n",
        "        # outputs prior to activation.\n",
        "        outputs = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "        # Accumulate the training loss over all of the batches so that we can\n",
        "        # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "        # single value; the `.item()` function just returns the Python value \n",
        "        # from the tensor.\n",
        "        \n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        # Update parameters and take a step using the computed gradient.\n",
        "        # The optimizer dictates the \"update rule\"--how the parameters are\n",
        "        # modified based on their gradients, the learning rate, etc.\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        # Tell pytorch not to bother with constructing the compute graph during\n",
        "        # the forward pass, since this is only needed for backprop (training).\n",
        "        with torch.no_grad():        \n",
        "\n",
        "            # Forward pass, calculate logit predictions.\n",
        "            # token_type_ids is the same as the \"segment ids\", which \n",
        "            # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "            # The documentation for this `model` function is here: \n",
        "            # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "            # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "            # values prior to applying an activation function like the softmax.\n",
        "            outputs = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            loss = outputs[0]\n",
        "            logits = outputs[1]\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "30E0E4h67hcp",
        "outputId": "22bb3b5d-cd9d-4747-8705-3da4b078db54"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Configuration saved in /content/drive/MyDrive/saved_models/multibert_fnfn/config.json\n",
            "Model weights saved in /content/drive/MyDrive/saved_models/multibert_fnfn/pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "#TM_fnfn : tahsin mayeesha finetune+finetune (first fine tuned with regular train, then model summarized train data)\n",
        "model.save_pretrained('/content/drive/MyDrive/saved_models/multibert_fnfn/')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1y2mQdbwGRR"
      },
      "source": [
        "#load model from saved\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BUMXkhrU7hcq",
        "outputId": "1094ddc2-baff-4907-c585-eb85e75258a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file /content/drive/MyDrive/saved_models/multibert_fnfn/config.json\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"/content/drive/MyDrive/saved_models/multibert/\",\n",
            "  \"architectures\": [\n",
            "    \"BertForSequenceClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"directionality\": \"bidi\",\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pooler_fc_size\": 768,\n",
            "  \"pooler_num_attention_heads\": 12,\n",
            "  \"pooler_num_fc_layers\": 3,\n",
            "  \"pooler_size_per_head\": 128,\n",
            "  \"pooler_type\": \"first_token_transform\",\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"problem_type\": \"single_label_classification\",\n",
            "  \"torch_dtype\": \"float32\",\n",
            "  \"transformers_version\": \"4.25.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 119547\n",
            "}\n",
            "\n",
            "loading weights file /content/drive/MyDrive/saved_models/multibert_fnfn/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
            "\n",
            "All the weights of BertForSequenceClassification were initialized from the model checkpoint at /content/drive/MyDrive/saved_models/multibert_fnfn/.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#loading models\n",
        "loaded_model = BertForSequenceClassification.from_pretrained(\n",
        "    \"/content/drive/MyDrive/saved_models/multibert_fnfn/\",\n",
        "    num_labels = 2\n",
        ")\n",
        "\n",
        "# Tell pytorch to run this model on the GPU.\n",
        "loaded_model.cuda()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycrqMjV1z9ei"
      },
      "source": [
        "#Testing with test_df(regular)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiW-7TD8z9ez",
        "outputId": "96dfdb92-0057-48c4-efc5-0d2b073d6006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "e5xOg7x_z9e0",
        "outputId": "26e4d6b6-28c4-4aa0-f97d-532c4cc1deb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7ce04f70-74db-4458-bfdd-e192e75010ed\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>মোস্তফা কামালের 'থ্রি নভেলস' এখন ই-বুক ফরমেটেদ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7ce04f70-74db-4458-bfdd-e192e75010ed')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7ce04f70-74db-4458-bfdd-e192e75010ed button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7ce04f70-74db-4458-bfdd-e192e75010ed');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "test_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwmV1eRzz9e0"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "68hgybTvz9e0",
        "outputId": "66dc75e4-1903-4bdf-9008-046199775b29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  অধ্যাপক গোলাম আযম যে ইস্কুলের মাষ্টার, আমি সে ইস্কুলের চানাচুরওলা: কাদের সিদ্দিকী | দৈনিক মতিকণ্ঠনিজস্ব মতিবেদকচলমান মানবতাবিরোধী অপরাধের বিচার নিয়ে তীব্র ক্ষোভ প্রকাশ করে মুক্তিযুদ্ধকালে কাদেরিয়া বাহিনীর প্রধান বঙ্গবীর আবদুল কাদের সিদ্দিকী বীর উত্তম বলেছেন, এ দেশে কোনো মানবতাবিরোধী অপরাধী নেই। যে দুইজন মানবতাবিরোধী অপরাধী ছিলো, তাদের দেশছাড়া করা হয়েছে। তাদের একজন শহীদ প্রেসিডেন্ট মুক্তিযোদ্ধা জিয়াউর রহমান বীর উত্তমের সন্তান তারেক জিয়া এখন লন্ডনে ফুর্তি করছে। অপরজন বেগম খালেদা জিয়ার অপর সন্তান আরাফাত কোকো বেংককে গেংবেং করছে। দেশ তাই মানবতাবিরোধী অপরাধীমুক্ত।আজ এক সংবাদ সম্মেলনে আবদুল কাদের সিদ্দিকী এ কথা বলেন।তিনি আবেগঘন গলায় বলেন, অধ্যাপক গোলাম আযম একজন অধ্যাপক। তিনি অধ্যাপনা করতেন। মুক্তিযুদ্ধ চলাকালে তিনি টিক্কা খানের শিশুপুত্র খালিদ খানকে আমপারা অধ্যাপনা করতে টিক্কা খানের বাসভবনে যেতেন। অথচ বাকশালীরা গুজব রটিয়েছে তিনি মানবতাবিরোধী অপরাধে লিপ্ত ছিলেন। টিক্কার ছেলেকে আরবী শেখান কেন মানবতাবিরোধী অপরাধ হবে?কাদের সিদ্দিকী বলেন, অনেকেই বলে টিক্কার সাথে অধ্যাপক গোলাম আযমের অবৈধ যৌন সম্পর্ক আছে। তারা ভুল বলে। এ কথা মোটেও সত্য নয়। টিক্কা খান অনেক জোরাজুরি করলেও অধ্যাপক গোলাম আযম কখনও টিক্কার সাথে যৌন সম্পর্কে লিপ্ত হননি। তিনি তখনও পাক ছিলেন, এখনও পাক আছেন।অধ্যাপক গোলাম আযমের কাছে অস্ত্র জমা দিচ্ছেন কাদের সিদ্দিকীআবেগঘন গলায় তিনি বলেন, মুক্তিযুদ্ধের পর ভারতীয় সেনাবাহিনী আমাকে অস্ত্র সমর্পনের আদেশ দিয়েছিল। আমি তাদের বলেছিলাম, তুমাদের আমি চুদি না। এরপর বাংলাদেশ সেনাবাহিনী আমাকে অস্ত্র সমর্পনের আদেশ দিয়েছিল। আমি তাদের বলেছিলাম, তুমাদেরও আমি চুদি না। এরপর ১৯৭৮ সালে অধ্যাপক গোলাম আযম দেশে ফিরে আমাকে অস্ত্র সমর্পনের আদেশ দেন। আমি তখন বলেছিলাম, হুজুর আমি আপনাকেই শুধু চুদি। আপনারা জানেন, আমি অধ্যাপক গোলাম আযমের কদম মুবারকে আমার থ্রি নট থ্রি রাইফেলটি জমা দিয়েছিলাম। কাদের সিদ্দিকী দৃপ্ত কণ্ঠে বলেন, “অস্ত্র জমা দিয়েছি, ট্রেনিং জমা দেই নাই। অধ্যাপক গোলাম আযমের ডাকে দরকার হলে আবার আরেকটি মুক্তিযুদ্ধে ঝাপিয়ে পড়ব। পাক সার জমিন সাদ বাদ।”\n",
            "Token IDs: tensor([   101,    937,  56251,  97543,    950, 105525,  58354,    938, 111234,\n",
            "         15002,  24288,    939,  15258,  66946,  30277,  11421,  18601,  38695,\n",
            "         15010,    117,    938,  37376,  58417,    939,  15258,  66946,  30277,\n",
            "         11421,    953,  44465,  39427,  29261,  18262,  29621,    131,    948,\n",
            "        101655,  11421,    978,  12235,  17511,  72614,  15691,  13100,    196,\n",
            "         93793,  77221,  15691,  20513, 111240,  93996,  80198,  15258,  29806,\n",
            "         77221,  12235,  49178,  17511,  13104,  39427,  13458,  29454,  18601,\n",
            "         11737,  19910,  19668,  47356,  11128,  16431,  56251,  13100,    937,\n",
            "         62210,  12079,  56251,  11421,    970,  12235,  85746,  31527,    963,\n",
            "         13100,  19910,  21790,    948, 111240,  34070,  16431,  61596,  75973,\n",
            "         13334,    972,  83807, 111234,  16166,  47231,  80180,    948, 101655,\n",
            "         11421,  32437,  17660,  93659,  38628,    970,  62855,  70060,  11128,\n",
            "           938,  19910,  17511,  30277,    948, 101655,  11421,    978,  12235,\n",
            "         17511,  72614,  15691,  13100,    970,  27608,    941,  13542,  45947,\n",
            "         15002,  41330,  43468,    117,    944,  88324,  11199,  77001,  18601,\n",
            "         11737,  19910,  19668,  47356,  11128,  16431,  56251,  13100,    937,\n",
            "         62210,  12079,  56251,  13100,    967,  59712,    920,  24288,  55145,\n",
            "         77983,  18601,  11737,  19910,  19668,  47356,  11128,  16431,  56251,\n",
            "         13100,    937,  62210,  12079,  56251,  13100,  20066,  16431,    117,\n",
            "         32144,  88324,  53574,  92525,  14704,  28515,    920,  32144,  28943,\n",
            "           976,  74282,  17511,    968,  80187,  45733,  38044,  37903,  33072,\n",
            "           972,  83807, 111234,  16431,  47231,  12079,    955,  32437,  89362,\n",
            "         11128,    974,  26145,  29454,    970,  27608,    941,  13542,  45947,\n",
            "         72703,    978,  70115,  18770,  16869,  55971,    955,  32437,    944,\n",
            "         42651,  11737,    975,  77045,  30023,    969,  29261,  50782,    948,\n",
            "         11128,  32294,    920,    937,  62210,  77983,    970,  11199,  20725,\n",
            "         15002,  80501,  28799, 106352,    955,  76914,    937,  62210,    978,\n",
            "         70115,  18770,  46085,  12079,  84929,  13542,    948,  16431,  13104,\n",
            "         16431,    970,  11199,  22756,  13104,  18243,    950,  11199,  22756,\n",
            "         49178,  22756,    948,  11128,  32294,    920,  88324,  52038,  14998,\n",
            "         18601,  11737,  19910,  19668,  47356,  11128,  16431,  56251,  13100,\n",
            "           937,  62210,  12079,  56251,  13100,  15002,  69778,    920,    938,\n",
            "         24383,  28777,    978,  22756,  74765,    978,  15002, 111240,  65045,\n",
            "         13458,  30023,    938,  19910,  17511,  30277,    948, 101655,  11421,\n",
            "           978,  12235,  17511,  72614,  15691,  13100,    944,  72088,  41330,\n",
            "         11737,    920,  14192,    938,  49178,  20725, 111228,  11737,    950,\n",
            "         29621,  13228,  41330,  11737,    117,    937,  56251,  97543,    950,\n",
            "        105525,  58354,    938, 111234,  15002,  28943,    937,  56251,  97543,\n",
            "           920,  14192,    937,  56251,  40685,  71943,  12079,  99713,    920,\n",
            "           972,  83807, 111234,  16166,  47231,    953,  29621,  80180,  14192,\n",
            "         65288,  13104,  66946,  12079,  78666,  11421,    976, 102916,  16166,\n",
            "         22335,  98191,  21790,  80501,  55384,  17511,  78666,  18243,    938,\n",
            "         15002,  22335,  59928,    937,  56251,  40685,  71943,  12079,  28517,\n",
            "         65288,  13104,  66946,  12079,  78666,  11421,  17660,  15258,  61596,\n",
            "         75762,  11199,  24288,  15613,  11737,    920,    937,  39414,  39427,\n",
            "         17660,  13104,  92910,  79385,  28410,    950,  16166,  24383,  19910,\n",
            "           974,  14176,  24758,  32294,  14192,  18601,  11737,  19910,  19668,\n",
            "         47356,  11128,  16431,  56251,  13100,    937,  62210,  12079,  56251,\n",
            "         11199,    975,  12235,  77139,  24355,    920,  65288,  13104,  79932,\n",
            "           954,  67735,  18243,  46085,  70060,    976,  11199,  79045,  11737,\n",
            "         82937,  11737,  18601,  11737,  19910,  19668,  47356,  11128,  16431,\n",
            "         56251,  13100,    937,  62210,  12079,  56251,  53761,    136,    948,\n",
            "        101655,  11421,    978,  12235,  17511,  72614,  15691,  13100,  41330,\n",
            "         11737,    117,  45201,  59712,  41330,  65288,  13104,  79932,  22904,\n",
            "           937,  56251,  97543,    950, 105525,  58354,    938, 111234,  72703,\n",
            "         59136, 111238,  56251,    973, 111239,  11737,    978,  15002, 111240,\n",
            "         62210,  66946,  40560,    920,  43956,    971,  30277,    102])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LgxoBxXDz9e1"
      },
      "source": [
        "We can see some of the results by the model here. Our model trains on half of the dataset and achieves around 0.80 in overall f1. Its likely that the model is trained longer it will achieve better performance. I might retrain it later on full data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4I0lcQmz9e1"
      },
      "outputs": [],
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QQlh9EFOz9e1"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_VLqVCNz9e2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UaYkEw6z9e2",
        "outputId": "9eeedbfd-7d0e-49b3-bfbf-967815d2b98b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.91\n",
            "  Test Loss: 0.56\n",
            "  Test took: 0:00:46\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#model = loaded_model\n",
        "loaded_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        outputs = loaded_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        _, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y-5uNy9wz9e3",
        "outputId": "c7cc7c83-9cc5-4d69-f899-0a9201c3d486"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.87      0.90       600\n",
            "           1       0.88      0.95      0.91       600\n",
            "\n",
            "    accuracy                           0.91      1200\n",
            "   macro avg       0.91      0.91      0.91      1200\n",
            "weighted avg       0.91      0.91      0.91      1200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w9qmSLwBtG_1"
      },
      "source": [
        "#Testing with modelsum_test(summarized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lnEQAJ67tR_1"
      },
      "outputs": [],
      "source": [
        "path4 = '/content/drive/MyDrive/datasets/modelsum_test.csv'\n",
        "test_df = pd.read_csv(path4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjakwioetG_3",
        "outputId": "c879c132-adca-4b66-ee98-65fc4fcee1ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "test_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WX7Lt9NhtG_5",
        "outputId": "e3ad9f59-bcd7-4ac5-ff60-3bd48fd5cb90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    600\n",
              "1    600\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "test_df = test_df.dropna()\n",
        "test_df.label.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yDdorCIHtG_6",
        "outputId": "21dc69d7-0914-40fd-f1fa-87511caa7a8f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      label                                               text\n",
              "1195      1  বাংলাদেশের জনপ্রিয় কথাসাহিত্যিক মোস্তফা কামাল...\n",
              "1196      1  ‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...\n",
              "1197      1  শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...\n",
              "1198      1  তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...\n",
              "1199      1  বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2556ed7-b471-43ac-8552-e11fb7d142b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1195</th>\n",
              "      <td>1</td>\n",
              "      <td>বাংলাদেশের জনপ্রিয় কথাসাহিত্যিক মোস্তফা কামাল...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1196</th>\n",
              "      <td>1</td>\n",
              "      <td>‘জনসভা নিয়ে সরকারি দলের বিভিন্ন কথা অত্যন্ত দু...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1197</th>\n",
              "      <td>1</td>\n",
              "      <td>শয়নকক্ষ থেকে চুরি হওয়া নবজাতকের লাশ মিলল পুকুর...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1198</th>\n",
              "      <td>1</td>\n",
              "      <td>তারেক রহমানকে ফাঁসানোর ষড়যন্ত্র চলছে : মির্জা ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1199</th>\n",
              "      <td>1</td>\n",
              "      <td>বিবিএস কেবলস লিমিটেড'র ডিলার কনফারেন্সকেবলস ম্...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2556ed7-b471-43ac-8552-e11fb7d142b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b2556ed7-b471-43ac-8552-e11fb7d142b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b2556ed7-b471-43ac-8552-e11fb7d142b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "test_df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xb-aFgRitG_7"
      },
      "outputs": [],
      "source": [
        "label_list = []\n",
        "for label in test_df['label']:\n",
        "  label_list.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNUjhpu7tG_8",
        "outputId": "40d3c7a9-61fe-493d-ecc5-606ba4d755a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original:  বাংলাদেশে মানবতাবিরোধী অপরাধের বিচার নিয়ে তীব্র ক্ষোভ প্রকাশ করেছেন দৈনিক মতিকণ্ঠ। মুক্তিযুদ্ধের সময় বিএনপির চেয়ারপার্সন আবদুল কাদের সিদ্দিকী এবং তাঁর পরিবারের সদস্যরা তাকে গ্রেপ্তার ছাড়ার জন্য সরকার ব্যবস্থা গ্রহণ করেছে.  ,  BBC নিউজ এর পক্ষ থেকে এ বিষয়ে তৈরি কোন তথ্য বের হচ্ছে না - যার মধ্যে এক  Kuni ( ( ) ? ' বিবিসি ’ র সঙ্গে এখনও এই দেশে মানসিকতার বিচারে যুক্ত নেই .. এ সব ক্ষেত্রেই তারা গত কাল ঢাকায় জন্ম হল । এমন কী ভাবেন জাতিসংঘের একজন সাবেক প্রধানমন্ত্রী জিয়া খানকে গুলি করেন অধ্যাপক গোলাম আযমের বিরুদ্ধে যে অভিযোগ উঠেছে, সেই অভিজ্ঞতার কথা বললেও বিবিসির সংবাদ মাধ্যমে এসব খবর পাওয়া গেছে ইস্কুলের মাষ্টার, যিনি অবৈধভাবে টিক্কার সাথে যৌন সম্পর্কে লিপ্ত ছিলেন, তাদের দেশছাড়া তিনি এখনো বন্ধ করা হয়নি ; কিন্তু পাকিস্তানী নাগরিকদের কাছে এত মানুষের মত লোকজন এখানে আবারো যুদ্ধাপরাধীদের মৃত্যুর ঘটনা তো ঠিকই ছিলো, যে তিনজনের সামাজিক যোগাযোগ\n",
            "Token IDs: tensor([   101,  27470,  11199,  18601,  11737,  19910,  19668,  47356,  11128,\n",
            "         16431,  56251,  13100,    937,  62210,  12079,  56251,  11421,    970,\n",
            "         12235,  85746,  31527,    963,  13100,  19910,  21790,    948, 111240,\n",
            "         34070,  16431,  61596,  75973,  42339,  93793,  77221,  15691,  20513,\n",
            "        111240, 111232,    920,    972,  83807, 111234,  16166,  47231,  11421,\n",
            "         31803,    970,  12235, 111225,  11737,  82445,  11128,    953,  11199,\n",
            "         40061,  22335,  15010,  27556,  11737,    938,  19910,  17511,  30277,\n",
            "           948, 101655,  11421,    978,  12235,  17511,  72614,  15691,  13100,\n",
            "         12051,  22811,  29740,  12235,  87828,  64000,  28410,  51003,    950,\n",
            "         80187,  77139,  15010,    954,  92525,  11128,  17634,  62853,    970,\n",
            "         15215, 106676,  84294,  72567,    119,    117,  11721,    967,  99475,\n",
            "         24383,  14770,    968,  68988,  14339,    944,    970,  12235,  34070,\n",
            "         24758,  61664,  41431,  84933,    970,  11421,  53372,  26109,    118,\n",
            "         50793,  20430,  28777,  29184,  10116,    113,    113,    114,    136,\n",
            "           112,    970,  12235,  47356,  45733,    100,    974,  52082,    944,\n",
            "         42651,  11737,  18262,  14112,  88324,  11199,  18601,  11737,  45733,\n",
            "         13104,  44990,    970,  12235,  85746,  11199,    973,  69778,    967,\n",
            "         59712,    119,    119,    944, 100024,  76605,  14998,  43956,    950,\n",
            "         13542,    948,  28725,  46438,  13228,  53913,  27834,    920, 109477,\n",
            "           948,  13100,    971,  78639,  37903,    955,  43004,  65240,  22756,\n",
            "        111228,  11421,  28943,    978,  78639,  55971,  38628,  15002,  70115,\n",
            "         50644,    955,  32437,  78666,  18243,    950,  30277,  12235,  14199,\n",
            "           937,  56251,  97543,    950, 105525,  58354,    938, 111234,  72703,\n",
            "         93370,  24288,    937,  80045,  61777,    941,  90534,  32294,    117,\n",
            "         61899,    937,  80045,  24383, 111240, 111231,  44990,  72088,    970,\n",
            "         13458,  28799,  18262,    970,  12235,  47356,  45733,  11128,    978,\n",
            "         22756,  74765,  40143,    944,  86373,    949,  19910,  11128,  58347,\n",
            "           950, 109432,    939,  15258,  66946,  30277,  11421,  18601,  38695,\n",
            "         15010,    117,  98183,  59136, 111238,  56251,  27790,  65288,  13104,\n",
            "         79932,  22904,    973, 111239,  11737,    978,  15002, 111240,  62210,\n",
            "         66946,  11199,    975,  12235,  77139,  24355,    117,  32144,  88324,\n",
            "         53574,  92525,  14192,    944,  42651,  53294,    970,  11737,  66199,\n",
            "         14704,  12711,  40349,    132,  35003, 103093,  13100,  26109,  54032,\n",
            "         15691,  16755,  62920,    944,  13542, 109216,  77221,  19320,  77983,\n",
            "         60788, 106681,  16431, 107531,  96397,  28410,  56251,  93418,    972,\n",
            "         45908,  15215,  29261,    951,  18513,  20979,    963,  16431,    959,\n",
            "         15691,  14998,  20066,  16431,    117,  24288,  98146,  77983,  11421,\n",
            "           978,  58354, 100277,  15691, 106535,  12079,  61777,    102,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0,      0,\n",
            "             0,      0,      0,      0,      0,      0,      0,      0])\n"
          ]
        }
      ],
      "source": [
        "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in test_df['text']:\n",
        "    # `encode_plus` will:\n",
        "    #   (1) Tokenize the sentence.\n",
        "    #   (2) Prepend the `[CLS]` token to the start.\n",
        "    #   (3) Append the `[SEP]` token to the end.\n",
        "    #   (4) Map tokens to their IDs.\n",
        "    #   (5) Pad or truncate the sentence to `max_length`\n",
        "    #   (6) Create attention masks for [PAD] tokens.\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      # Sentence to encode.\n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 512,           # Pad & truncate all sentences.\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # Construct attn. masks.\n",
        "                        truncation = True,\n",
        "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
        "                   )\n",
        "    \n",
        "    # Add the encoded sentence to the list.    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    \n",
        "    # And its attention mask (simply differentiates padding from non-padding).\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(label_list)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', test_df['text'][0])\n",
        "print('Token IDs:', input_ids[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyp994tntG_9"
      },
      "source": [
        "We can see some of the results by the model here. Our model trains on half of the dataset and achieves around 0.80 in overall f1. Its likely that the model is trained longer it will achieve better performance. I might retrain it later on full data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ww40748CtG_9"
      },
      "outputs": [],
      "source": [
        "testdataset = TensorDataset(input_ids, attention_masks, labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQ5ly3hhtG_-"
      },
      "outputs": [],
      "source": [
        "test_dataloader = DataLoader(\n",
        "            testdataset, # The validation samples.\n",
        "            sampler = SequentialSampler(testdataset), # Pull out batches sequentially.\n",
        "            batch_size = 16 # Evaluate with this batch size.\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwgOoNYYtG_-"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JWk58-BNtG__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ea6b555-8966-4978-e90d-c82da8248688"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Testing...\n",
            "  Accuracy: 0.72\n",
            "  Test Loss: 1.75\n",
            "  Test took: 0:00:42\n"
          ]
        }
      ],
      "source": [
        "print(\"Running Testing...\")\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "# Put the model in evaluation mode--the dropout layers behave differently\n",
        "# during evaluation.\n",
        "#model = loaded_model\n",
        "loaded_model.eval()\n",
        "\n",
        "# Tracking variables \n",
        "total_eval_accuracy = 0\n",
        "total_eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "\n",
        "y_pred = []\n",
        "y_true = []\n",
        "\n",
        "# Evaluate data for one epoch\n",
        "for batch in test_dataloader:\n",
        "    \n",
        "    # Unpack this training batch from our dataloader. \n",
        "    #\n",
        "    # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "    # the `to` method.\n",
        "    #\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels \n",
        "    b_input_ids = batch[0].to(device)\n",
        "    b_input_mask = batch[1].to(device)\n",
        "    b_labels = batch[2].to(device)\n",
        "    \n",
        "    # Tell pytorch not to bother with constructing the compute graph during\n",
        "    # the forward pass, since this is only needed for backprop (training).\n",
        "    with torch.no_grad():        \n",
        "\n",
        "        # Forward pass, calculate logit predictions.\n",
        "        # token_type_ids is the same as the \"segment ids\", which \n",
        "        # differentiates sentence 1 and 2 in 2-sentence tasks.\n",
        "        # The documentation for this `model` function is here: \n",
        "        # https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
        "        # Get the \"logits\" output by the model. The \"logits\" are the output\n",
        "        # values prior to applying an activation function like the softmax.\n",
        "        outputs = loaded_model(b_input_ids, \n",
        "                                token_type_ids=None, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                labels=b_labels)\n",
        "        loss = outputs[0]\n",
        "        logits = outputs[1]\n",
        "\n",
        "        _, prediction = torch.max(logits, dim=1)\n",
        "        targets = b_labels.cpu().detach().numpy()\n",
        "        prediction = prediction.cpu().detach().numpy()\n",
        "\n",
        "        y_pred.extend(prediction)\n",
        "        y_true.extend(targets.tolist())\n",
        "        \n",
        "    # Accumulate the validation loss.\n",
        "    total_eval_loss += loss.item()\n",
        "\n",
        "    # Move logits and labels to CPU\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "    # Calculate the accuracy for this batch of test sentences, and\n",
        "    # accumulate it over all batches.\n",
        "    total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "    \n",
        "\n",
        "# Report the final accuracy for this validation run.\n",
        "avg_val_accuracy = total_eval_accuracy / len(test_dataloader)\n",
        "print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "# Calculate the average loss over all of the batches.\n",
        "avg_val_loss = total_eval_loss / len(test_dataloader)\n",
        "\n",
        "# Measure how long the validation run took.\n",
        "validation_time = format_time(time.time() - t0)\n",
        "\n",
        "print(\"  Test Loss: {0:.2f}\".format(avg_val_loss))\n",
        "print(\"  Test took: {:}\".format(validation_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HkMU8ESktHAA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b912fc-8cfc-411c-ecca-be486651d3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.53      0.66       600\n",
            "           1       0.66      0.92      0.77       600\n",
            "\n",
            "    accuracy                           0.73      1200\n",
            "   macro avg       0.77      0.72      0.71      1200\n",
            "weighted avg       0.77      0.72      0.71      1200\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_true, y_pred))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "QloXfBVVjlZh",
        "EhQIDJ6il66B",
        "XpmaLJWyNB2U"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c9dcc0acd96e45c18f0e853bf403a794": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64bc8c0b98d24730988810a5ed9583fb",
              "IPY_MODEL_4db6041e38664766abe5beb3e322f2f8",
              "IPY_MODEL_b5de1eafeca647d1a1e9f25d93041811"
            ],
            "layout": "IPY_MODEL_691ef4b9a9204180b8ed87f27c3f3210"
          }
        },
        "64bc8c0b98d24730988810a5ed9583fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_606ce278a16e404681719137483b2149",
            "placeholder": "​",
            "style": "IPY_MODEL_0853097ad1ca40f98a472aeceafed905",
            "value": "Downloading: 100%"
          }
        },
        "4db6041e38664766abe5beb3e322f2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55edede4c4fe48289b1b3884a657a67e",
            "max": 29,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8a551944ff3e44d09553637a955add26",
            "value": 29
          }
        },
        "b5de1eafeca647d1a1e9f25d93041811": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629302cc44a64185bbbb8fcf15213473",
            "placeholder": "​",
            "style": "IPY_MODEL_309ce77eac0541ff912e016e89abdea7",
            "value": " 29.0/29.0 [00:00&lt;00:00, 708B/s]"
          }
        },
        "691ef4b9a9204180b8ed87f27c3f3210": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "606ce278a16e404681719137483b2149": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0853097ad1ca40f98a472aeceafed905": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55edede4c4fe48289b1b3884a657a67e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a551944ff3e44d09553637a955add26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "629302cc44a64185bbbb8fcf15213473": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "309ce77eac0541ff912e016e89abdea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "238ec9805c45474987980d3ef28aaf02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9cb4c39d99b4788b34a0726f4b164ef",
              "IPY_MODEL_5f37396b162440f1a9f9282e0f234bdc",
              "IPY_MODEL_9c150cf5c35642cca4dfdfe714fb3e87"
            ],
            "layout": "IPY_MODEL_86a4bbc8951c4dc1b7df1e6ac337b2a8"
          }
        },
        "b9cb4c39d99b4788b34a0726f4b164ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58a147b23313435e8808dbb237a8cb60",
            "placeholder": "​",
            "style": "IPY_MODEL_eca703045a1c4600a3347a2ceb1df57d",
            "value": "Downloading: 100%"
          }
        },
        "5f37396b162440f1a9f9282e0f234bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_183508222e2241d18541b96204b2b07e",
            "max": 625,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18a2ed183f394843a661ac0629e1435a",
            "value": 625
          }
        },
        "9c150cf5c35642cca4dfdfe714fb3e87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ac548ca9fa453ebfc5675f5051038b",
            "placeholder": "​",
            "style": "IPY_MODEL_11e2a10675804cfeb61ca3096467c4c9",
            "value": " 625/625 [00:00&lt;00:00, 23.3kB/s]"
          }
        },
        "86a4bbc8951c4dc1b7df1e6ac337b2a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58a147b23313435e8808dbb237a8cb60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eca703045a1c4600a3347a2ceb1df57d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "183508222e2241d18541b96204b2b07e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18a2ed183f394843a661ac0629e1435a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a0ac548ca9fa453ebfc5675f5051038b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e2a10675804cfeb61ca3096467c4c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d186fbfdc984819893be6ca213950cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08bb5d0162bf4c219f25397ee497a581",
              "IPY_MODEL_685a0c6a4bf14ad1a81098d2dee681a9",
              "IPY_MODEL_ff69ac9550264ab3a27645f09654a34e"
            ],
            "layout": "IPY_MODEL_91e2c31539174b4da986daddd93c6896"
          }
        },
        "08bb5d0162bf4c219f25397ee497a581": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5095b1d9cd924d609b2ff39941e511fa",
            "placeholder": "​",
            "style": "IPY_MODEL_a17bfe5576c84d17b7dad8793386b3b8",
            "value": "Downloading: 100%"
          }
        },
        "685a0c6a4bf14ad1a81098d2dee681a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96e68a1c7c0941ac9873697e5dea84d8",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_277f6ecfc316410287b76d6490f51804",
            "value": 995526
          }
        },
        "ff69ac9550264ab3a27645f09654a34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a088bbfb0e8549a0a24dc17a7332a364",
            "placeholder": "​",
            "style": "IPY_MODEL_a8eefd8c2ddb4dd88048aa679a69dff5",
            "value": " 996k/996k [00:00&lt;00:00, 1.56MB/s]"
          }
        },
        "91e2c31539174b4da986daddd93c6896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5095b1d9cd924d609b2ff39941e511fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a17bfe5576c84d17b7dad8793386b3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96e68a1c7c0941ac9873697e5dea84d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "277f6ecfc316410287b76d6490f51804": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a088bbfb0e8549a0a24dc17a7332a364": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8eefd8c2ddb4dd88048aa679a69dff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f6e80fa4bdc4b60b9730ceb0b91ef73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b3533b21db984eb2a6ee5acba40c3b53",
              "IPY_MODEL_01533dbb8fcb4e01817aec67242cba2b",
              "IPY_MODEL_c3133b3a187148d2b83684c62a113b27"
            ],
            "layout": "IPY_MODEL_30aa584466804722bffebe3a3fa14d0f"
          }
        },
        "b3533b21db984eb2a6ee5acba40c3b53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b82990028d834fc3b86281f80fb7d8e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0de5c100100f4531bf69f6579766095e",
            "value": "Downloading: 100%"
          }
        },
        "01533dbb8fcb4e01817aec67242cba2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48df543bcfd74e7ea4848a847c51d948",
            "max": 1961828,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c8743e0d46ad404aba69641edcce70b1",
            "value": 1961828
          }
        },
        "c3133b3a187148d2b83684c62a113b27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0bdccb7dc1b4e10bf71d8097abee067",
            "placeholder": "​",
            "style": "IPY_MODEL_b51444cb720f437eabb121bc7dc60a02",
            "value": " 1.96M/1.96M [00:00&lt;00:00, 4.69MB/s]"
          }
        },
        "30aa584466804722bffebe3a3fa14d0f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82990028d834fc3b86281f80fb7d8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0de5c100100f4531bf69f6579766095e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48df543bcfd74e7ea4848a847c51d948": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8743e0d46ad404aba69641edcce70b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d0bdccb7dc1b4e10bf71d8097abee067": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b51444cb720f437eabb121bc7dc60a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}