{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TOq7B_40lDK9",
        "outputId": "c3358e90-cbc2-4d7b-e3ff-c9dc4a377c86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No GPU available, using the CPU instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bLXleXuvNmOV"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentencepiece\n",
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0Ni-8Uqswow",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9be1ea2-3f6b-4e4d-f29a-dd1bfec6988e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaUFAGkoOjw9"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MeHFP-aKe8yS"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEtV-2-RNpO5"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQJ_1ZHyvhne"
      },
      "outputs": [],
      "source": [
        "\n",
        "from transformers import *\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS3kzHl6Mwkz"
      },
      "source": [
        "We will use weights and biases for tracking experiments and runs. Project page : https://wandb.ai/tasmiah-tahsin/fake-news-blurr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVEvLd64veua"
      },
      "source": [
        "# Load dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4q3yba0FOm4D"
      },
      "outputs": [],
      "source": [
        "# fake = pd.read_csv(\"/content/drive/MyDrive/datasets/Fake-1K.csv\")\n",
        "# fake_syn = pd.read_csv(\"/content/drive/MyDrive/datasets/fake_synthetic.csv\")\n",
        "# authentic = pd.read_csv(\"/content/drive/MyDrive/datasets/Authentic-48K.csv\",engine='python',error_bad_lines=False,warn_bad_lines=True,nrows=15000)\n",
        "# df = pd.concat([authentic[['headline','content','label']],fake[['headline','content','label']],fake_syn[['headline','content','label']]])\n",
        "# df.reset_index(drop=True,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split1 = pd.read_csv(\"/content/drive/MyDrive/datasets/test.csv\")\n",
        "split1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DAojrRaKdkFQ",
        "outputId": "18446149-a9de-491e-fd2e-c7405fe388e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1200, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##preparing a new dataframe "
      ],
      "metadata": {
        "id": "RnyD-tE_2RP1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# sel_df = pd.DataFrame(columns = ['label', 'text', 'sum_text'])\n",
        "# final_df['sum_text'] = \"\""
      ],
      "metadata": {
        "id": "oSYBjTrE2ZT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# final_df.shape, sel_df.shape"
      ],
      "metadata": {
        "id": "9sylRssV4S0b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code for Alt line Truncation"
      ],
      "metadata": {
        "id": "3_xxVY9_eSde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_len_wtokenizer(sent):\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "    length = len(input_ids)\n",
        "    return length"
      ],
      "metadata": {
        "id": "fULL8SDyeXUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_len(sent):\n",
        "    word_count = len(sent.split())\n",
        "    return word_count"
      ],
      "metadata": {
        "id": "T58KqEJyebtq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def trunc_alt_sent(str_w):\n",
        "    x = str_w.rsplit(\"। \")\n",
        "    n = len(x)\n",
        "    if n==1:\n",
        "      x = str_w.rsplit(\"।\")\n",
        "      n = len(x)\n",
        "    res_str = \"default: \"\n",
        "    l2 = []\n",
        "    for i in range(0,n):\n",
        "        if(i%2==0):\n",
        "            #print(x[i])\n",
        "            l2.append(x[i])\n",
        "\n",
        "    res_str = \"। \".join(l2)\n",
        "\n",
        "    #print(res_str)\n",
        "    return res_str\n",
        "    "
      ],
      "metadata": {
        "id": "_jnJOkxPef5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "#timeout = time.time() + 60   # 1 minutes from now"
      ],
      "metadata": {
        "id": "Pu7pwYVCewON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# timeout = time.time() + 30\n",
        "# while True:    \n",
        "#     if time.time() > timeout:\n",
        "#       print('timeout')\n",
        "#       break"
      ],
      "metadata": {
        "id": "JUBeGkMde8h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itr=0\n",
        "sum_count=0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in split1['text']:   \n",
        "    \n",
        "    timeout = time.time() + 30\n",
        "    while(1):\n",
        "        if(calc_len(sent)<512):\n",
        "            break\n",
        "        \n",
        "        if(itr!=903):\n",
        "          sum_count+=1\n",
        "        \n",
        "        if(time.time() > timeout):\n",
        "            print('timeout. eror in row: ', itr)\n",
        "            break\n",
        "        sent = trunc_alt_sent(sent)\n",
        "        #leng = calc_len(sent)\n",
        "    \n",
        "    split1.at[itr,'text'] = sent\n",
        "    \n",
        "    if(itr%300==0):\n",
        "      print(itr)\n",
        "    itr+=1\n",
        "print(\"successfully done. sum count: \", sum_count)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qbypk_GqgVAE",
        "outputId": "51fc5518-709a-408e-917a-a76d9e680ea0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "300\n",
            "600\n",
            "900\n",
            "timeout. eror in row:  903\n",
            "successfully done. sum count:  0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split1.to_csv('/content/drive/MyDrive/datasets/work2.csv', index=False)"
      ],
      "metadata": {
        "id": "Ix7sSdpfJXWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testing_hypo = split1\n",
        "testing_hypo.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGW5j-x3kBTW",
        "outputId": "17919788-f10d-4a17-bfad-5f9fba845e84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10016, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_string = testing_hypo.iloc[0]['text']\n",
        "sent_t = trunc_alt_sent(a_string)\n",
        "testing_hypo.iloc[0]['text'] = sent_t\n",
        "testing_hypo.iloc[0]['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "wikZ_12WkJZv",
        "outputId": "c63e8a8f-0a2a-499a-eaf4-f2f4dbfedc4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'হট্টগোল করায় বাকৃবিতে দুইজন বরখাস্ত, ৬ জনকে শোকজগত ১৭ সেপ্টেম্বর বাংলাদেশ কৃষি বিশ্ববিদ্যালয়ে (বাকৃবি) উপাচার্যের কার্যালয়ে হট্টগোলের ঘটনায় দুইজনকে সাময়িক বরখাস্ত ও ছয় জনকে শোকজ করেছে বিশ্ববিদ্যালয় প্রশাসন। বুধবার বিশ্ববিদ্যালয় বাকৃবি রেজিস্ট্রার সাইফুল ইসলাম স্বাক্ষরিত এক নোটিশে আগামী ৭ দিনের মধ্যে উপযুক্ত উত্তর দেয়ার নির্দেশ দেয়া হয়েছে। এদিকে এ ঘটনায় আন্দোলনের সঙ্গে একাত্বতা প্রকাশ না করায় হামলার শিকার হয়ে কারিগরি কর্মচারী পরিষদের সভাপতি ও সাধারণ সম্পাদক হাসপাতালে ভর্তি হয়েছেন। সাময়িক বরখাস্তরা হলেন- শিক্ষা বিষয়ক শাখার কর্মচারী ও ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন ও কর্মকর্তা পরিষদের যুগ্ম সম্পাদক জিয়াউর রহমান টিটু। এছাড়া বিশ্ববিদ্যালয় সম্প্রসারণ কেন্দ্রের সহকারী পরিচালক মোহাম্মদ আবুল বাসার আমজাদ, ডেপুটি লাইব্রেরিয়ান মো.খাইরুল আলম নান্নু, মো.আবদুল বাতেন, ক্রীড়া প্রশিক্ষণ বিভাগের মোহাম্মদ মোস্তাইন কবীর সোহেল, সংস্থাপন শাখার সহকারী রেজিস্ট্রার মোহাম্মদ আশিকুল আলম বাচ্চু ও খামার ব্যবস্থাপনা শাখার অ্যাডিশনাল রেজিস্ট্রার ড. মো. হেলাল উদ্দীনকে কারণ দর্শানোর নোটিশ দেয় প্রশাসন।  নোটিশে উল্লেখ করা হয়, গত সোমবার দুপুরে সোয়া ১২টার দিকে উপাচার্যের অনুমতি ছাড়াই হঠাৎ করে উপাচার্যের কার্যালয়ে প্রবেশ করে ছাত্র বিষয়ক উপদেষ্টা, প্রক্টর, ডিন কাউন্সিলের আহ্বায়ক, রেজিস্ট্রার ও সাংবাদিকদের সামনে উপাচার্য ও উপ-উপাচার্যকে লক্ষ্য করে আঙ্গুল উচিয়ে কটুক্তি করে এবং অশালীন শারীরিক অঙ্গভঙ্গি করে। এতে করে বিশ্ববিদ্যালয়ের উচ্চ পর্যায়ের প্রাশাসনিক কার্যক্রম ব্যাহত হয় এবং উপাচার্যের সঙ্গে দুর্ব্যবহার করে যা বিশ্ববিদ্যালয়েল চাকরি সংবিধির সুস্পষ্ট লঙ্ঘন ও গুরুতর অপরাধ। এদিকে প্রশাসনের কারণ দর্শানোর নোটিশ পাওয়ার পর অফিসার পরিষদের নেতারা মিছিল নিয়ে হিসাব সংরক্ষণ শাখা, প্রকৌশল শাখা, পরিকল্পনা ও উন্নয়ন শাখায় তালা ঝুঁলিয়ে দেয়। তবে প্রশাসন ভবনে পুলিশ মোতায়ন থাকায় তালা দিতে ব্যর্থ হয়। কর্মকর্তাদের সঙ্গে একাত্বতা প্রকাশ করে কর্মচারীরাও ক্যাম্পাসে মিছিল করে। এসময় তারা প্রশাসনের বিরুদ্ধে বিভিন্ন ধরনে শ্লোগান দিতে থাকে।  এদিকে কারিগরি কর্মচারী পরিষদের পক্ষ থেকে আন্দোলনে সঙ্গে একাত্বতা প্রকাশ না করায় হামলা করে ৩য় ও চতুর্থ শ্রেণির কর্মচারীরা। এবিষয়ে কারিগরি কর্মচারী পরিষদের সভাপতি মো. আবদুল মোতালেব বলেন, আমরা চার দফা দাবিতে ঐক্যবদ্ধ হয়েছিলাম। গত ১৭ সেপ্টেম্বর আমাদের রেখেই ৩য় শ্রেণির সাধারণ সম্পাদক মো. মোশারফ হোসেন কর্মকর্তাদের সঙ্গে ভিসি সচিবালয়ে ঢুকে ভিসির সঙ্গে বেয়াদবি করে। পরবর্তীতে তাকে বিশ্ববিদ্যালয় থেকে শোকজ করলে আমাকে ও আমার সংগঠনের সকলকে তাদের সঙ্গে আন্দোলনে যেতে বলে। যোগ না দিলে পরে ৩য় ও ৪র্থ শ্রেণি মিলে আমাদের সংগঠনে হামলা করে, চেয়ার ভাঙে। এ ঘটনায় আমি ও আমার সংগঠনের সাধারণ সম্পাদক সুলতান আহমেদ আহত হয়ে বর্তমানে ময়মনসিংহ হাসপাতালে ভর্তি আছি। মো. শাহীন সরদার/আরএ/আরআইপি'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Code for Slicing df before summarization\n"
      ],
      "metadata": {
        "id": "QloXfBVVjlZh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "\n",
        "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
        "\n"
      ],
      "metadata": {
        "id": "K9-59f9Gfigh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aba644af-2f7a-4f59-b144-1213e38f02ba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"csebuetnlp/mT5_multilingual_XLSum\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"length_penalty\": 0.6,\n",
            "  \"max_length\": 84,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"no_repeat_ngram_size\": 2,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading file spiece.model from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/spiece.model\n",
            "loading file tokenizer.json from cache at None\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/special_tokens_map.json\n",
            "loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"csebuetnlp/mT5_multilingual_XLSum\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"length_penalty\": 0.6,\n",
            "  \"max_length\": 84,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"no_repeat_ngram_size\": 2,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"csebuetnlp/mT5_multilingual_XLSum\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"length_penalty\": 0.6,\n",
            "  \"max_length\": 84,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"no_repeat_ngram_size\": 2,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/config.json\n",
            "Model config MT5Config {\n",
            "  \"_name_or_path\": \"csebuetnlp/mT5_multilingual_XLSum\",\n",
            "  \"architectures\": [\n",
            "    \"MT5ForConditionalGeneration\"\n",
            "  ],\n",
            "  \"d_ff\": 2048,\n",
            "  \"d_kv\": 64,\n",
            "  \"d_model\": 768,\n",
            "  \"decoder_start_token_id\": 0,\n",
            "  \"dense_act_fn\": \"gelu_new\",\n",
            "  \"dropout_rate\": 0.1,\n",
            "  \"eos_token_id\": 1,\n",
            "  \"feed_forward_proj\": \"gated-gelu\",\n",
            "  \"initializer_factor\": 1.0,\n",
            "  \"is_encoder_decoder\": true,\n",
            "  \"is_gated_act\": true,\n",
            "  \"layer_norm_epsilon\": 1e-06,\n",
            "  \"length_penalty\": 0.6,\n",
            "  \"max_length\": 84,\n",
            "  \"model_type\": \"mt5\",\n",
            "  \"no_repeat_ngram_size\": 2,\n",
            "  \"num_beams\": 4,\n",
            "  \"num_decoder_layers\": 12,\n",
            "  \"num_heads\": 12,\n",
            "  \"num_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"relative_attention_max_distance\": 128,\n",
            "  \"relative_attention_num_buckets\": 32,\n",
            "  \"tie_word_embeddings\": false,\n",
            "  \"tokenizer_class\": \"T5Tokenizer\",\n",
            "  \"transformers_version\": \"4.24.0\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 250112\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--csebuetnlp--mT5_multilingual_XLSum/snapshots/2437a524effdbadc327ced84595508f1e32025b3/pytorch_model.bin\n",
            "All model checkpoint weights were used when initializing MT5ForConditionalGeneration.\n",
            "\n",
            "All the weights of MT5ForConditionalGeneration were initialized from the model checkpoint at csebuetnlp/mT5_multilingual_XLSum.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use MT5ForConditionalGeneration for predictions without further training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "i=0\n",
        "\n",
        "# For every sentence...\n",
        "for sent in final_df['text']:   \n",
        "\n",
        "    # Tokenize the text and add `[CLS]` and `[SEP]` tokens.\n",
        "    input_ids = tokenizer.encode(sent, add_special_tokens=True)\n",
        "\n",
        "    # Only transfering greater than 500 token_length\n",
        "    length = len(input_ids)\n",
        "    if(length>500):\n",
        "        sel_df = sel_df.append(final_df.iloc[i]) \n",
        "        final_df = final_df.drop(i)\n",
        "        counter+=1    \n",
        "    \n",
        "    i+=1              \n",
        "\n",
        "print('number of sum text: ', counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "omy9EJ9D3ixU",
        "outputId": "d9003f8d-9ee0-4438-b16a-b0665bc0d45b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-63f26f0272de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0msel_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msel_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mfinal_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mcounter\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m             \u001b[0;31m# validate the location\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ixs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_integer\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1498\u001b[0m         \u001b[0mlen_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1499\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen_axis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlen_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1500\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"single positional indexer is out-of-bounds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1501\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1502\u001b[0m     \u001b[0;31m# -------------------------------------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sel_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mfi-F1GR40Hk",
        "outputId": "e12ab58d-b14b-446e-f7fa-b211a3d81426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3931, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxV2151S45Ba",
        "outputId": "8338d7a9-5115-4ff0-de43-65f58a4ea9de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6085, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sel_df.to_csv('/content/drive/MyDrive/datasets/selected_forsum.csv')\n",
        "final_df.to_csv('/content/drive/MyDrive/datasets/mod_final.csv')"
      ],
      "metadata": {
        "id": "R46kbMuZ5Qur"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##slicing into 9 parts"
      ],
      "metadata": {
        "id": "xcMIOG-368aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split1 = sel_df.iloc[:440, 0:]\n",
        "split2 = sel_df.iloc[440:880, 0:]\n",
        "split3 = sel_df.iloc[880:1320, 0:]\n",
        "split4 = sel_df.iloc[1320:1760, 0:]\n",
        "split5 = sel_df.iloc[1760:2200, 0:]\n",
        "split6 = sel_df.iloc[2200:2640, 0:]\n",
        "split7 = sel_df.iloc[2640:3080, 0:]\n",
        "split8 = sel_df.iloc[3080:3520, 0:]\n",
        "split9 = sel_df.iloc[3520:3930, 0:]"
      ],
      "metadata": {
        "id": "sb4ZvtyN6_Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split9.shape, split8.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuozx2Ux9Lzy",
        "outputId": "754f1770-5449-455f-a399-37d8b19588d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((410, 3), (440, 3))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "split1.to_csv('split1.csv')\n",
        "split2.to_csv('split2.csv')\n",
        "split3.to_csv('split3.csv')\n",
        "split4.to_csv('split3.csv')\n",
        "split5.to_csv('split5.csv')\n",
        "split6.to_csv('split6.csv')\n",
        "split7.to_csv('split7.csv')\n",
        "split8.to_csv('split8.csv')\n",
        "split9.to_csv('split9.csv')\n"
      ],
      "metadata": {
        "id": "e5Qsrnwn9hpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split1.to_csv('/content/drive/MyDrive/datasets/split1.csv')"
      ],
      "metadata": {
        "id": "GhbTQIPk-mUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split2.to_csv('/content/drive/MyDrive/datasets/split2.csv')\n",
        "split3.to_csv('/content/drive/MyDrive/datasets/split3.csv')\n",
        "split4.to_csv('/content/drive/MyDrive/datasets/split4.csv')\n",
        "split5.to_csv('/content/drive/MyDrive/datasets/split5.csv')\n",
        "split6.to_csv('/content/drive/MyDrive/datasets/split6.csv')\n",
        "split7.to_csv('/content/drive/MyDrive/datasets/split7.csv')\n",
        "split8.to_csv('/content/drive/MyDrive/datasets/split8.csv')\n",
        "split9.to_csv('/content/drive/MyDrive/datasets/split9.csv')"
      ],
      "metadata": {
        "id": "7Szw_ZWS-9mq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving the csv"
      ],
      "metadata": {
        "id": "hvEsJ5LluQd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_df.to_csv('sum_train.csv', index=False)\n",
        "path_tsum = '/content/drive/MyDrive/datasets/sum_train.csv'\n",
        "with open(path1, 'w') as f:\n",
        "  final_df.to_csv(f, index=False)"
      ],
      "metadata": {
        "id": "TlRxVcZHuT8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpmaLJWyNB2U"
      },
      "source": [
        "# Resources\n",
        "\n",
        "* fastai paper : https://arxiv.org/pdf/2002.04688.pdf\n",
        "* [BERT Fine-Tuning Tutorial with PyTorch · Chris McCormick](https://mccormickml.com/2019/07/22/BERT-fine-tuning/)\n",
        "* [multilingual bert](https://huggingface.co/bert-base-multilingual-cased)\n",
        "* https://github.com/cdpierse/transformers-interpret\n",
        "* https://blog.dataiku.com/the-learning-rate-finder-technique-how-reliable-is-it"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "SaUFAGkoOjw9",
        "XpmaLJWyNB2U"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}